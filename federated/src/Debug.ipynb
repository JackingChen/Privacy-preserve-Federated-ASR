{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'None/meta-data/test_dic.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/FedASR/dacs/federated/src/Debug.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# from options import args_parser\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataset, average_weights, exp_details\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mupdate\u001b[39;00m \u001b[39mimport\u001b[39;00m update_network_weight, get_model_weight\n",
      "File \u001b[0;32m~/dacs/federated/src/utils.py:53\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m             batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m processor(batch[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39minput_ids            \u001b[39m# generate labels\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mID2Label\u001b[39m(ID,\n\u001b[0;32m---> 53\u001b[0m             spk2label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mDACS_codeRoot\u001b[39m}\u001b[39;49;00m\u001b[39m/meta-data/test_dic.npy\u001b[39;49m\u001b[39m\"\u001b[39;49m, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mtolist()):\n\u001b[1;32m     54\u001b[0m     name \u001b[39m=\u001b[39m ID\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)                                                    \u001b[39m#  from file name to spkID\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[39mif\u001b[39;00m (name[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mINV\u001b[39m\u001b[39m'\u001b[39m):                                                  \u001b[39m# interviewer is CC\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/Flower-speechbrain/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'None/meta-data/test_dic.npy'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from options import args_parser\n",
    "from utils import get_dataset, average_weights, exp_details\n",
    "\n",
    "import multiprocessing\n",
    "from update import update_network_weight, get_model_weight\n",
    "\n",
    "from training import client_train, centralized_training\n",
    "from update import ASRLocalUpdate\n",
    "\n",
    "def FL_training_rounds(args, model_in_path_root, model_out_path, train_dataset, test_dataset):\n",
    "    train_loss = []                                                                 # list for training loss\n",
    "    global_weights = None                                                           # initial global_weights\n",
    "\n",
    "    \n",
    "    for epoch in tqdm(range(args.epochs)):                                          # train for given global rounds\n",
    "        print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "        m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "        pool = multiprocessing.Pool(processes=m)\n",
    "\n",
    "        if args.STAGE == 0:                                                         # train ASR\n",
    "            local_weights_en = []                                                   # weight list for ASR encoder\n",
    "            local_weights_de = []                                                   # weight list for ASR decoder\n",
    "        else:                                                                       # train AD classifier or toggling network\n",
    "            local_weights = []                                                      # only 1 weight list needed\n",
    "        local_losses = []                                                           # losses of training clients of this round\n",
    "\n",
    "        try:\n",
    "            if (epoch == 0) and (args.STAGE == 2):                                  # start from global model to train toggling network\n",
    "                global_weights = get_model_weight(args=args, source_path=model_out_path + \"_global/final/\", network=\"toggling_network\")\n",
    "                                                                                    # local ASR and AD with global toggling network\n",
    "                                                                                    # get toggling_network weights from model in model_out_path + \"_global/final/\"\n",
    "            final_result = pool.starmap_async(client_train, [(args, model_in_path_root, model_out_path, train_dataset, test_dataset, idx,\n",
    "                                                                  epoch, global_weights) for idx in idxs_users])\n",
    "                                                                                    # train from model in model_in_path \n",
    "                                                                                    #                                 + \"_global/final/\", when stage=0\n",
    "                                                                                    #                                 + \"_client\" + str(idx) + \"_round\" + str(args.epochs-1) + \"/final/\", o.w.\n",
    "                                                                                    # or model in last round\n",
    "                                                                                    # final result in model_out_path + \"_client\" + str(client_id) + \"_round\" + str(global_round)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while using starmap_sync to run client_train: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            final_result.wait()                                                     # wait for all clients end\n",
    "            results = final_result.get()                                            # get results\n",
    "        \n",
    "        for idx in range(len(results)):                                             # for each participated clients\n",
    "            w, loss = results[idx]                                                  # function client_train returns w & loss\n",
    "            if args.STAGE == 0:                                                     # train ASR\n",
    "                local_weights_en.append(copy.deepcopy(w[0]))                        # save encoder weight for this client\n",
    "                local_weights_de.append(copy.deepcopy(w[1]))                        # save decoder weight for this client\n",
    "            else:                                                                   # train AD classifier or toggling network\n",
    "                local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(loss)\n",
    "\n",
    "        # aggregate weights\n",
    "        if args.STAGE == 0:                                                         # train ASR\n",
    "            global_weights = [average_weights(local_weights_en), average_weights(local_weights_de)]\n",
    "        else:                                                                       # train AD classifier or toggling network\n",
    "            global_weights = average_weights(local_weights)\n",
    "\n",
    "        loss_avg = sum(local_losses) / len(local_losses)                            # average losses from participated client\n",
    "        train_loss.append(loss_avg)                                                 # save loss for this round\n",
    "    return global_weights\n",
    "\n",
    "# FL stage 1: ASR & AD Classifier\n",
    "def stage1_training(args, train_dataset, test_dataset):\n",
    "    local_epoch = args.local_ep                                                     # save given number of local epoch\n",
    "    ##########################################################\n",
    "    # Centralized Training: train global ASR & AD Classifier #\n",
    "    ##########################################################\n",
    "    \"\"\"\n",
    "    args.local_ep = args.global_ep                                                  # use number of global epoch for global model\n",
    "    args.STAGE = 0                                                                  # train ASR first\n",
    "    centralized_training(args=args, model_in_path=args.pretrain_name, model_out_path=args.model_out_path+\"_finetune\", \n",
    "                         train_dataset=train_dataset, test_dataset=test_dataset, epoch=0)\n",
    "                                                                                    # train from pretrain, final result in args.model_out_path + \"_finetune\" + \"_global/final\"\n",
    "    args.STAGE = 1                                                                  # then train AD classifier\n",
    "    centralized_training(args=args, model_in_path=args.model_out_path+\"_finetune_global/final/\", \n",
    "                         model_out_path=args.model_out_path, train_dataset=train_dataset, test_dataset=test_dataset, epoch=0)\n",
    "                                                                                    # train from final result from last line, final result in args.model_out_path + \"_global/final\"\n",
    "    \"\"\"\n",
    "    ##########################################################\n",
    "    # FL: train local ASR & AD Classifier federally          #\n",
    "    ##########################################################\n",
    "    args.local_ep = local_epoch                                                     # use the given number of local epoch\n",
    "    args.STAGE = 0                                                                  # train ASR first\n",
    "    global_weights = FL_training_rounds(args=args, model_in_path_root=args.model_out_path, model_out_path=args.model_out_path+\"_finetune\",\n",
    "                                        train_dataset=train_dataset, test_dataset=test_dataset)\n",
    "\n",
    "    # update global model\n",
    "    model = update_network_weight(args=args, source_path=args.model_out_path+\"_global/final/\", target_weight=global_weights, network=\"ASR\") \n",
    "                                                                                    # update ASR in source_path with given weights\n",
    "    model.save_pretrained(args.model_out_path+\"_FLASR_global/final\")\n",
    "    \n",
    "    args.STAGE = 1                                                                  # then train AD classifier\n",
    "    global_weights = FL_training_rounds(args=args, model_in_path_root=args.model_out_path+\"_finetune\", model_out_path=args.model_out_path,\n",
    "                                        train_dataset=train_dataset, test_dataset=test_dataset)\n",
    "\n",
    "    # update global model\n",
    "    model = update_network_weight(args=args, source_path=args.model_out_path+\"_FLASR_global/final\", target_weight=global_weights, network=\"AD\")\n",
    "                                                                                    # update AD classifier in source_path with given weights\n",
    "    model.save_pretrained(args.model_out_path+\"_FLAD_global/final\")\n",
    "    \n",
    "    \n",
    "# FL stage 2: Toggling Network\n",
    "def stage2_training(args, train_dataset, test_dataset):\n",
    "    local_epoch = args.local_ep                                                     # save given number of local epoch\n",
    "    ##########################################################\n",
    "    # Centralized Training: train global Toggling Network    #\n",
    "    ##########################################################\n",
    "    \"\"\"\n",
    "    args.local_ep = args.global_ep                                                  # use number of global epoch for global model\n",
    "    centralized_training(args=args, model_in_path=args.model_in_path + \"_FLAD_global/final/\", model_out_path=args.model_out_path, \n",
    "                         train_dataset=train_dataset, test_dataset=test_dataset, epoch=0)\n",
    "                                                                                    # train from model_in_path + \"_FLAD_global/final/\" (aggregated ASR & AD)\n",
    "                                                                                    # final result in args.model_out_path + \"_global/final\"\n",
    "    \"\"\"\n",
    "    ##########################################################\n",
    "    # FL: train local Toggling Network federally             #\n",
    "    ##########################################################\n",
    "    args.local_ep = local_epoch                                                     # use the given number of local epoch\n",
    "    global_weights = FL_training_rounds(args=args, model_in_path_root=args.model_in_path, model_out_path=args.model_out_path,\n",
    "                                        train_dataset=train_dataset, test_dataset=test_dataset)\n",
    "    # update global model\n",
    "    model = update_network_weight(args=args, source_path=args.model_out_path+\"_global/final\", target_weight=global_weights, network=\"toggling_network\")\n",
    "                                                                                    # update toggling_network in source_path with given weights\n",
    "    model.save_pretrained(args.model_out_path+\"_final_global/final\")\n",
    "\n",
    "def extract_emb(args, train_dataset, test_dataset):\n",
    "    if args.client_id == \"public\":\n",
    "        idx = \"public\"\n",
    "    else:\n",
    "        idx = int(args.client_id)\n",
    "    local_model = ASRLocalUpdate(args=args, dataset=train_dataset, global_test_dataset=test_dataset, \n",
    "                                 client_id=idx, model_in_path=args.model_in_path, model_out_path=None)\n",
    "                                                                                      # initial dataset of current client\n",
    "    local_model.extract_embs()\n",
    "                                                                                      # from model_in_path model, update certain part using given weight\n",
    "# if __name__ == '__main__':\n",
    "print(\"I'm here\")\n",
    "start_time = time.time()\n",
    "\n",
    "# define paths\n",
    "path_project = os.path.abspath('..')\n",
    "\n",
    "# args = args_parser()  \n",
    "import argparse                                                          # get configuration\n",
    "parser = argparse.ArgumentParser()\n",
    "# federated arguments (Notation for the arguments followed from paper)\n",
    "parser.add_argument('--epochs', type=int, default=2,\n",
    "                    help=\"number of rounds of training\")\n",
    "parser.add_argument('--num_users', type=int, default=2,\n",
    "                    help=\"number of users: K\")\n",
    "parser.add_argument('--frac', type=float, default=1.0,\n",
    "                    help='the fraction of clients: C')\n",
    "parser.add_argument('--local_ep', type=int, default=5,\n",
    "                    help=\"the number of local epochs: E\")\n",
    "# model arguments\n",
    "parser.add_argument('--model', type=str, default='data2vec', help='model name')\n",
    "parser.add_argument('--dataset', type=str, default='adress', help=\"name \\\n",
    "                    of dataset\")\n",
    "parser.add_argument('--gpu', default=None, help=\"To use cuda, set \\\n",
    "                    to a specific GPU ID. Default set to use CPU.\")\n",
    "# additional arguments\n",
    "parser.add_argument('--pretrain_name', type=str, default='facebook/data2vec-audio-large-960h', help=\"str used to load pretrain model\")\n",
    "\n",
    "parser.add_argument('-lam', '--LAMBDA', type=float, default=0.5, help=\"Lambda for GRL\")\n",
    "parser.add_argument('-st', '--STAGE', type=int, default=1, help=\"Current training stage\")\n",
    "parser.add_argument('-fl_st', '--FL_STAGE', type=int, default=1, help=\"Current FL training stage\")\n",
    "parser.add_argument('-GRL', '--GRL', action='store_true', default=False, help=\"True: GRL\")\n",
    "parser.add_argument('-model_in', '--model_in_path', type=str, default=\"/home/FedASR/dacs/federated/save/data2vec-audio-large-960h_new1_recall_client0_round1/\", help=\"Where the global model is saved\")\n",
    "parser.add_argument('-model_out', '--model_out_path', type=str, default=\"/home/FedASR/dacs/federated/save/data2vec-audio-large-960h_new1_recall\", help=\"Where to save the model\")\n",
    "parser.add_argument('-log', '--log_path', type=str, default=\"wav2vec2-base-960h_linear_GRL.txt\", help=\"name for the txt file\")\n",
    "parser.add_argument('-csv', '--csv_path', type=str, default=\"wav2vec2-base-960h_GRL_0.5\", help=\"name for the csv file\")\n",
    "# 2023/01/08: loss type\n",
    "parser.add_argument('-ad_loss', '--AD_loss', type=str, default=\"cel\", help=\"loss to use for AD classifier\")\n",
    "# 2023/01/18: ckpt\n",
    "parser.add_argument('-ckpt', '--checkpoint', type=str, default=None, help=\"path to checkpoint\")\n",
    "# 2023/02/13: TOGGLE_RATIO\n",
    "parser.add_argument('-toggle_rt', '--TOGGLE_RATIO', type=float, default=0, help=\"To toggle more or less\")\n",
    "# 2023/02/15: GS_TAU, loss weight\n",
    "parser.add_argument('-gs_tau', '--GS_TAU', type=float, default=1, help=\"Tau for gumbel_softmax\")\n",
    "parser.add_argument('-w_loss', '--W_LOSS', type=float, default=None, nargs='+', help=\"weight for HC and AD\")\n",
    "# 2023/04/20\n",
    "parser.add_argument('-EXTRACT', '--EXTRACT', action='store_true', default=False, help=\"True: extract embs\")\n",
    "parser.add_argument('-client_id', '--client_id', type=str, default=\"public\", help=\"client_id: public, 0, or 1\")\n",
    "# 2023/04/24\n",
    "parser.add_argument('--global_ep', type=int, default=30, help=\"number for global model\")\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "exp_details(args)                                                               # print out details based on configuration\n",
    "\n",
    "train_dataset, test_dataset = get_dataset(args)                                 # get dataset\n",
    "# _, test_dataset = get_dataset(args)\n",
    "# train_dataset=test_dataset #先這樣Debug\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "multiprocessing.set_start_method('spawn', force=True)\n",
    "if args.EXTRACT != True:                                                        # Training\n",
    "    if args.FL_STAGE == 1:\n",
    "        print(\"| Start FL Training Stage 1|\")\n",
    "        stage1_training(args, train_dataset, test_dataset)                      # Train ASR & AD Classifier\n",
    "        print(\"| FL Training Stage 1 Done|\")\n",
    "\n",
    "    elif args.FL_STAGE == 2:\n",
    "        print(\"| Start FL Training Stage 2|\")\n",
    "        args.STAGE = 2\n",
    "        stage2_training(args, train_dataset, test_dataset)                      # Train Toggling Network\n",
    "        print(\"| FL Training Stage 2 Done|\")\n",
    "else:\n",
    "    extract_emb(args, train_dataset, test_dataset)\n",
    "\n",
    "print('\\n Total Run Time: {0:0.4f}'.format(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FedASR/.conda/envs/Flower-speechbrain/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading cached processed dataset at /home/FedASR/dacs/federated/src/dataset/ADReSSo/train_ADReSSo/cache-5f84b687fbc2e2ed_*_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from local...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset_addresso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/FedASR/dacs/federated/src/Debug.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 132>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m \u001b[39m# 设置要切割的等分数量\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m num_splits \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m slices \u001b[39m=\u001b[39m train_dataset_addresso\u001b[39m.\u001b[39mtrain_test_split(test_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m40\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m aaa\u001b[39m=\u001b[39mcccc\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.106/home/FedASR/dacs/federated/src/Debug.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m \u001b[39m# 将列表切割成N等分\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset_addresso' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import whisper\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ['DACS_codeRoot'] = '/home/FedASR/dacs/'\n",
    "os.environ['DACS_dataRoot'] = '/mnt/Internal/FedASR/Data/ADReSS-IS2020-data/'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2,3\"\n",
    "from utils import csv2dataset, get_dataset, average_weights, exp_details\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "def args_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # federated arguments (Notation for the arguments followed from paper)\n",
    "    parser.add_argument('--epochs', type=int, default=10,\n",
    "                        help=\"number of rounds of training\")\n",
    "    parser.add_argument('--num_users', type=int, default=100,\n",
    "                        help=\"number of users: K\")\n",
    "    parser.add_argument('--frac', type=float, default=0.1,\n",
    "                        help='the fraction of clients: C')\n",
    "    parser.add_argument('--local_ep', type=int, default=10,\n",
    "                        help=\"the number of local epochs: E\")\n",
    "    parser.add_argument('--train_batch_size', type=int, default=6, help=\"\")\n",
    "    parser.add_argument('--eval_batch_size', type=int, default=8, help=\"\")\n",
    "    # model arguments\n",
    "    parser.add_argument('--model', type=str, default='data2vec', help='model name')\n",
    "    # other arguments\n",
    "    parser.add_argument('--dataset', type=str, default='adress', help=\"name \\\n",
    "                        of dataset\")\n",
    "    parser.add_argument('--gpu', default=None, help=\"To use cuda, set \\\n",
    "                        to a specific GPU ID. Default set to use CPU.\")\n",
    "    # additional arguments\n",
    "    parser.add_argument('--pretrain_name', type=str, default='facebook/data2vec-audio-large-960h', help=\"str used to load pretrain model\")\n",
    "    parser.add_argument('-lam', '--LAMBDA', type=float, default=0.5, help=\"Lambda for GRL\")\n",
    "    parser.add_argument('-st', '--STAGE', type=int, default=1, help=\"Current training stage\")\n",
    "    parser.add_argument('-fl_st', '--FL_STAGE', type=int, default=1, help=\"Current FL training stage\")\n",
    "    parser.add_argument('-GRL', '--GRL', action='store_true', default=False, help=\"True: GRL\")\n",
    "    parser.add_argument('-model_in', '--model_in_path', type=str, default=\"./saves/wav2vec2-base-960h_GRL_0.5/checkpoint-14010/\", help=\"Where the global model is saved\")\n",
    "    parser.add_argument('-model_out', '--model_out_path', type=str, default=\"./saves/wav2vec2-base-960h_linear_GRL\", help=\"Where to save the model\")\n",
    "    parser.add_argument('-log', '--log_path', type=str, default=\"wav2vec2-base-960h_linear_GRL.txt\", help=\"name for the txt file\")\n",
    "    parser.add_argument('-csv', '--csv_path', type=str, default=\"wav2vec2-base-960h_GRL_0.5\", help=\"name for the csv file\")\n",
    "    # 2023/01/08: loss type\n",
    "    parser.add_argument('-ad_loss', '--AD_loss', type=str, default=\"cel\", help=\"loss to use for AD classifier\")\n",
    "    # 2023/01/18: ckpt\n",
    "    parser.add_argument('-ckpt', '--checkpoint', type=str, default=None, help=\"path to checkpoint\")\n",
    "    # 2023/02/13: TOGGLE_RATIO\n",
    "    parser.add_argument('-toggle_rt', '--TOGGLE_RATIO', type=float, default=0, help=\"To toggle more or less\")\n",
    "    # 2023/02/15: GS_TAU, loss weight\n",
    "    parser.add_argument('-gs_tau', '--GS_TAU', type=float, default=1, help=\"Tau for gumbel_softmax\")\n",
    "    parser.add_argument('-w_loss', '--W_LOSS', type=float, default=None, nargs='+', help=\"weight for HC and AD\")\n",
    "    # 2023/04/20\n",
    "    parser.add_argument('-EXTRACT', '--EXTRACT', action='store_true', default=False, help=\"True: extract embs\")\n",
    "    parser.add_argument('-client_id', '--client_id', type=str, default=\"public\", help=\"client_id: public, 0, or 1\")\n",
    "    # 2023/04/24\n",
    "    parser.add_argument('--global_ep', type=int, default=30, help=\"number for global model\")\n",
    "    parser.add_argument('--GPU_batchsize', type=str, default=None, help=\"如果cpu滿了就用GPU\")\n",
    "    # 2023/05/18\n",
    "    parser.add_argument('-sl', '--supervised_level', type=float, default=1, help=\"0=fully unsupervised; 0.5=unsupervised+supervised; 1=fully supervised\")\n",
    "    parser.add_argument('--num_lms', type=int, default=5, help=\"\")\n",
    "    # 2023/5/200\n",
    "    parser.add_argument('--eval_steps', type=int, default=1000, help=\"\")\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "\n",
    "args= args_parser()\n",
    "class TeacherStudentLearning:\n",
    "    def __init__(self, loadpath=None, savepath=None, load_mdl='large-v2'):\n",
    "        self.transcript = []\n",
    "        self.loadpath = loadpath\n",
    "        self.savepath = savepath\n",
    "        self.DACS_dataRoot = '/mnt/Internal/FedASR/Data/ADReSSo21/diagnosis/train'\n",
    "        out_root='/mnt/Internal/FedASR/Data/ADReSSo21/diagnosis'\n",
    "        out_dirname='transcript_whisper'\n",
    "        out_filename='train.csv'\n",
    "        self.out_file=f\"{out_root}/{out_dirname}/{out_filename}\"\n",
    "        self.model = whisper.load_model(load_mdl)\n",
    "    \n",
    "    def add_transcript_to_dataset(self, dataset, transcript_in):\n",
    "        dataset = dataset.add_column(\"text\", transcript_in)\n",
    "        return dataset\n",
    "    \n",
    "    def save_transcript(self, dataset,outFile):\n",
    "        df = pd.DataFrame(dataset)\n",
    "        df.to_csv(outFile, index=False)\n",
    "    def load_transcript(self, in_file):\n",
    "        df = pd.read_csv(in_file)\n",
    "        dataset = Dataset.from_pandas(df)\n",
    "        return dataset\n",
    "    def transcribe(self, dataset):\n",
    "        transcript=[]\n",
    "        for i,batch in tqdm(enumerate(dataset)):\n",
    "            singleFile=batch['path']\n",
    "            file=f'{self.DACS_dataRoot}/clips/{singleFile}'\n",
    "            result = self.model.transcribe(file, language=\"en\")\n",
    "            pred_text=result['text'].upper().strip()\n",
    "            print(pred_text)\n",
    "            transcript.append(pred_text)\n",
    "        return transcript\n",
    "    def transcribe_n_Merge(self, dataset):\n",
    "        transcript = self.transcribe(dataset)\n",
    "        ds=self.add_transcript_to_dataset(self, dataset, transcript)\n",
    "        return ds\n",
    "    def FilterAvailAudios(self, dataset):\n",
    "        dataset_enoughLen = dataset.filter(lambda example: len(example['array']) >= 1600, input_columns=['array'])\n",
    "        dataset_enoughLen_enoughtext = dataset.filter(lambda example: len(example['text']) >= 0, input_columns=['text'])\n",
    "        return dataset_enoughLen_enoughtext\n",
    "\n",
    "\n",
    "args.dataset = \"adresso\"                                                        # get unsupervised dataset (adresso)\n",
    "train_dataset_unsupervised, _ = get_dataset(args)                               # get dataset w.o. testing set\n",
    "\n",
    "def split_list(lst, num_parts):\n",
    "    total_samples = len(lst)\n",
    "    samples_per_part = total_samples // num_parts\n",
    "\n",
    "    # 切割成N等分的索引范围\n",
    "    indices = [(i * samples_per_part, (i + 1) * samples_per_part) for i in range(num_parts)]\n",
    "\n",
    "    # 处理最后一个部分，以处理无法整除的情况\n",
    "    last_index = num_parts * samples_per_part\n",
    "    if last_index < total_samples:\n",
    "        indices.append((last_index, total_samples))\n",
    "\n",
    "    # 建立切割的子列表\n",
    "    split_lists = []\n",
    "    for start, end in indices:\n",
    "        split_lists.append(lst[start:end])\n",
    "\n",
    "    return split_lists\n",
    "\n",
    "# 设置要切割的等分数量\n",
    "num_splits = 40\n",
    "slices = train_dataset_addresso.train_test_split(test_size=1/40)\n",
    "aaa=cccc\n",
    "# 将列表切割成N等分\n",
    "split_datasets = split_list(train_dataset_unsupervised, num_splits)\n",
    "\n",
    "ds_new=TSL.transcribe_n_Merge(self, dataset)\n",
    "\n",
    "\n",
    "\n",
    "# 創建一個 TranscriptDataset 物件\n",
    "TSL = TeacherStudentLearning()\n",
    "# transcript=TSL.transcribe(train_dataset_unsupervised)\n",
    "\n",
    "pool = multiprocessing.Pool(processes=num_splits)\n",
    "try:\n",
    "    final_result = pool.starmap_async(\n",
    "        TSL.transcribe, [(dataset)\n",
    "                    for dataset in split_datasets])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while running local_model.update_weights(): {str(e)}\")\n",
    "finally:\n",
    "    final_result.wait()\n",
    "    results = final_result.get()\n",
    "\n",
    "for idx in range(len(results)):                                             # for each participated clients\n",
    "    w, loss = results[idx]                                                  # function client_train returns w *& loss\n",
    "    if args.STAGE == 0:                                                     # train ASR\n",
    "        local_weights_en.append(copy.deepcopy(w[0]))                        # save encoder weight for this client\n",
    "        local_weights_de.append(copy.deepcopy(w[1]))                        # save decoder weight for this client\n",
    "    else:                                                                   # train AD classifier or toggling network\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "    local_losses.append(loss)\n",
    "\n",
    "\n",
    "train_dataset_addresso=TSL.add_transcript_to_dataset(train_dataset_unsupervised, transcript)\n",
    "out_root='/mnt/Internal/FedASR/Data/ADReSSo21/diagnosis'\n",
    "out_dirname='transcript_whisper'\n",
    "out_filename='train.csv'\n",
    "out_file=f\"{out_root}/{out_dirname}/{out_filename}\"\n",
    "TSL.save_transcript(train_dataset_addresso, out_file)\n",
    "in_file=out_file\n",
    "train_dataset_addresso_loaded=TSL.load_transcript(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/FedASR/dacs/federated/src/dataset/ADReSSo/train_ADReSSo/cache-5f84b687fbc2e2ed_*_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from local...\n",
      "124113\n"
     ]
    }
   ],
   "source": [
    "args.dataset = \"adresso\"                                                        # get unsupervised dataset (adresso)\n",
    "train_dataset_unsupervised, _ = get_dataset(args)                               # get dataset w.o. testing set\n",
    "print(len(train_dataset_unsupervised[0]['array']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flower-speechbrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
