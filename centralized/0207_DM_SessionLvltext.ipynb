{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=1, epochs=5, lr=2e-05, random_seed=2023, t_embed='mbert', a_embed='en', SaveRoot='/mnt/External/Seagate/FedASR/LLaMa2/dacs', file_in='/home/FedASR/dacs/centralized/saves/results/data2vec-audio-large-960h_total.csv')\n",
      "Using PyTorch Ver 2.1.1+cu121\n",
      "Fix Seed: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session S009 has no data\n",
      "Session S011 has no data\n",
      "Session S017 has no data\n",
      "Session S027 has no data\n",
      "Session S029 has no data\n",
      "Session S052 has no data\n",
      "Session S080 has no data\n",
      "Session S084 has no data\n",
      "Session S086 has no data\n",
      "Session S118 has no data\n",
      "Session S124 has no data\n",
      "Session S138 has no data\n",
      "Session S145 has no data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 540\u001b[0m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m Arg()\n\u001b[1;32m    539\u001b[0m     args\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mepochs\n\u001b[0;32m--> 540\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m       \n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03mpython 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed en\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m \n\u001b[1;32m    552\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[55], line 486\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args, config)\u001b[0m\n\u001b[1;32m    483\u001b[0m seed_everything( config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_seed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    485\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(args,config) \n\u001b[0;32m--> 486\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m early_stop_callback \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m    489\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    490\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    493\u001b[0m )\n\u001b[1;32m    495\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m    496\u001b[0m     dirpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSaveRoot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Model/checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    497\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m     save_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    502\u001b[0m   )    \n",
      "Cell \u001b[0;32mIn[55], line 306\u001b[0m, in \u001b[0;36mModel.preprocess_dataframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data \u001b[38;5;241m=\u001b[39m TensorDataset(\n\u001b[1;32m    291\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(df_train[t_col_name]\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# torch.tensor(df_train[a_col_name].tolist(), dtype=torch.float),\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(df_train[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_cols]\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[1;32m    294\u001b[0m )\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data \u001b[38;5;241m=\u001b[39m TensorDataset(\n\u001b[1;32m    297\u001b[0m      torch\u001b[38;5;241m.\u001b[39mtensor(df_val[t_col_name]\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m#  torch.tensor(df_val[a_col_name].tolist(), dtype=torch.float),\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(df_val[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_cols]\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[1;32m    300\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data \u001b[38;5;241m=\u001b[39m TensorDataset(\n\u001b[1;32m    303\u001b[0m      torch\u001b[38;5;241m.\u001b[39mtensor(df_test[t_col_name]\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;66;03m#  torch.tensor(df_test[a_col_name].tolist(), dtype=torch.float),\u001b[39;00m\n\u001b[1;32m    305\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(df_test[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_cols]\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[0;32m--> 306\u001b[0m      \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    307\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# torch:\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor\n",
    "from transformers import BertTokenizer, BertConfig, BertModel,XLMTokenizer, XLMModel\n",
    "from prompts import assesmentPrompt_template, Instruction_templates, Psychology_template,\\\n",
    "    Sensitive_replace_dict, generate_psychology_prompt\n",
    "class Arg:\n",
    "    version = 1\n",
    "    # data\n",
    "    epochs: int = 5  # Max Epochs, BERT paper setting [3,4,5]\n",
    "    max_length: int = 350  # Max Length input size\n",
    "    report_cycle: int = 30  # Report (Train Metrics) Cycle\n",
    "    cpu_workers: int = os.cpu_count()  # Multi cpu workers\n",
    "    test_mode: bool = False  # Test Mode enables `fast_dev_run`\n",
    "    optimizer: str = 'AdamW'  # AdamW vs AdamP\n",
    "    lr_scheduler: str = 'exp'  # ExponentialLR vs CosineAnnealingWarmRestarts\n",
    "    fp16: bool = False  # Enable train on FP16\n",
    "    a_hidden_size = 0 # BERT-base: 768, BERT-large: 1024, BERT paper setting\n",
    "    t_hidden_size = 768\n",
    "    t_x_hidden_size = a_hidden_size+t_hidden_size\n",
    "    batch_size: int = 8\n",
    "            \n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "    \n",
    "    \n",
    "class Model(LightningModule):\n",
    "    def __init__(self, args,config):\n",
    "        super().__init__()\n",
    "        # config:\n",
    "        \n",
    "        self.args = args\n",
    "        self.config = config\n",
    "        self.batch_size = self.args.batch_size\n",
    "        \n",
    "        # meta data:\n",
    "        self.epochs_index = 0\n",
    "        self.label_cols = 'dementia_labels'\n",
    "        self.label_names = ['Control','ProbableAD']\n",
    "        self.num_labels = 2\n",
    "        self.t_embed_type = self.config['t_embed']\n",
    "        self.a_embed_type = self.config['a_embed']\n",
    "        self.a_hidden = self.args.a_hidden_size\n",
    "        \n",
    "        # --> HERE STEP 1 <--\n",
    "        # ATTRIBUTES TO SAVE BATCH OUTPUTS\n",
    "        self.test_step_outputs = []   # save outputs in each batch to compute metric overall epoch\n",
    "        self.test_step_targets = []   # save targets in each batch to compute metric overall epoch\n",
    "        self.val_step_outputs = []        # save outputs in each batch to compute metric overall epoch\n",
    "        self.val_step_targets = []        # save targets in each batch to compute metric overall epoch\n",
    "\n",
    "\n",
    "        if self.t_embed_type == \"mbert\":\n",
    "            self.t_hidden = self.args.t_hidden_size\n",
    "            \n",
    "            t_pretrained = 'bert-base-multilingual-uncased'\n",
    "            self.t_tokenizer = BertTokenizer.from_pretrained(t_pretrained)\n",
    "            self.t_model = BertModel.from_pretrained(t_pretrained)\n",
    "            \n",
    "            \n",
    "        elif self.t_embed_type == \"xlm\":\n",
    "            self.t_hidden = self.args.t_x_hidden_size\n",
    "            \n",
    "            t_pretrained = 'xlm-mlm-100-1280'\n",
    "            self.t_tokenizer = XLMTokenizer.from_pretrained(t_pretrained)\n",
    "            self.t_model = XLMModel.from_pretrained(t_pretrained)\n",
    "            self.pooler = BertPooler(self.t_hidden)\n",
    "            \n",
    "        self.hidden = int(self.a_hidden + self.t_hidden)\n",
    "        \n",
    "        if self.a_embed_type == \"en\":\n",
    "            a_pretrained =  \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
    "            \n",
    "        elif self.a_embed_type == \"gr\":\n",
    "            a_pretrained =  \"lighteternal/wav2vec2-large-xlsr-53-greek\"\n",
    "\n",
    "        elif self.a_embed_type == \"multi\":\n",
    "            a_pretrained = \"voidful/wav2vec2-xlsr-multilingual-56\"\n",
    "            \n",
    "        elif self.a_embed_type == \"wv\":\n",
    "            a_pretrained ='facebook/wav2vec2-base'\n",
    "            \n",
    "        self.a_tokenizer = Wav2Vec2FeatureExtractor.from_pretrained(a_pretrained)\n",
    "        self.a_model = Wav2Vec2Model.from_pretrained(a_pretrained)\n",
    "        \n",
    "        \n",
    "        self.clf1 = nn.Linear(self.hidden, int(self.hidden/2))\n",
    "        self.clf2 = nn.Linear(int(self.hidden/2), self.num_labels)\n",
    "        \n",
    "            \n",
    "            \n",
    "    # def forward(self, text, audio):\n",
    "    def forward(self, text):\n",
    "        \n",
    "        if self.t_embed_type == \"mbert\":\n",
    "            t_out = self.t_model(text)[1] \n",
    "\n",
    "            \n",
    "        elif self.t_embed_type == \"xlm\":\n",
    "            t_out = self.t_model(text)[0]\n",
    "            t_out = self.pooler(t_out)\n",
    "            \n",
    "            \n",
    "        # a_out = self.a_model(audio)['extract_features']#[2] #last_hidden_state , feature extraction\n",
    "        # a_out = a_out[:, 0, :] \n",
    "        \n",
    "        #print(a_out)\n",
    "        #print(a_out['extract_features'].shape) # ([8, 437, 512])\n",
    "        #print(a_out['last_hidden_state'].shape) # ([8, 437, 1024]) => pooling 필요\n",
    "        \n",
    "        \n",
    "        # output = torch.cat((t_out,a_out),axis=1)   \n",
    "        output = t_out\n",
    "        #print(output.shape)\n",
    "        \n",
    "        logits = self.clf2(self.clf1(output))\n",
    "    \n",
    "        return logits\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.config['lr'])\n",
    "        scheduler = ExponentialLR(optimizer, gamma=0.5)\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "        }\n",
    "\n",
    "    def preprocess_dataframe(self):\n",
    "        \n",
    "        tg_sr = 16000\n",
    "        t_col_name = \"text\" \n",
    "        # a_col_name = \"path\"         \n",
    "        # df = pd.read_json('/mnt/Internal/FedASR/Data/230126_total_asr_data.json')\n",
    "        df = pd.read_csv(config.file_in)\n",
    "\n",
    "        def Augment_info_df(df_test):\n",
    "            # 將 'path' 欄位進行字串操作\n",
    "            df_test['path'] = df_test['path'].str.rstrip('.wav')\n",
    "\n",
    "            # 使用 str.split 拆分 'path' 欄位\n",
    "            df_test[['session', 'role', 'number', 'start_time', 'end_time']] = df_test['path'].str.split('_', expand=True)\n",
    "\n",
    "            # 如果 'number' 欄位的末尾包含 '.wav'，進行一次額外的拆分\n",
    "            df_test['number'] = df_test['number'].str.rstrip('.wav')\n",
    "\n",
    "            # 將 'start_time' 和 'end_time' 欄位轉換為數值型別\n",
    "            df_test[['start_time', 'end_time']] = df_test[['start_time', 'end_time']].astype(int)\n",
    "\n",
    "            return df_test\n",
    "        df = Augment_info_df(df)\n",
    "\n",
    "\n",
    "        # Packer\n",
    "        def Packer(df_test) -> dict:\n",
    "            People_dict = dict(tuple(df_test.groupby('session')))\n",
    "            return People_dict\n",
    "\n",
    "        def Dialogueturn2corpus(data_frame, mode='text'): #mode can be 'pred_str' or 'text'\n",
    "            # 按 'start_time' 列進行排序\n",
    "            sorted_data_frame = data_frame.sort_values(by='start_time')\n",
    "\n",
    "            # 添加前綴並使用 '\\n' 進行拼接\n",
    "            processed_text = sorted_data_frame.apply(lambda row: f\"{row['role']}: {row[mode]}\", axis=1).str.cat(sep='\\n')\n",
    "\n",
    "            return processed_text\n",
    "\n",
    "        def filter_people_dict(People_dict, mode=\"INV+PAR\", verbose=False) -> dict:# 'INV' , 'PAR', 'INV+PAR'\n",
    "            filtered_people_dict = {}\n",
    "\n",
    "            for session, data_frame in People_dict.items():\n",
    "                # 使用 query 過濾 'role' 為 'INV' 或 'PAR'\n",
    "                if mode == \"PAR\":\n",
    "                    filtered_data_frame = data_frame.query(\"role == 'PAR'\")\n",
    "                    filtered_people_dict[session] = filtered_data_frame\n",
    "                elif mode == \"INV\":\n",
    "                    filtered_data_frame = data_frame.query(\"role == 'INV'\")\n",
    "                    filtered_people_dict[session] = filtered_data_frame\n",
    "                elif mode == \"INV+PAR\":\n",
    "                    filtered_people_dict[session] = data_frame\n",
    "                else:\n",
    "                    raise OSError\n",
    "            \n",
    "            if verbose:\n",
    "                # 印出過濾後的 People_dict 中每個 session 的 DataFrame\n",
    "                for session, data_frame in filtered_people_dict.items():\n",
    "                    print(f\"Session: {session}\")\n",
    "                    print(data_frame)\n",
    "                    print(\"\\n\")\n",
    "\n",
    "            return filtered_people_dict\n",
    "\n",
    "        # Dialogue Formatter\n",
    "        def Dialogue_Formatter(People_dict, sep=\"\\n\",role_mode='PAR')->dict:\n",
    "            session_df=pd.DataFrame()\n",
    "            for session, data_frame in People_dict.items():\n",
    "                if len(data_frame)>0:\n",
    "                    total_info=data_frame.iloc[0].copy()\n",
    "                    sessional_text = Dialogueturn2corpus(data_frame,mode='text')\n",
    "                    sessional_predStr = Dialogueturn2corpus(data_frame,mode='pred_str')\n",
    "                    \n",
    "                    # total_info,'text']=sessional_text\n",
    "                    # session_df.loc[session,'pred_str']=sessional_predStr\n",
    "                    # session_df.loc[session,'role']=role_mode\n",
    "                    # session_df.loc[session,'start_time']=data_frame['start_time'].min()\n",
    "                    # session_df.loc[session,'end_time']=data_frame['end_time'].max()\n",
    "\n",
    "                    total_info['text']=sessional_text\n",
    "                    total_info['pred_str']=sessional_predStr\n",
    "                    total_info['role']=role_mode\n",
    "                    total_info['start_time']=data_frame['start_time'].min()\n",
    "                    total_info['end_time']=data_frame['end_time'].max()\n",
    "                    session_df = pd.concat([session_df, pd.DataFrame([total_info], index=[session])])\n",
    "                else:\n",
    "                    print(f\"Session {session} has no data\")\n",
    "            return session_df\n",
    "        df_train = df[df['ex'] == 'train']\n",
    "        df_val = df[df['ex'] == 'dev']\n",
    "        df_test = df[df['ex'] == 'test']\n",
    "\n",
    "        def SentenceLvldf2SessionLvldf(df, role_mode=\"PAR\"):\n",
    "            People_dict=Packer(df)\n",
    "            People_dict = filter_people_dict(People_dict, mode=role_mode, verbose=False)\n",
    "            df_dialogue=Dialogue_Formatter(People_dict,role_mode)\n",
    "            return df_dialogue\n",
    "\n",
    "        df_train=SentenceLvldf2SessionLvldf(df_train)\n",
    "        df_val=SentenceLvldf2SessionLvldf(df_val)\n",
    "        df_test=SentenceLvldf2SessionLvldf(df_test)\n",
    "\n",
    "        def Tokenize(df_data):\n",
    "            df_data[t_col_name] = df_data[t_col_name].map(lambda x: self.t_tokenizer.encode(\n",
    "                str(x),\n",
    "                padding = 'max_length',\n",
    "                max_length=self.args.max_length,\n",
    "                truncation=True,\n",
    "                ))\n",
    "            return df_data\n",
    "        df_train=Tokenize(df_train)\n",
    "        df_val=Tokenize(df_val)\n",
    "        df_test=Tokenize(df_test)\n",
    "        df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "        # audio_root=\"/mnt/Internal/FedASR/Data/ADReSS-IS2020-data/clips\"\n",
    "        # # 원래 길이: 562992, batch 16: 90000, batch 8: 140000\n",
    "        # # max_length=16000, truncation=True 이건 일단 돌려보고 결정 => 뒤쪽, 앞에쪽 뭐보면 좋을 지 그런거 check하면 좋으니까! \n",
    "        # df[a_col_name] = df[a_col_name].map(lambda x: self.a_tokenizer(\n",
    "        #     f\"{audio_root}/{x}\",\n",
    "        #     sampling_rate = tg_sr,\n",
    "        #     max_length=100000, \n",
    "        #     truncation=True\n",
    "        #     )['input_values'][0])\n",
    "\n",
    "        self.train_data = TensorDataset(\n",
    "            torch.tensor(df_train[t_col_name].tolist(), dtype=torch.long),\n",
    "            # torch.tensor(df_train[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_train[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "        \n",
    "        self.val_data = TensorDataset(\n",
    "             torch.tensor(df_val[t_col_name].tolist(), dtype=torch.long),\n",
    "            #  torch.tensor(df_val[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_val[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        self.test_data = TensorDataset(\n",
    "             torch.tensor(df_test[t_col_name].tolist(), dtype=torch.long),\n",
    "            #  torch.tensor(df_test[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_test[self.label_cols].tolist(), dtype=torch.long),\n",
    "             torch.tensor(df_test.index.tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        return DataLoader(\n",
    "            self.train_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.args.cpu_workers,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "\n",
    "        return DataLoader(\n",
    "            self.val_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.args.cpu_workers,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "\n",
    "        return DataLoader(\n",
    "            self.test_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.args.cpu_workers,\n",
    "        )\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # token, audio, labels = batch  \n",
    "        token,  labels = batch  \n",
    "        # logits = self(token, audio) \n",
    "        logits = self(token) \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)   \n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # token, audio, labels = batch  \n",
    "        token, labels = batch  \n",
    "        # logits = self(token, audio) \n",
    "        logits = self(token) \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)     \n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true = list(labels.cpu().numpy())\n",
    "        y_pred = list(preds.cpu().numpy())\n",
    "\n",
    "        # --> HERE STEP 2 <--\n",
    "        self.val_step_outputs.append({\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        })\n",
    "        # self.val_step_targets.append(y_true)\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "        \n",
    "            \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # token, audio, labels,id_ = batch \n",
    "        token, labels,id_ = batch \n",
    "        print('id', id_)\n",
    "        # logits = self(token, audio) \n",
    "        logits = self(token) \n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true = list(labels.cpu().numpy())\n",
    "        y_pred = list(preds.cpu().numpy())\n",
    "\n",
    "        # --> HERE STEP 2 <--\n",
    "        self.test_step_outputs.append({\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        })\n",
    "        # self.test_step_targets.append(y_true)\n",
    "        return {\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = torch.tensor(0, dtype=torch.float)\n",
    "        # print(\"Value= \",self.val_step_outputs)\n",
    "        # print(\"type(self.val_step_outputs)=\",type(self.val_step_outputs))\n",
    "        # print(\"type(self.val_step_outputs[0])=\",type(self.val_step_outputs[0]))\n",
    "        # print(\"type(self.val_step_outputs[0] loss)=\",type(self.val_step_outputs[0]['loss']))\n",
    "        for i in self.val_step_outputs:\n",
    "            loss += i['loss'].cpu().detach()\n",
    "        _loss = loss / len(self.val_step_outputs)\n",
    "        loss = float(_loss)\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in self.val_step_outputs:\n",
    "            y_true += i['y_true']\n",
    "            y_pred += i['y_pred']\n",
    "            \n",
    "        y_pred = np.asanyarray(y_pred)#y_temp_pred y_pred\n",
    "        y_true = np.asanyarray(y_true)\n",
    "        \n",
    "        pred_dict = {}\n",
    "        pred_dict['y_pred']= y_pred\n",
    "        pred_dict['y_true']= y_true\n",
    "        \n",
    "        val_acc = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "        \n",
    "        self.log(\"val_acc\", val_acc)\n",
    "        # print(\"y_pred= \", y_pred)\n",
    "        # print('\\n\\n\\n')\n",
    "        # print(\"y_true= \", y_true)\n",
    "        # print('\\n\\n\\n')\n",
    "        print(\"-------val_report-------\")\n",
    "        metrics_dict = classification_report(y_true, y_pred,zero_division=1,\n",
    "                                             target_names = self.label_names, \n",
    "                                             output_dict=True)\n",
    "        df_result = pd.DataFrame(metrics_dict).transpose()\n",
    "        pprint(df_result)\n",
    "        \n",
    "        Output_dir=f\"{SaveRoot}/result\"\n",
    "        os.makedirs(Output_dir, exist_ok=True)\n",
    "        df_result.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_val.csv')\n",
    "\n",
    "        pred_df = pd.DataFrame(pred_dict)\n",
    "        pred_df.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_val_pred.csv')\n",
    "        self.val_step_outputs.clear()\n",
    "        # self.val_step_targets.clear()\n",
    "        return {'loss': _loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in self.test_step_outputs:\n",
    "            y_true += i['y_true']\n",
    "            y_pred += i['y_pred']\n",
    "            \n",
    "        y_pred = np.asanyarray(y_pred)#y_temp_pred y_pred\n",
    "        y_true = np.asanyarray(y_true)\n",
    "        \n",
    "        pred_dict = {}\n",
    "        pred_dict['y_pred']= y_pred\n",
    "        pred_dict['y_true']= y_true\n",
    "        \n",
    "        \n",
    "        print(\"-------test_report-------\")\n",
    "        metrics_dict = classification_report(y_true, y_pred,zero_division=1,\n",
    "                                             target_names = self.label_names, \n",
    "                                             output_dict=True)\n",
    "        df_result = pd.DataFrame(metrics_dict).transpose()\n",
    "        self.test_step_outputs.clear()\n",
    "        # self.test_step_targets.clear()\n",
    "        pprint(df_result)\n",
    "        \n",
    "        Output_dir=f\"{SaveRoot}/result\"\n",
    "        os.makedirs(Output_dir, exist_ok=True)\n",
    "        df_result.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_test.csv')\n",
    "\n",
    "        pred_df = pd.DataFrame(pred_dict)\n",
    "        pred_df.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_test_pred.csv')\n",
    "\n",
    "    \n",
    "def main(args,config):\n",
    "    print(\"Using PyTorch Ver\", torch.__version__)\n",
    "    print(\"Fix Seed:\", config['random_seed'])\n",
    "    seed_everything( config['random_seed'])\n",
    "        \n",
    "    model = Model(args,config) \n",
    "    model.preprocess_dataframe()\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=f\"{SaveRoot}/Model/checkpoints\",\n",
    "        monitor='val_acc',\n",
    "        auto_insert_metric_name=True,\n",
    "        verbose=True,\n",
    "        mode='max', \n",
    "        save_top_k=1,\n",
    "      )    \n",
    "\n",
    "    print(\":: Start Training ::\")\n",
    "    #     \n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        callbacks=[early_stop_callback,checkpoint_callback],\n",
    "        enable_checkpointing = True,\n",
    "        max_epochs=args.epochs,\n",
    "        fast_dev_run=args.test_mode,\n",
    "        num_sanity_val_steps=None if args.test_mode else 0,\n",
    "        deterministic=True, # ensure full reproducibility from run to run you need to set seeds for pseudo-random generators,\n",
    "        # For GPU Setup\n",
    "        # gpus=[config['gpu']] if torch.cuda.is_available() else None,\n",
    "        precision=16 if args.fp16 else 32\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model,dataloaders=model.test_dataloader(),ckpt_path=\"best\")\n",
    "    \n",
    "if __name__ == '__main__': \n",
    "\n",
    "    parser = argparse.ArgumentParser(\"main.py\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\"--gpu\", type=int, default=1)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=5)\n",
    "    parser.add_argument(\"--lr\", type=float, default=2e-5, help=\"learning rate\")\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=2023) \n",
    "    parser.add_argument(\"--t_embed\", type=str, default=\"mbert\") \n",
    "    parser.add_argument(\"--a_embed\", type=str, default=\"en\") \n",
    "    parser.add_argument(\"--SaveRoot\", type=str, default='/mnt/External/Seagate/FedASR/LLaMa2/dacs') \n",
    "    parser.add_argument(\"--file_in\", type=str, default='/home/FedASR/dacs/centralized/saves/results/data2vec-audio-large-960h_total.csv') \n",
    "    \n",
    "    \n",
    "    config = parser.parse_args(args=[])\n",
    "    SaveRoot=config.SaveRoot\n",
    "    \n",
    "    print(config)\n",
    "    args = Arg()\n",
    "    args.epochs=config.epochs\n",
    "    main(args,config.__dict__)       \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed en\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed xlm --a_embed en\n",
    "\n",
    "# don\n",
    "python 0207_DM_multi.py --gpu 0 --t_embed xlm --a_embed gr\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed gr\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session S009 has no data\n",
      "Session S011 has no data\n",
      "Session S017 has no data\n",
      "Session S027 has no data\n",
      "Session S029 has no data\n",
      "Session S052 has no data\n",
      "Session S080 has no data\n",
      "Session S084 has no data\n",
      "Session S086 has no data\n",
      "Session S118 has no data\n",
      "Session S124 has no data\n",
      "Session S138 has no data\n",
      "Session S145 has no data\n",
      "# of train:108, val:73, test:48\n"
     ]
    }
   ],
   "source": [
    "args = Arg()\n",
    "model = Model(args,config.__dict__) \n",
    "self=model\n",
    "tg_sr = 16000\n",
    "t_col_name = \"text\" \n",
    "# a_col_name = \"path\"         \n",
    "# df = pd.read_json('/mnt/Internal/FedASR/Data/230126_total_asr_data.json')\n",
    "df = pd.read_csv(config.file_in)\n",
    "\n",
    "def Augment_info_df(df_test):\n",
    "    # 將 'path' 欄位進行字串操作\n",
    "    df_test['path'] = df_test['path'].str.rstrip('.wav')\n",
    "\n",
    "    # 使用 str.split 拆分 'path' 欄位\n",
    "    df_test[['session', 'role', 'number', 'start_time', 'end_time']] = df_test['path'].str.split('_', expand=True)\n",
    "\n",
    "    # 如果 'number' 欄位的末尾包含 '.wav'，進行一次額外的拆分\n",
    "    df_test['number'] = df_test['number'].str.rstrip('.wav')\n",
    "\n",
    "    # 將 'start_time' 和 'end_time' 欄位轉換為數值型別\n",
    "    df_test[['start_time', 'end_time']] = df_test[['start_time', 'end_time']].astype(int)\n",
    "\n",
    "    return df_test\n",
    "df = Augment_info_df(df)\n",
    "\n",
    "\n",
    "# Packer\n",
    "def Packer(df_test) -> dict:\n",
    "    People_dict = dict(tuple(df_test.groupby('session')))\n",
    "    return People_dict\n",
    "\n",
    "def Dialogueturn2corpus(data_frame, mode='text'): #mode can be 'pred_str' or 'text'\n",
    "    # 按 'start_time' 列進行排序\n",
    "    sorted_data_frame = data_frame.sort_values(by='start_time')\n",
    "\n",
    "    # 添加前綴並使用 '\\n' 進行拼接\n",
    "    processed_text = sorted_data_frame.apply(lambda row: f\"{row['role']}: {row[mode]}\", axis=1).str.cat(sep='\\n')\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "def filter_people_dict(People_dict, mode=\"INV+PAR\", verbose=False) -> dict:# 'INV' , 'PAR', 'INV+PAR'\n",
    "    filtered_people_dict = {}\n",
    "\n",
    "    for session, data_frame in People_dict.items():\n",
    "        # 使用 query 過濾 'role' 為 'INV' 或 'PAR'\n",
    "        if mode == \"PAR\":\n",
    "            filtered_data_frame = data_frame.query(\"role == 'PAR'\")\n",
    "            filtered_people_dict[session] = filtered_data_frame\n",
    "        elif mode == \"INV\":\n",
    "            filtered_data_frame = data_frame.query(\"role == 'INV'\")\n",
    "            filtered_people_dict[session] = filtered_data_frame\n",
    "        elif mode == \"INV+PAR\":\n",
    "            filtered_people_dict[session] = data_frame\n",
    "        else:\n",
    "            raise OSError\n",
    "    \n",
    "    if verbose:\n",
    "        # 印出過濾後的 People_dict 中每個 session 的 DataFrame\n",
    "        for session, data_frame in filtered_people_dict.items():\n",
    "            print(f\"Session: {session}\")\n",
    "            print(data_frame)\n",
    "            print(\"\\n\")\n",
    "\n",
    "    return filtered_people_dict\n",
    "\n",
    "# Dialogue Formatter\n",
    "def Dialogue_Formatter(People_dict, sep=\"\\n\",role_mode='PAR')->dict:\n",
    "    session_df=pd.DataFrame()\n",
    "    for session, data_frame in People_dict.items():\n",
    "        if len(data_frame)>0:\n",
    "            total_info=data_frame.iloc[0].copy()\n",
    "            sessional_text = Dialogueturn2corpus(data_frame,mode='text')\n",
    "            sessional_predStr = Dialogueturn2corpus(data_frame,mode='pred_str')\n",
    "            \n",
    "            # total_info,'text']=sessional_text\n",
    "            # session_df.loc[session,'pred_str']=sessional_predStr\n",
    "            # session_df.loc[session,'role']=role_mode\n",
    "            # session_df.loc[session,'start_time']=data_frame['start_time'].min()\n",
    "            # session_df.loc[session,'end_time']=data_frame['end_time'].max()\n",
    "\n",
    "            total_info['text']=sessional_text\n",
    "            total_info['pred_str']=sessional_predStr\n",
    "            total_info['role']=role_mode\n",
    "            total_info['start_time']=data_frame['start_time'].min()\n",
    "            total_info['end_time']=data_frame['end_time'].max()\n",
    "            session_df = pd.concat([session_df, pd.DataFrame([total_info], index=[session])])\n",
    "        else:\n",
    "            print(f\"Session {session} has no data\")\n",
    "    return session_df\n",
    "df_train = df[df['ex'] == 'train']\n",
    "df_val = df[df['ex'] == 'dev']\n",
    "df_test = df[df['ex'] == 'test']\n",
    "\n",
    "def SentenceLvldf2SessionLvldf(df, role_mode=\"PAR\"):\n",
    "    People_dict=Packer(df)\n",
    "    People_dict = filter_people_dict(People_dict, mode=role_mode, verbose=False)\n",
    "    df_dialogue=Dialogue_Formatter(People_dict,role_mode)\n",
    "    return df_dialogue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_train=SentenceLvldf2SessionLvldf(df_train)\n",
    "df_val=SentenceLvldf2SessionLvldf(df_val)\n",
    "df_test=SentenceLvldf2SessionLvldf(df_test)\n",
    "\n",
    "def Tokenize(df_data):\n",
    "    df_data[t_col_name] = df_data[t_col_name].map(lambda x: self.t_tokenizer.encode(\n",
    "        str(x),\n",
    "        padding = 'max_length',\n",
    "        max_length=self.args.max_length,\n",
    "        truncation=True,\n",
    "        ))\n",
    "    return df_data\n",
    "df_train=Tokenize(df_train)\n",
    "df_val=Tokenize(df_val)\n",
    "df_test=Tokenize(df_test)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# audio_root=\"/mnt/Internal/FedASR/Data/ADReSS-IS2020-data/clips\"\n",
    "# # 원래 길이: 562992, batch 16: 90000, batch 8: 140000\n",
    "# # max_length=16000, truncation=True 이건 일단 돌려보고 결정 => 뒤쪽, 앞에쪽 뭐보면 좋을 지 그런거 check하면 좋으니까! \n",
    "# df[a_col_name] = df[a_col_name].map(lambda x: self.a_tokenizer(\n",
    "#     f\"{audio_root}/{x}\",\n",
    "#     sampling_rate = tg_sr,\n",
    "#     max_length=100000, \n",
    "#     truncation=True\n",
    "#     )['input_values'][0])\n",
    "\n",
    "\n",
    "\n",
    "print(f'# of train:{len(df_train)}, val:{len(df_val)}, test:{len(df_test)}')\n",
    "\n",
    "\n",
    "self.train_data = TensorDataset(\n",
    "    torch.tensor(df_train[t_col_name].tolist(), dtype=torch.long),\n",
    "    # torch.tensor(df_train[a_col_name].tolist(), dtype=torch.float),\n",
    "    torch.tensor(df_train[self.label_cols].tolist(), dtype=torch.long),\n",
    ")\n",
    "\n",
    "self.val_data = TensorDataset(\n",
    "        torch.tensor(df_val[t_col_name].tolist(), dtype=torch.long),\n",
    "    #  torch.tensor(df_val[a_col_name].tolist(), dtype=torch.float),\n",
    "    torch.tensor(df_val[self.label_cols].tolist(), dtype=torch.long),\n",
    ")\n",
    "\n",
    "self.test_data = TensorDataset(\n",
    "        torch.tensor(df_test[t_col_name].tolist(), dtype=torch.long),\n",
    "    #  torch.tensor(df_test[a_col_name].tolist(), dtype=torch.float),\n",
    "    torch.tensor(df_test[self.label_cols].tolist(), dtype=torch.long),\n",
    "        torch.tensor(df_test.index.tolist(), dtype=torch.long),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
