{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from addict import Dict\n",
    "import argparse \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-hyperparemeter','--top_k', type=int, default=5, help=\"\")\n",
    "parser.add_argument('--summary_dir_in', type=str, default=\"/mnt/External/Seagate/FedASR/LLaMa2/dacs/EmbFeats/Lexical/Embeddings/text_data2vec-audio-large-960h_Phych-anomia\", help=\"\")\n",
    "args = parser.parse_args(args=[])\n",
    "top_k=args.top_k\n",
    "\n",
    "df_train = pd.read_pickle(f\"{args.summary_dir_in}/train.pkl\")\n",
    "df_val = pd.read_pickle(f\"{args.summary_dir_in}/dev.pkl\")\n",
    "df_test = pd.read_pickle(f\"{args.summary_dir_in}/test.pkl\")\n",
    "\n",
    "\n",
    "class FindTopK_class:\n",
    "    def __init__(self, method=1, top_n=5):\n",
    "        self.method=method\n",
    "        self.similarity='cosine_similarity'\n",
    "        # self.similarity='distance'\n",
    "        self.relatedness_fn=lambda x, y: cosine_similarity(x, y) if self.similarity=='cosine_similarity' else lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "        self.top_n=top_n\n",
    "        if method==1:\n",
    "            self.prompt_template = \"{text}\"\n",
    "        elif method == 2:\n",
    "            self.prompt_template = \"This sentence: {text} means in one word:\"\n",
    "        \n",
    "        self.df_dictionary=None\n",
    "    def update_dictionary(self,df_train,selected_cols=['session','Psych_Summary','Embedding']):\n",
    "        self.df_dictionary=df_train[selected_cols]\n",
    "    def query(self, sentence_embeddings,top_n=None):\n",
    "        if self.similarity=='cosine_similarity' :\n",
    "            strings_and_relatednesses = [\n",
    "                (row[\"session\"], self.relatedness_fn(np.array(sentence_embeddings).reshape(1,-1), np.array(row[\"Embedding\"]).reshape(1,-1)))\n",
    "                for i, row in self.df_dictionary.iterrows()\n",
    "            ]\n",
    "        else:\n",
    "            strings_and_relatednesses = [\n",
    "                (row[\"session\"], self.relatedness_fn(sentence_embeddings.squeeze(0), row[\"Embedding\"].squeeze(0)))\n",
    "                for i, row in self.df_dictionary.iterrows()\n",
    "            ]\n",
    "\n",
    "        strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "\n",
    "        Rank_df = pd.DataFrame({\n",
    "            \"session\": self.df_dictionary[\"session\"],\n",
    "            \"relatedness\": relatednesses\n",
    "        })\n",
    "        if type(top_n)!=int:\n",
    "            return Rank_df\n",
    "        else:\n",
    "            strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "            strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "            print(\"Top5: \",strings[:self.top_n])\n",
    "            return strings[:self.top_n]\n",
    "def ConstructCompareBase(df_train):\n",
    "    Similar_finder=FindTopK_class()\n",
    "    Similar_finder.update_dictionary(df_train)\n",
    "    return Similar_finder\n",
    "\n",
    "Similar_finder=ConstructCompareBase(df_train)\n",
    "\n",
    "# df_data=df_train\n",
    "# if 'Similarity_Emb' not in df_data.columns and 'Similarity_IDs' not in df_data.columns:\n",
    "#     Similarity_Emb_dict={}\n",
    "#     Similarity_IDs_dict={}\n",
    "#     for session, row in df_data.iterrows():\n",
    "#         top_relate=Similar_finder.query(row['Embedding'])\n",
    "#         top_k_relate=top_relate.sort_values(by='relatedness', ascending=False).iloc[:top_k]\n",
    "#         top_k_relate_indexes=list(top_k_relate.index)\n",
    "\n",
    "#         average_Emb=np.mean(np.vstack(df_train.loc[top_k_relate_indexes,'Embedding']),axis=0)\n",
    "#         topk_related_ID=\"/\".join(top_k_relate_indexes)\n",
    "\n",
    "#         # df_data.loc[i,'Similarity_Emb']=average_Emb\n",
    "#         # df_data.loc[i,'Similarity_IDs']=topk_related_ID\n",
    "#         Similarity_Emb_dict[session]=average_Emb\n",
    "#         Similarity_IDs_dict[session]=topk_related_ID\n",
    "#     df_data['Similarity_Emb'] = df_data.index.to_series().apply(lambda x: Similarity_Emb_dict.get(x, []))\n",
    "#     df_data['Similarity_IDs'] = df_data.index.to_series().apply(lambda x: Similarity_IDs_dict.get(x, []))\n",
    "\n",
    "def Extend_similarity_Emb(df_data, df_train, top_k=5):\n",
    "    if 'Similarity_Emb' not in df_data.columns and 'Similarity_IDs' not in df_data.columns:\n",
    "        Similarity_Emb_dict={}\n",
    "        Similarity_IDs_dict={}\n",
    "        for session, row in df_data.iterrows():\n",
    "            top_relate = Similar_finder.query(row['Embedding'])\n",
    "            top_k_relate = top_relate.sort_values(by='relatedness', ascending=False).iloc[:top_k]\n",
    "            top_k_relate_indexes = list(top_k_relate.index)\n",
    "\n",
    "            average_Emb = np.mean(np.vstack(df_train.loc[top_k_relate_indexes, 'Embedding']), axis=0)\n",
    "            topk_related_ID = \"/\".join(top_k_relate_indexes)\n",
    "\n",
    "            \n",
    "            Similarity_Emb_dict[session]=average_Emb\n",
    "            Similarity_IDs_dict[session]=topk_related_ID\n",
    "        df_data['Similarity_Emb'] = df_data.index.to_series().apply(lambda x: Similarity_Emb_dict.get(x, []))\n",
    "        df_data['Similarity_IDs'] = df_data.index.to_series().apply(lambda x: Similarity_IDs_dict.get(x, []))\n",
    "    return df_data\n",
    "df_train=Extend_similarity_Emb(df_train, df_train, top_k=5)\n",
    "df_test=Extend_similarity_Emb(df_test, df_train, top_k=5)\n",
    "df_val=Extend_similarity_Emb(df_val, df_train, top_k=5)\n",
    "\n",
    "pd.to_pickle(df_train,f\"{args.summary_dir_in}/train.pkl\")\n",
    "pd.to_pickle(df_val,f\"{args.summary_dir_in}/dev.pkl\")\n",
    "pd.to_pickle(df_test,f\"{args.summary_dir_in}/test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
