{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=1, epochs=1, lr=2e-05, random_seed=2023, t_embed='mbert', a_embed='en', SaveRoot='/mnt/External/Seagate/FedASR/LLaMa2/dacs', file_in='/home/FedASR/dacs/centralized/saves/results/data2vec-audio-large-960h_total.csv', process_summary=False, summary_dir_in='/mnt/External/Seagate/FedASR/LLaMa2/dacs/EmbFeats/Lexical/Embeddings/text_data2vec-audio-large-960h_Phych-anomia')\n",
      "Using PyTorch Ver 2.1.1+cu121\n",
      "Fix Seed: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Trainer will use only 1 of 5 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=5)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Start Training ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FedASR/.conda/envs/openai/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /mnt/External/Seagate/FedASR/LLaMa2/dacs/Model/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4]\n",
      "/home/FedASR/.conda/envs/openai/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:375: Found unsupported keys in the optimizer configuration: {'scheduler'}\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | t_model | BertModel     | 167 M \n",
      "1 | a_model | Wav2Vec2Model | 315 M \n",
      "2 | clf1    | Linear        | 1.2 M \n",
      "3 | clf2    | Linear        | 1.5 K \n",
      "------------------------------------------\n",
      "483 M     Trainable params\n",
      "0         Non-trainable params\n",
      "483 M     Total params\n",
      "1,935.908 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb41c7893d4f46be927d9be96bd16026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f519415d2146828c314ebd56d0b828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 0.651\n",
      "Epoch 0, global step 14: 'val_acc' reached 0.65116 (best 0.65116), saving model to '/mnt/External/Seagate/FedASR/LLaMa2/dacs/Model/checkpoints/epoch=0-step=14-v3.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------val_report-------\n",
      "              precision    recall  f1-score    support\n",
      "Control        0.651163  1.000000  0.788732  56.000000\n",
      "ProbableAD     1.000000  0.000000  0.000000  30.000000\n",
      "accuracy       0.651163  0.651163  0.651163   0.651163\n",
      "macro avg      0.825581  0.500000  0.394366  86.000000\n",
      "weighted avg   0.772850  0.651163  0.513593  86.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /mnt/External/Seagate/FedASR/LLaMa2/dacs/Model/checkpoints/epoch=0-step=14-v3.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4]\n",
      "Loaded model weights from the checkpoint at /mnt/External/Seagate/FedASR/LLaMa2/dacs/Model/checkpoints/epoch=0-step=14-v3.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13db1525bde463493fca6691a9b6fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------test_report-------\n",
      "              precision  recall  f1-score  support\n",
      "Control        0.625000   1.000  0.769231   30.000\n",
      "ProbableAD     1.000000   0.000  0.000000   18.000\n",
      "accuracy       0.625000   0.625  0.625000    0.625\n",
      "macro avg      0.812500   0.500  0.384615   48.000\n",
      "weighted avg   0.765625   0.625  0.480769   48.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\npython 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed en\\npython 0207_DM_multi.py --gpu 1 --t_embed xlm --a_embed en\\n\\n# don\\npython 0207_DM_multi.py --gpu 0 --t_embed xlm --a_embed gr\\npython 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed gr\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# torch:\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor\n",
    "from transformers import BertTokenizer, BertConfig, BertModel,XLMTokenizer, XLMModel\n",
    "from prompts import assesmentPrompt_template, Instruction_templates, Psychology_template,\\\n",
    "    Sensitive_replace_dict, generate_psychology_prompt\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate, FewShotPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "class Arg:\n",
    "    version = 1\n",
    "    # data\n",
    "    epochs: int = 5  # Max Epochs, BERT paper setting [3,4,5]\n",
    "    max_length: int = 350  # Max Length input size\n",
    "    report_cycle: int = 30  # Report (Train Metrics) Cycle\n",
    "    cpu_workers: int = os.cpu_count()  # Multi cpu workers\n",
    "    test_mode: bool = False  # Test Mode enables `fast_dev_run`\n",
    "    optimizer: str = 'AdamW'  # AdamW vs AdamP\n",
    "    lr_scheduler: str = 'exp'  # ExponentialLR vs CosineAnnealingWarmRestarts\n",
    "    fp16: bool = False  # Enable train on FP16\n",
    "    a_hidden_size = 768 # BERT-base: 768, BERT-large: 1024, BERT paper setting\n",
    "    t_hidden_size = 768\n",
    "    t_x_hidden_size = a_hidden_size+t_hidden_size\n",
    "    batch_size: int = 8\n",
    "            \n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "class RAG_chatbot:\n",
    "    def __init__(self):\n",
    "        self.retreiver = None\n",
    "        self.stepback_model = None\n",
    "        self.answer_model = None\n",
    "        self.few_shot_prompt=None\n",
    "\n",
    "    def Initialize_openai(self,env_script_path = './env.sh'):\n",
    "        #activate environment\n",
    "        # 读取 env.sh 文件内容\n",
    "        with open(env_script_path, 'r') as file:\n",
    "            env_content = file.read()\n",
    "\n",
    "        # 将 env.sh 文件内容以换行符分割，并逐行执行\n",
    "        for line in env_content.split('\\n'):\n",
    "            # 跳过注释和空行\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                # 使用 split 等号来分割键值对\n",
    "                key, value = line.split('=', 1)\n",
    "                # 设置环境变量\n",
    "                os.environ[key.replace(\"export \",\"\")] = value.strip()\n",
    "        #Initialize openai\n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_version = \"2023-05-15\" \n",
    "        openai.api_base = os.getenv('OPENAI_API_BASE')  # Your Azure OpenAI resource's endpoint value.\n",
    "        openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "        chatopenai=ChatOpenAI(api_key=openai.api_key,model_kwargs={\"engine\": \"gpt-35-turbo\"})\n",
    "        return chatopenai\n",
    "    def Initialize_Embedder(self):\n",
    "        from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "        os.environ[\"AZURE_OPENAI_API_KEY\"] = openai.api_key\n",
    "        os.environ[\"AZURE_OPENAI_ENDPOINT\"] = openai.api_base\n",
    "\n",
    "\n",
    "        embedder = AzureOpenAIEmbeddings(\n",
    "            azure_deployment=\"text-embedding-ada-002\",\n",
    "            openai_api_version=\"2023-05-15\",\n",
    "        )\n",
    "        return embedder\n",
    "\n",
    "    def Initialize_fewshot_prompt(self, user_input):\n",
    "        # 在知識庫中搜尋與使用者輸入相關的資訊\n",
    "        # 這裡假設 knowledge_base 是一個包含資訊的字典或其他數據結構\n",
    "        if user_input in self.knowledge_base:\n",
    "            return self.knowledge_base[user_input]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Model(LightningModule):\n",
    "    def __init__(self, args,config):\n",
    "        super().__init__()\n",
    "        # config:\n",
    "        \n",
    "        self.args = args\n",
    "        self.config = config\n",
    "        self.batch_size = self.args.batch_size\n",
    "        \n",
    "        # meta data:\n",
    "        self.epochs_index = 0\n",
    "        self.label_cols = 'dementia_labels'\n",
    "        self.label_names = ['Control','ProbableAD']\n",
    "        self.num_labels = 2\n",
    "        self.t_embed_type = self.config['t_embed']\n",
    "        self.a_embed_type = self.config['a_embed']\n",
    "        self.a_hidden = self.args.a_hidden_size\n",
    "\n",
    "        if self.config['process_summary']:\n",
    "            self.RAG_bot=RAG_chatbot()\n",
    "            self.chatopenai=self.RAG_bot.Initialize_openai()\n",
    "            prompts_dict = generate_psychology_prompt(assessment_prompt_template=assesmentPrompt_template,\n",
    "                                            instruction_templates=Instruction_templates,\n",
    "                                            psychology_template=Psychology_template,\n",
    "                                            )\n",
    "            self.result_prompts=prompts_dict['self.config.selected_psych']\n",
    "\n",
    "\n",
    "        \n",
    "        # --> HERE STEP 1 <--\n",
    "        # ATTRIBUTES TO SAVE BATCH OUTPUTS\n",
    "        self.test_step_outputs = []   # save outputs in each batch to compute metric overall epoch\n",
    "        self.val_step_outputs = []        # save outputs in each batch to compute metric overall epoch\n",
    "\n",
    "\n",
    "        if self.t_embed_type == \"mbert\":\n",
    "            self.t_hidden = self.args.t_hidden_size\n",
    "            \n",
    "            t_pretrained = 'bert-base-multilingual-uncased'\n",
    "            self.t_tokenizer = BertTokenizer.from_pretrained(t_pretrained)\n",
    "            self.t_model = BertModel.from_pretrained(t_pretrained)\n",
    "            \n",
    "            \n",
    "        elif self.t_embed_type == \"xlm\":\n",
    "            self.t_hidden = self.args.t_x_hidden_size\n",
    "            \n",
    "            t_pretrained = 'xlm-mlm-100-1280'\n",
    "            self.t_tokenizer = XLMTokenizer.from_pretrained(t_pretrained)\n",
    "            self.t_model = XLMModel.from_pretrained(t_pretrained)\n",
    "            self.pooler = BertPooler(self.t_hidden)\n",
    "            \n",
    "        self.hidden = int(self.a_hidden + self.t_hidden)\n",
    "        \n",
    "        if self.a_embed_type == \"en\":\n",
    "            a_pretrained =  \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
    "            \n",
    "        elif self.a_embed_type == \"gr\":\n",
    "            a_pretrained =  \"lighteternal/wav2vec2-large-xlsr-53-greek\"\n",
    "\n",
    "        elif self.a_embed_type == \"multi\":\n",
    "            a_pretrained = \"voidful/wav2vec2-xlsr-multilingual-56\"\n",
    "            \n",
    "        elif self.a_embed_type == \"wv\":\n",
    "            a_pretrained ='facebook/wav2vec2-base'\n",
    "            \n",
    "        self.a_tokenizer = Wav2Vec2FeatureExtractor.from_pretrained(a_pretrained)\n",
    "        self.a_model = Wav2Vec2Model.from_pretrained(a_pretrained)\n",
    "        \n",
    "        \n",
    "        self.clf1 = nn.Linear(self.hidden, int(self.hidden/2))\n",
    "        self.clf2 = nn.Linear(int(self.hidden/2), self.num_labels)\n",
    "        \n",
    "            \n",
    "            \n",
    "    # def forward(self, text, audio):\n",
    "    def forward(self, text1, text2):\n",
    "        \n",
    "        if self.t_embed_type == \"mbert\":\n",
    "            t1_out = self.t_model(text1)[1] \n",
    "\n",
    "            t2_out = self.t_model(text2)[1] \n",
    "\n",
    "            \n",
    "        elif self.t_embed_type == \"xlm\":\n",
    "            t1_out = self.t_model(text1)[0]\n",
    "            t1_out = self.pooler(t1_out)\n",
    "\n",
    "            t2_out = self.t_model(text2)[0]\n",
    "            t2_out = self.pooler(t2_out)\n",
    "            \n",
    "            \n",
    "        # a_out = self.a_model(audio)['extract_features']#[2] #last_hidden_state , feature extraction\n",
    "        # a_out = a_out[:, 0, :] \n",
    "        \n",
    "        #print(a_out)\n",
    "        #print(a_out['extract_features'].shape) # ([8, 437, 512])\n",
    "        #print(a_out['last_hidden_state'].shape) # ([8, 437, 1024]) => pooling 필요\n",
    "        \n",
    "        \n",
    "        output = torch.cat((t1_out,t2_out),axis=1)   \n",
    "        # output = t_out\n",
    "        #print(output.shape)\n",
    "        \n",
    "        logits = self.clf2(self.clf1(output))\n",
    "    \n",
    "        return logits\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.config['lr'])\n",
    "        scheduler = ExponentialLR(optimizer, gamma=0.5)\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "        }\n",
    "\n",
    "    def preprocess_dataframe(self):\n",
    "        tg_sr = 16000\n",
    "        t_col_name = \"text\" \n",
    "        # a_col_name = \"path\"         \n",
    "        # df = pd.read_json('/mnt/Internal/FedASR/Data/230126_total_asr_data.json')\n",
    "        df = pd.read_csv(config.file_in)\n",
    "\n",
    "        def Augment_info_df(df_test):\n",
    "            # 將 'path' 欄位進行字串操作\n",
    "            df_test['path'] = df_test['path'].str.rstrip('.wav')\n",
    "\n",
    "            # 使用 str.split 拆分 'path' 欄位\n",
    "            df_test[['session', 'role', 'number', 'start_time', 'end_time']] = df_test['path'].str.split('_', expand=True)\n",
    "\n",
    "            # 如果 'number' 欄位的末尾包含 '.wav'，進行一次額外的拆分\n",
    "            df_test['number'] = df_test['number'].str.rstrip('.wav')\n",
    "\n",
    "            # 將 'start_time' 和 'end_time' 欄位轉換為數值型別\n",
    "            df_test[['start_time', 'end_time']] = df_test[['start_time', 'end_time']].astype(int)\n",
    "\n",
    "            return df_test\n",
    "        df = Augment_info_df(df)\n",
    "\n",
    "\n",
    "        # Packer\n",
    "        def Packer(df_test) -> dict:\n",
    "            People_dict = dict(tuple(df_test.groupby('session')))\n",
    "            return People_dict\n",
    "\n",
    "        def Dialogueturn2corpus(data_frame, mode='text'): #mode can be 'pred_str' or 'text'\n",
    "            # 按 'start_time' 列進行排序\n",
    "            sorted_data_frame = data_frame.sort_values(by='start_time')\n",
    "\n",
    "            # 添加前綴並使用 '\\n' 進行拼接\n",
    "            processed_text = sorted_data_frame.apply(lambda row: f\"{row['role']}: {row[mode]}\", axis=1).str.cat(sep='\\n')\n",
    "\n",
    "            return processed_text\n",
    "\n",
    "        def filter_people_dict(People_dict, mode=\"INV+PAR\", verbose=False) -> dict:# 'INV' , 'PAR', 'INV+PAR'\n",
    "            filtered_people_dict = {}\n",
    "\n",
    "            for session, data_frame in People_dict.items():\n",
    "                # 使用 query 過濾 'role' 為 'INV' 或 'PAR'\n",
    "                if mode == \"PAR\":\n",
    "                    filtered_data_frame = data_frame.query(\"role == 'PAR'\")\n",
    "                    filtered_people_dict[session] = filtered_data_frame\n",
    "                elif mode == \"INV\":\n",
    "                    filtered_data_frame = data_frame.query(\"role == 'INV'\")\n",
    "                    filtered_people_dict[session] = filtered_data_frame\n",
    "                elif mode == \"INV+PAR\":\n",
    "                    filtered_people_dict[session] = data_frame\n",
    "                else:\n",
    "                    raise OSError\n",
    "            \n",
    "            if verbose:\n",
    "                # 印出過濾後的 People_dict 中每個 session 的 DataFrame\n",
    "                for session, data_frame in filtered_people_dict.items():\n",
    "                    print(f\"Session: {session}\")\n",
    "                    print(data_frame)\n",
    "                    print(\"\\n\")\n",
    "\n",
    "            return filtered_people_dict\n",
    "\n",
    "        # Dialogue Formatter\n",
    "        def Dialogue_Formatter(People_dict, sep=\"\\n\",role_mode='PAR')->dict:\n",
    "            session_df=pd.DataFrame()\n",
    "            for session, data_frame in People_dict.items():\n",
    "                if len(data_frame)>0:\n",
    "                    total_info=data_frame.iloc[0].copy()\n",
    "                    sessional_text = Dialogueturn2corpus(data_frame,mode='text')\n",
    "                    sessional_predStr = Dialogueturn2corpus(data_frame,mode='pred_str')\n",
    "                    \n",
    "                    # total_info,'text']=sessional_text\n",
    "                    # session_df.loc[session,'pred_str']=sessional_predStr\n",
    "                    # session_df.loc[session,'role']=role_mode\n",
    "                    # session_df.loc[session,'start_time']=data_frame['start_time'].min()\n",
    "                    # session_df.loc[session,'end_time']=data_frame['end_time'].max()\n",
    "\n",
    "                    total_info['text']=sessional_text\n",
    "                    total_info['pred_str']=sessional_predStr\n",
    "                    total_info['role']=role_mode\n",
    "                    total_info['start_time']=data_frame['start_time'].min()\n",
    "                    total_info['end_time']=data_frame['end_time'].max()\n",
    "                    session_df = pd.concat([session_df, pd.DataFrame([total_info], index=[session])])\n",
    "                else:\n",
    "                    print(f\"Session {session} has no data\")\n",
    "            return session_df\n",
    "        df_train = df[df['ex'] == 'train']\n",
    "        df_val = df[df['ex'] == 'dev']\n",
    "        df_test = df[df['ex'] == 'test']\n",
    "\n",
    "        def SentenceLvldf2SessionLvldf(df, role_mode=\"PAR\"):\n",
    "            People_dict=Packer(df)\n",
    "            People_dict = filter_people_dict(People_dict, mode=role_mode, verbose=False)\n",
    "            df_dialogue=Dialogue_Formatter(People_dict,role_mode)\n",
    "            return df_dialogue\n",
    "\n",
    "        df_train=SentenceLvldf2SessionLvldf(df_train)\n",
    "        df_val=SentenceLvldf2SessionLvldf(df_val)\n",
    "        df_test=SentenceLvldf2SessionLvldf(df_test)\n",
    "\n",
    "        def Tokenize(df_data):\n",
    "            df_data[t_col_name] = df_data[t_col_name].map(lambda x: self.t_tokenizer.encode(\n",
    "                str(x),\n",
    "                padding = 'max_length',\n",
    "                max_length=self.args.max_length,\n",
    "                truncation=True,\n",
    "                ))\n",
    "            return df_data\n",
    "        df_train=Tokenize(df_train)\n",
    "        df_val=Tokenize(df_val)\n",
    "        df_test=Tokenize(df_test)\n",
    "        df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "        # audio_root=\"/mnt/Internal/FedASR/Data/ADReSS-IS2020-data/clips\"\n",
    "        # # 원래 길이: 562992, batch 16: 90000, batch 8: 140000\n",
    "        # # max_length=16000, truncation=True 이건 일단 돌려보고 결정 => 뒤쪽, 앞에쪽 뭐보면 좋을 지 그런거 check하면 좋으니까! \n",
    "        # df[a_col_name] = df[a_col_name].map(lambda x: self.a_tokenizer(\n",
    "        #     f\"{audio_root}/{x}\",\n",
    "        #     sampling_rate = tg_sr,\n",
    "        #     max_length=100000, \n",
    "        #     truncation=True\n",
    "        #     )['input_values'][0])\n",
    "        def get_sessiondf_summary(session_df, prompt_template, chatopenai, Sensitive_replace_dict, use_text='text'):\n",
    "            Summary_dict, Prompt_dict = {}, {}, {}\n",
    "            for session, row in session_df.iterrows():\n",
    "                if session in Sensitive_replace_dict.keys():\n",
    "                    dialogue_content = row[use_text]\n",
    "                    for values in Sensitive_replace_dict[session]:\n",
    "                        dialogue_content = dialogue_content.replace(values[0], values[1])\n",
    "                    \n",
    "                else:\n",
    "                    dialogue_content = row[use_text]\n",
    "\n",
    "                prompt=prompt_template.format(dialogue_content=dialogue_content)\n",
    "                ans_middle = chatopenai.invoke(prompt)\n",
    "\n",
    "                output_parser = StrOutputParser()\n",
    "                summary = output_parser.parse(ans_middle).content\n",
    "                Summary_dict[session] = summary\n",
    "                Prompt_dict[session] = prompt\n",
    "\n",
    "            session_df['Psych_Summary'] = session_df.index.to_series().apply(lambda x: Summary_dict.get(x, []))\n",
    "            session_df['Psych_Prompt'] = session_df.index.to_series().apply(lambda x: Prompt_dict.get(x, []))\n",
    "            return session_df\n",
    "        if self.process_summary:\n",
    "            df_train=get_sessiondf_summary(df_train, self.result_prompts, self.chatopenai, Sensitive_replace_dict, use_text='text')\n",
    "            df_val=get_sessiondf_summary(df_val, self.result_prompts, self.chatopenai, Sensitive_replace_dict, use_text='text')\n",
    "            df_test=get_sessiondf_summary(df_test, self.result_prompts, self.chatopenai, Sensitive_replace_dict, use_text='text')\n",
    "\n",
    "        self.train_data = TensorDataset(\n",
    "            torch.tensor(df_train[t_col_name].tolist(), dtype=torch.long),\n",
    "            # torch.tensor(df_train[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_train[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "        \n",
    "        self.val_data = TensorDataset(\n",
    "             torch.tensor(df_val[t_col_name].tolist(), dtype=torch.long),\n",
    "            #  torch.tensor(df_val[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_val[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        self.test_data = TensorDataset(\n",
    "             torch.tensor(df_test[t_col_name].tolist(), dtype=torch.long),\n",
    "            #  torch.tensor(df_test[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_test[self.label_cols].tolist(), dtype=torch.long),\n",
    "             torch.tensor(df_test.index.tolist(), dtype=torch.long),\n",
    "        )\n",
    "    \n",
    "    def preprocess_loaded_summaries(self):\n",
    "        df_train = pd.read_pickle(f\"{config.summary_dir_in}/train.pkl\")\n",
    "        df_val = pd.read_pickle(f\"{config.summary_dir_in}/dev.pkl\")\n",
    "        df_test = pd.read_pickle(f\"{config.summary_dir_in}/test.pkl\")\n",
    "\n",
    "        t1_col_name='text'\n",
    "        t2_col_name='Psych_Summary'\n",
    "        def Tokenize(df_data, t_col_name='text'):\n",
    "            df_data[t_col_name] = df_data[t_col_name].map(lambda x: self.t_tokenizer.encode(\n",
    "                str(x),\n",
    "                padding = 'max_length',\n",
    "                max_length=self.args.max_length,\n",
    "                truncation=True,\n",
    "                ))\n",
    "            return df_data\n",
    "        df_train=Tokenize(df_train,t_col_name=t1_col_name)\n",
    "        df_train=Tokenize(df_train,t_col_name=t2_col_name)\n",
    "        df_val=Tokenize(df_val,t_col_name=t1_col_name)\n",
    "        df_val=Tokenize(df_val,t_col_name=t2_col_name)\n",
    "        df_test=Tokenize(df_test,t_col_name=t1_col_name)\n",
    "        df_test=Tokenize(df_test,t_col_name=t2_col_name)\n",
    "        df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "        self.train_data = TensorDataset(\n",
    "            torch.tensor(df_train[t1_col_name].tolist(), dtype=torch.long),\n",
    "            torch.tensor(df_train[t2_col_name].tolist(), dtype=torch.long),\n",
    "            torch.tensor(df_train[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        self.val_data = TensorDataset(\n",
    "                torch.tensor(df_val[t1_col_name].tolist(), dtype=torch.long),\n",
    "             torch.tensor(df_val[t2_col_name].tolist(), dtype=torch.long),\n",
    "            torch.tensor(df_val[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        self.test_data = TensorDataset(\n",
    "            torch.tensor(df_test[t1_col_name].tolist(), dtype=torch.long),\n",
    "            torch.tensor(df_test[t2_col_name].tolist(), dtype=torch.long),\n",
    "            torch.tensor(df_test[self.label_cols].tolist(), dtype=torch.long),\n",
    "            torch.tensor(df_test.index.tolist(), dtype=torch.long),\n",
    "        )\n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        return DataLoader(\n",
    "            self.train_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.args.cpu_workers,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "\n",
    "        return DataLoader(\n",
    "            self.val_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.args.cpu_workers,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "\n",
    "        return DataLoader(\n",
    "            self.test_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.args.cpu_workers,\n",
    "        )\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        token1, token2, labels = batch  \n",
    "        # token,  labels = batch  \n",
    "        logits = self(token1, token2) \n",
    "        # logits = self(token) \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)   \n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        token1, token2, labels = batch  \n",
    "        # token,  labels = batch  \n",
    "        logits = self(token1, token2) \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)     \n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true = list(labels.cpu().numpy())\n",
    "        y_pred = list(preds.cpu().numpy())\n",
    "\n",
    "        # --> HERE STEP 2 <--\n",
    "        self.val_step_outputs.append({\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        })\n",
    "        # self.val_step_targets.append(y_true)\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "        \n",
    "            \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        token1, token2, labels,id_ = batch  \n",
    "        # token,  labels = batch  \n",
    "        logits = self(token1, token2) \n",
    "        # logits = self(token) \n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true = list(labels.cpu().numpy())\n",
    "        y_pred = list(preds.cpu().numpy())\n",
    "\n",
    "        # --> HERE STEP 2 <--\n",
    "        self.test_step_outputs.append({\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        })\n",
    "        # self.test_step_targets.append(y_true)\n",
    "        return {\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = torch.tensor(0, dtype=torch.float)\n",
    "        # print(\"Value= \",self.val_step_outputs)\n",
    "        # print(\"type(self.val_step_outputs)=\",type(self.val_step_outputs))\n",
    "        # print(\"type(self.val_step_outputs[0])=\",type(self.val_step_outputs[0]))\n",
    "        # print(\"type(self.val_step_outputs[0] loss)=\",type(self.val_step_outputs[0]['loss']))\n",
    "        for i in self.val_step_outputs:\n",
    "            loss += i['loss'].cpu().detach()\n",
    "        _loss = loss / len(self.val_step_outputs)\n",
    "        loss = float(_loss)\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in self.val_step_outputs:\n",
    "            y_true += i['y_true']\n",
    "            y_pred += i['y_pred']\n",
    "            \n",
    "        y_pred = np.asanyarray(y_pred)#y_temp_pred y_pred\n",
    "        y_true = np.asanyarray(y_true)\n",
    "        \n",
    "        pred_dict = {}\n",
    "        pred_dict['y_pred']= y_pred\n",
    "        pred_dict['y_true']= y_true\n",
    "        \n",
    "        val_acc = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "        \n",
    "        self.log(\"val_acc\", val_acc)\n",
    "        # print(\"y_pred= \", y_pred)\n",
    "        # print('\\n\\n\\n')\n",
    "        # print(\"y_true= \", y_true)\n",
    "        # print('\\n\\n\\n')\n",
    "        print(\"-------val_report-------\")\n",
    "        metrics_dict = classification_report(y_true, y_pred,zero_division=1,\n",
    "                                             target_names = self.label_names, \n",
    "                                             output_dict=True)\n",
    "        df_result = pd.DataFrame(metrics_dict).transpose()\n",
    "        pprint(df_result)\n",
    "        \n",
    "        Output_dir=f\"{SaveRoot}/result\"\n",
    "        os.makedirs(Output_dir, exist_ok=True)\n",
    "        df_result.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_val.csv')\n",
    "\n",
    "        pred_df = pd.DataFrame(pred_dict)\n",
    "        pred_df.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_val_pred.csv')\n",
    "        self.val_step_outputs.clear()\n",
    "        # self.val_step_targets.clear()\n",
    "        return {'loss': _loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in self.test_step_outputs:\n",
    "            y_true += i['y_true']\n",
    "            y_pred += i['y_pred']\n",
    "            \n",
    "        y_pred = np.asanyarray(y_pred)#y_temp_pred y_pred\n",
    "        y_true = np.asanyarray(y_true)\n",
    "        \n",
    "        pred_dict = {}\n",
    "        pred_dict['y_pred']= y_pred\n",
    "        pred_dict['y_true']= y_true\n",
    "        \n",
    "        \n",
    "        print(\"-------test_report-------\")\n",
    "        metrics_dict = classification_report(y_true, y_pred,zero_division=1,\n",
    "                                             target_names = self.label_names, \n",
    "                                             output_dict=True)\n",
    "        df_result = pd.DataFrame(metrics_dict).transpose()\n",
    "        self.test_step_outputs.clear()\n",
    "        # self.test_step_targets.clear()\n",
    "        pprint(df_result)\n",
    "        \n",
    "        Output_dir=f\"{SaveRoot}/result\"\n",
    "        os.makedirs(Output_dir, exist_ok=True)\n",
    "        df_result.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_test.csv')\n",
    "\n",
    "        pred_df = pd.DataFrame(pred_dict)\n",
    "        pred_df.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_test_pred.csv')\n",
    "\n",
    "    # def preprocess_existing_summary_dataframe():\n",
    "\n",
    "def main(args,config):\n",
    "    print(\"Using PyTorch Ver\", torch.__version__)\n",
    "    print(\"Fix Seed:\", config['random_seed'])\n",
    "    seed_everything( config['random_seed'])\n",
    "        \n",
    "    model = Model(args,config) \n",
    "    # model.preprocess_dataframe()\n",
    "    model.preprocess_loaded_summaries()\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=f\"{SaveRoot}/Model/checkpoints\",\n",
    "        monitor='val_acc',\n",
    "        auto_insert_metric_name=True,\n",
    "        verbose=True,\n",
    "        mode='max', \n",
    "        save_top_k=1,\n",
    "      )    \n",
    "\n",
    "    print(\":: Start Training ::\")\n",
    "    #     \n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        callbacks=[early_stop_callback,checkpoint_callback],\n",
    "        enable_checkpointing = True,\n",
    "        max_epochs=args.epochs,\n",
    "        fast_dev_run=args.test_mode,\n",
    "        num_sanity_val_steps=None if args.test_mode else 0,\n",
    "        deterministic=True, # ensure full reproducibility from run to run you need to set seeds for pseudo-random generators,\n",
    "        # For GPU Setup\n",
    "        # gpus=[config['gpu']] if torch.cuda.is_available() else None,\n",
    "        precision=16 if args.fp16 else 32\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model,dataloaders=model.test_dataloader(),ckpt_path=\"best\")\n",
    "    \n",
    "if __name__ == '__main__': \n",
    "\n",
    "    parser = argparse.ArgumentParser(\"main.py\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\"--gpu\", type=int, default=1)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "    parser.add_argument(\"--lr\", type=float, default=2e-5, help=\"learning rate\")\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=2023) \n",
    "    parser.add_argument(\"--t_embed\", type=str, default=\"mbert\") \n",
    "    parser.add_argument(\"--a_embed\", type=str, default=\"en\") \n",
    "    parser.add_argument(\"--SaveRoot\", type=str, default='/mnt/External/Seagate/FedASR/LLaMa2/dacs') \n",
    "    parser.add_argument(\"--file_in\", type=str, default='/home/FedASR/dacs/centralized/saves/results/data2vec-audio-large-960h_total.csv') \n",
    "    parser.add_argument(\"--process_summary\", type=bool, default=False) \n",
    "    parser.add_argument(\"--summary_dir_in\", type=str, default='/mnt/External/Seagate/FedASR/LLaMa2/dacs/EmbFeats/Lexical/Embeddings/text_data2vec-audio-large-960h_Phych-anomia') \n",
    "    \n",
    "    config = parser.parse_args(args=[])\n",
    "    SaveRoot=config.SaveRoot\n",
    "    \n",
    "    print(config)\n",
    "    args = Arg()\n",
    "    args.epochs=config.epochs\n",
    "    main(args,config.__dict__)       \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed en\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed xlm --a_embed en\n",
    "\n",
    "# don\n",
    "python 0207_DM_multi.py --gpu 0 --t_embed xlm --a_embed gr\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed gr\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mpreprocess_loaded_summaries()\n\u001b[1;32m      7\u001b[0m tst_dl\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtest_dataloader()\n\u001b[0;32m----> 8\u001b[0m tst_dta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtst_dl\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not an iterator"
     ]
    }
   ],
   "source": [
    "args.epochs=config.epochs\n",
    "\n",
    "model = Model(args,config.__dict__) \n",
    "self=model\n",
    "\n",
    "model.preprocess_loaded_summaries()\n",
    "tst_dl=model.test_dataloader()\n",
    "tst_dta=next(tst_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tst_dl:\n\u001b[0;32m----> 2\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for batch in tst_dl:\n",
    "    token1, token2, labels = batch  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(batch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
