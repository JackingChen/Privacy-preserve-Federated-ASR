{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=1, epochs=5, lr=2e-05, random_seed=2023, t_embed='mbert', a_embed='en', SaveRoot='/mnt/External/Seagate/FedASR/LLaMa2/dacs', file_in='/home/FedASR/dacs/centralized/saves/results/data2vec-audio-large-960h_total.csv', process_summary=False, summary_dir_in='/mnt/External/Seagate/FedASR/LLaMa2/dacs/EmbFeats/Lexical/Embeddings/text_data2vec-audio-large-960h_Phych-anomia')\n",
      "Using PyTorch Ver 2.1.1+cu121\n",
      "Fix Seed: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Trainer will use only 1 of 5 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=5)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Start Training ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FedASR/.conda/envs/openai/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /mnt/External/Seagate/FedASR/LLaMa2/dacs/Model/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4]\n",
      "/home/FedASR/.conda/envs/openai/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:375: Found unsupported keys in the optimizer configuration: {'scheduler'}\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | t_model | BertModel     | 167 M \n",
      "1 | a_model | Wav2Vec2Model | 315 M \n",
      "2 | clf1    | Linear        | 295 K \n",
      "3 | clf2    | Linear        | 770   \n",
      "------------------------------------------\n",
      "483 M     Trainable params\n",
      "0         Non-trainable params\n",
      "483 M     Total params\n",
      "1,932.365 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963a59498f234ea6be36069b9300ff1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4360ff3b1ff4e88ab9bcd2ed9ee8a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 0.651\n",
      "Epoch 0, global step 14: 'val_acc' reached 0.65116 (best 0.65116), saving model to '/mnt/External/Seagate/FedASR/LLaMa2/dacs/Model/checkpoints/epoch=0-step=14-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------val_report-------\n",
      "              precision    recall  f1-score    support\n",
      "Control        0.651163  1.000000  0.788732  56.000000\n",
      "ProbableAD     1.000000  0.000000  0.000000  30.000000\n",
      "accuracy       0.651163  0.651163  0.651163   0.651163\n",
      "macro avg      0.825581  0.500000  0.394366  86.000000\n",
      "weighted avg   0.772850  0.651163  0.513593  86.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f2f9df82544375b6c24995e9f4988c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 28: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------val_report-------\n",
      "              precision    recall  f1-score    support\n",
      "Control        0.651163  1.000000  0.788732  56.000000\n",
      "ProbableAD     1.000000  0.000000  0.000000  30.000000\n",
      "accuracy       0.651163  0.651163  0.651163   0.651163\n",
      "macro avg      0.825581  0.500000  0.394366  86.000000\n",
      "weighted avg   0.772850  0.651163  0.513593  86.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb80960299214751af3d4a9d22f338cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 42: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------val_report-------\n",
      "              precision    recall  f1-score    support\n",
      "Control        0.651163  1.000000  0.788732  56.000000\n",
      "ProbableAD     1.000000  0.000000  0.000000  30.000000\n",
      "accuracy       0.651163  0.651163  0.651163   0.651163\n",
      "macro avg      0.825581  0.500000  0.394366  86.000000\n",
      "weighted avg   0.772850  0.651163  0.513593  86.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd24bf512864e35ba55c4eb6bf04f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 56: 'val_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------val_report-------\n",
      "              precision    recall  f1-score    support\n",
      "Control        0.651163  1.000000  0.788732  56.000000\n",
      "ProbableAD     1.000000  0.000000  0.000000  30.000000\n",
      "accuracy       0.651163  0.651163  0.651163   0.651163\n",
      "macro avg      0.825581  0.500000  0.394366  86.000000\n",
      "weighted avg   0.772850  0.651163  0.513593  86.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b056c811d5024b009b65f9a6d5d99d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 70: 'val_acc' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------val_report-------\n",
      "              precision    recall  f1-score    support\n",
      "Control        0.651163  1.000000  0.788732  56.000000\n",
      "ProbableAD     1.000000  0.000000  0.000000  30.000000\n",
      "accuracy       0.651163  0.651163  0.651163   0.651163\n",
      "macro avg      0.825581  0.500000  0.394366  86.000000\n",
      "weighted avg   0.772850  0.651163  0.513593  86.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /mnt/External/Seagate/FedASR/LLaMa2/dacs/Model/checkpoints/epoch=0-step=14-v1.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4]\n",
      "Loaded model weights from the checkpoint at /mnt/External/Seagate/FedASR/LLaMa2/dacs/Model/checkpoints/epoch=0-step=14-v1.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d15565329246b0ac6b15a5b087b9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id tensor([0, 1, 2, 3, 4, 5, 6, 7], device='cuda:0')\n",
      "id tensor([ 8,  9, 10, 11, 12, 13, 14, 15], device='cuda:0')\n",
      "id tensor([16, 17, 18, 19, 20, 21, 22, 23], device='cuda:0')\n",
      "id tensor([24, 25, 26, 27, 28, 29, 30, 31], device='cuda:0')\n",
      "id tensor([32, 33, 34, 35, 36, 37, 38, 39], device='cuda:0')\n",
      "id tensor([40, 41, 42, 43, 44, 45, 46, 47], device='cuda:0')\n",
      "-------test_report-------\n",
      "              precision  recall  f1-score  support\n",
      "Control        0.625000   1.000  0.769231   30.000\n",
      "ProbableAD     1.000000   0.000  0.000000   18.000\n",
      "accuracy       0.625000   0.625  0.625000    0.625\n",
      "macro avg      0.812500   0.500  0.384615   48.000\n",
      "weighted avg   0.765625   0.625  0.480769   48.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\npython 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed en\\npython 0207_DM_multi.py --gpu 1 --t_embed xlm --a_embed en\\n\\n# don\\npython 0207_DM_multi.py --gpu 0 --t_embed xlm --a_embed gr\\npython 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed gr\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# torch:\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor\n",
    "from transformers import BertTokenizer, BertConfig, BertModel,XLMTokenizer, XLMModel\n",
    "from prompts import assesmentPrompt_template, Instruction_templates, Psychology_template,\\\n",
    "    Sensitive_replace_dict, generate_psychology_prompt\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate, FewShotPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "class Arg:\n",
    "    version = 1\n",
    "    # data\n",
    "    epochs: int = 5  # Max Epochs, BERT paper setting [3,4,5]\n",
    "    max_length: int = 350  # Max Length input size\n",
    "    report_cycle: int = 30  # Report (Train Metrics) Cycle\n",
    "    cpu_workers: int = os.cpu_count()  # Multi cpu workers\n",
    "    test_mode: bool = False  # Test Mode enables `fast_dev_run`\n",
    "    optimizer: str = 'AdamW'  # AdamW vs AdamP\n",
    "    lr_scheduler: str = 'exp'  # ExponentialLR vs CosineAnnealingWarmRestarts\n",
    "    fp16: bool = False  # Enable train on FP16\n",
    "    a_hidden_size = 0 # BERT-base: 768, BERT-large: 1024, BERT paper setting\n",
    "    t_hidden_size = 768\n",
    "    t_x_hidden_size = a_hidden_size+t_hidden_size\n",
    "    batch_size: int = 8\n",
    "            \n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "class RAG_chatbot:\n",
    "    def __init__(self):\n",
    "        self.retreiver = None\n",
    "        self.stepback_model = None\n",
    "        self.answer_model = None\n",
    "        self.few_shot_prompt=None\n",
    "\n",
    "    def Initialize_openai(self,env_script_path = './env.sh'):\n",
    "        #activate environment\n",
    "        # 读取 env.sh 文件内容\n",
    "        with open(env_script_path, 'r') as file:\n",
    "            env_content = file.read()\n",
    "\n",
    "        # 将 env.sh 文件内容以换行符分割，并逐行执行\n",
    "        for line in env_content.split('\\n'):\n",
    "            # 跳过注释和空行\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                # 使用 split 等号来分割键值对\n",
    "                key, value = line.split('=', 1)\n",
    "                # 设置环境变量\n",
    "                os.environ[key.replace(\"export \",\"\")] = value.strip()\n",
    "        #Initialize openai\n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_version = \"2023-05-15\" \n",
    "        openai.api_base = os.getenv('OPENAI_API_BASE')  # Your Azure OpenAI resource's endpoint value.\n",
    "        openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "        chatopenai=ChatOpenAI(api_key=openai.api_key,model_kwargs={\"engine\": \"gpt-35-turbo\"})\n",
    "        return chatopenai\n",
    "    def Initialize_Embedder(self):\n",
    "        from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "        os.environ[\"AZURE_OPENAI_API_KEY\"] = openai.api_key\n",
    "        os.environ[\"AZURE_OPENAI_ENDPOINT\"] = openai.api_base\n",
    "\n",
    "\n",
    "        embedder = AzureOpenAIEmbeddings(\n",
    "            azure_deployment=\"text-embedding-ada-002\",\n",
    "            openai_api_version=\"2023-05-15\",\n",
    "        )\n",
    "        return embedder\n",
    "\n",
    "    def Initialize_fewshot_prompt(self, user_input):\n",
    "        # 在知識庫中搜尋與使用者輸入相關的資訊\n",
    "        # 這裡假設 knowledge_base 是一個包含資訊的字典或其他數據結構\n",
    "        if user_input in self.knowledge_base:\n",
    "            return self.knowledge_base[user_input]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Model(LightningModule):\n",
    "    def __init__(self, args,config):\n",
    "        super().__init__()\n",
    "        # config:\n",
    "        \n",
    "        self.args = args\n",
    "        self.config = config\n",
    "        self.batch_size = self.args.batch_size\n",
    "        \n",
    "        # meta data:\n",
    "        self.epochs_index = 0\n",
    "        self.label_cols = 'dementia_labels'\n",
    "        self.label_names = ['Control','ProbableAD']\n",
    "        self.num_labels = 2\n",
    "        self.t_embed_type = self.config['t_embed']\n",
    "        self.a_embed_type = self.config['a_embed']\n",
    "        self.a_hidden = self.args.a_hidden_size\n",
    "\n",
    "        if self.config['process_summary']:\n",
    "            self.RAG_bot=RAG_chatbot()\n",
    "            self.chatopenai=self.RAG_bot.Initialize_openai()\n",
    "            prompts_dict = generate_psychology_prompt(assessment_prompt_template=assesmentPrompt_template,\n",
    "                                            instruction_templates=Instruction_templates,\n",
    "                                            psychology_template=Psychology_template,\n",
    "                                            )\n",
    "            self.result_prompts=prompts_dict['self.config.selected_psych']\n",
    "\n",
    "\n",
    "        \n",
    "        # --> HERE STEP 1 <--\n",
    "        # ATTRIBUTES TO SAVE BATCH OUTPUTS\n",
    "        self.test_step_outputs = []   # save outputs in each batch to compute metric overall epoch\n",
    "        self.val_step_outputs = []        # save outputs in each batch to compute metric overall epoch\n",
    "\n",
    "\n",
    "        if self.t_embed_type == \"mbert\":\n",
    "            self.t_hidden = self.args.t_hidden_size\n",
    "            \n",
    "            t_pretrained = 'bert-base-multilingual-uncased'\n",
    "            self.t_tokenizer = BertTokenizer.from_pretrained(t_pretrained)\n",
    "            self.t_model = BertModel.from_pretrained(t_pretrained)\n",
    "            \n",
    "            \n",
    "        elif self.t_embed_type == \"xlm\":\n",
    "            self.t_hidden = self.args.t_x_hidden_size\n",
    "            \n",
    "            t_pretrained = 'xlm-mlm-100-1280'\n",
    "            self.t_tokenizer = XLMTokenizer.from_pretrained(t_pretrained)\n",
    "            self.t_model = XLMModel.from_pretrained(t_pretrained)\n",
    "            self.pooler = BertPooler(self.t_hidden)\n",
    "            \n",
    "        self.hidden = int(self.a_hidden + self.t_hidden)\n",
    "        \n",
    "        if self.a_embed_type == \"en\":\n",
    "            a_pretrained =  \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
    "            \n",
    "        elif self.a_embed_type == \"gr\":\n",
    "            a_pretrained =  \"lighteternal/wav2vec2-large-xlsr-53-greek\"\n",
    "\n",
    "        elif self.a_embed_type == \"multi\":\n",
    "            a_pretrained = \"voidful/wav2vec2-xlsr-multilingual-56\"\n",
    "            \n",
    "        elif self.a_embed_type == \"wv\":\n",
    "            a_pretrained ='facebook/wav2vec2-base'\n",
    "            \n",
    "        self.a_tokenizer = Wav2Vec2FeatureExtractor.from_pretrained(a_pretrained)\n",
    "        self.a_model = Wav2Vec2Model.from_pretrained(a_pretrained)\n",
    "        \n",
    "        \n",
    "        self.clf1 = nn.Linear(self.hidden, int(self.hidden/2))\n",
    "        self.clf2 = nn.Linear(int(self.hidden/2), self.num_labels)\n",
    "        \n",
    "            \n",
    "            \n",
    "    # def forward(self, text, audio):\n",
    "    def forward(self, text):\n",
    "        \n",
    "        if self.t_embed_type == \"mbert\":\n",
    "            t_out = self.t_model(text)[1] \n",
    "\n",
    "            \n",
    "        elif self.t_embed_type == \"xlm\":\n",
    "            t_out = self.t_model(text)[0]\n",
    "            t_out = self.pooler(t_out)\n",
    "            \n",
    "            \n",
    "        # a_out = self.a_model(audio)['extract_features']#[2] #last_hidden_state , feature extraction\n",
    "        # a_out = a_out[:, 0, :] \n",
    "        \n",
    "        #print(a_out)\n",
    "        #print(a_out['extract_features'].shape) # ([8, 437, 512])\n",
    "        #print(a_out['last_hidden_state'].shape) # ([8, 437, 1024]) => pooling 필요\n",
    "        \n",
    "        \n",
    "        # output = torch.cat((t_out,a_out),axis=1)   \n",
    "        output = t_out\n",
    "        #print(output.shape)\n",
    "        \n",
    "        logits = self.clf2(self.clf1(output))\n",
    "    \n",
    "        return logits\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.config['lr'])\n",
    "        scheduler = ExponentialLR(optimizer, gamma=0.5)\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "        }\n",
    "\n",
    "    def preprocess_dataframe(self):\n",
    "        tg_sr = 16000\n",
    "        t_col_name = \"text\" \n",
    "        # a_col_name = \"path\"         \n",
    "        # df = pd.read_json('/mnt/Internal/FedASR/Data/230126_total_asr_data.json')\n",
    "        df = pd.read_csv(config.file_in)\n",
    "\n",
    "        def Augment_info_df(df_test):\n",
    "            # 將 'path' 欄位進行字串操作\n",
    "            df_test['path'] = df_test['path'].str.rstrip('.wav')\n",
    "\n",
    "            # 使用 str.split 拆分 'path' 欄位\n",
    "            df_test[['session', 'role', 'number', 'start_time', 'end_time']] = df_test['path'].str.split('_', expand=True)\n",
    "\n",
    "            # 如果 'number' 欄位的末尾包含 '.wav'，進行一次額外的拆分\n",
    "            df_test['number'] = df_test['number'].str.rstrip('.wav')\n",
    "\n",
    "            # 將 'start_time' 和 'end_time' 欄位轉換為數值型別\n",
    "            df_test[['start_time', 'end_time']] = df_test[['start_time', 'end_time']].astype(int)\n",
    "\n",
    "            return df_test\n",
    "        df = Augment_info_df(df)\n",
    "\n",
    "\n",
    "        # Packer\n",
    "        def Packer(df_test) -> dict:\n",
    "            People_dict = dict(tuple(df_test.groupby('session')))\n",
    "            return People_dict\n",
    "\n",
    "        def Dialogueturn2corpus(data_frame, mode='text'): #mode can be 'pred_str' or 'text'\n",
    "            # 按 'start_time' 列進行排序\n",
    "            sorted_data_frame = data_frame.sort_values(by='start_time')\n",
    "\n",
    "            # 添加前綴並使用 '\\n' 進行拼接\n",
    "            processed_text = sorted_data_frame.apply(lambda row: f\"{row['role']}: {row[mode]}\", axis=1).str.cat(sep='\\n')\n",
    "\n",
    "            return processed_text\n",
    "\n",
    "        def filter_people_dict(People_dict, mode=\"INV+PAR\", verbose=False) -> dict:# 'INV' , 'PAR', 'INV+PAR'\n",
    "            filtered_people_dict = {}\n",
    "\n",
    "            for session, data_frame in People_dict.items():\n",
    "                # 使用 query 過濾 'role' 為 'INV' 或 'PAR'\n",
    "                if mode == \"PAR\":\n",
    "                    filtered_data_frame = data_frame.query(\"role == 'PAR'\")\n",
    "                    filtered_people_dict[session] = filtered_data_frame\n",
    "                elif mode == \"INV\":\n",
    "                    filtered_data_frame = data_frame.query(\"role == 'INV'\")\n",
    "                    filtered_people_dict[session] = filtered_data_frame\n",
    "                elif mode == \"INV+PAR\":\n",
    "                    filtered_people_dict[session] = data_frame\n",
    "                else:\n",
    "                    raise OSError\n",
    "            \n",
    "            if verbose:\n",
    "                # 印出過濾後的 People_dict 中每個 session 的 DataFrame\n",
    "                for session, data_frame in filtered_people_dict.items():\n",
    "                    print(f\"Session: {session}\")\n",
    "                    print(data_frame)\n",
    "                    print(\"\\n\")\n",
    "\n",
    "            return filtered_people_dict\n",
    "\n",
    "        # Dialogue Formatter\n",
    "        def Dialogue_Formatter(People_dict, sep=\"\\n\",role_mode='PAR')->dict:\n",
    "            session_df=pd.DataFrame()\n",
    "            for session, data_frame in People_dict.items():\n",
    "                if len(data_frame)>0:\n",
    "                    total_info=data_frame.iloc[0].copy()\n",
    "                    sessional_text = Dialogueturn2corpus(data_frame,mode='text')\n",
    "                    sessional_predStr = Dialogueturn2corpus(data_frame,mode='pred_str')\n",
    "                    \n",
    "                    # total_info,'text']=sessional_text\n",
    "                    # session_df.loc[session,'pred_str']=sessional_predStr\n",
    "                    # session_df.loc[session,'role']=role_mode\n",
    "                    # session_df.loc[session,'start_time']=data_frame['start_time'].min()\n",
    "                    # session_df.loc[session,'end_time']=data_frame['end_time'].max()\n",
    "\n",
    "                    total_info['text']=sessional_text\n",
    "                    total_info['pred_str']=sessional_predStr\n",
    "                    total_info['role']=role_mode\n",
    "                    total_info['start_time']=data_frame['start_time'].min()\n",
    "                    total_info['end_time']=data_frame['end_time'].max()\n",
    "                    session_df = pd.concat([session_df, pd.DataFrame([total_info], index=[session])])\n",
    "                else:\n",
    "                    print(f\"Session {session} has no data\")\n",
    "            return session_df\n",
    "        df_train = df[df['ex'] == 'train']\n",
    "        df_val = df[df['ex'] == 'dev']\n",
    "        df_test = df[df['ex'] == 'test']\n",
    "\n",
    "        def SentenceLvldf2SessionLvldf(df, role_mode=\"PAR\"):\n",
    "            People_dict=Packer(df)\n",
    "            People_dict = filter_people_dict(People_dict, mode=role_mode, verbose=False)\n",
    "            df_dialogue=Dialogue_Formatter(People_dict,role_mode)\n",
    "            return df_dialogue\n",
    "\n",
    "        df_train=SentenceLvldf2SessionLvldf(df_train)\n",
    "        df_val=SentenceLvldf2SessionLvldf(df_val)\n",
    "        df_test=SentenceLvldf2SessionLvldf(df_test)\n",
    "\n",
    "        def Tokenize(df_data):\n",
    "            df_data[t_col_name] = df_data[t_col_name].map(lambda x: self.t_tokenizer.encode(\n",
    "                str(x),\n",
    "                padding = 'max_length',\n",
    "                max_length=self.args.max_length,\n",
    "                truncation=True,\n",
    "                ))\n",
    "            return df_data\n",
    "        df_train=Tokenize(df_train)\n",
    "        df_val=Tokenize(df_val)\n",
    "        df_test=Tokenize(df_test)\n",
    "        df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "        # audio_root=\"/mnt/Internal/FedASR/Data/ADReSS-IS2020-data/clips\"\n",
    "        # # 원래 길이: 562992, batch 16: 90000, batch 8: 140000\n",
    "        # # max_length=16000, truncation=True 이건 일단 돌려보고 결정 => 뒤쪽, 앞에쪽 뭐보면 좋을 지 그런거 check하면 좋으니까! \n",
    "        # df[a_col_name] = df[a_col_name].map(lambda x: self.a_tokenizer(\n",
    "        #     f\"{audio_root}/{x}\",\n",
    "        #     sampling_rate = tg_sr,\n",
    "        #     max_length=100000, \n",
    "        #     truncation=True\n",
    "        #     )['input_values'][0])\n",
    "        def get_sessiondf_summary(session_df, prompt_template, chatopenai, Sensitive_replace_dict, use_text='text'):\n",
    "            Summary_dict, Prompt_dict = {}, {}, {}\n",
    "            for session, row in session_df.iterrows():\n",
    "                if session in Sensitive_replace_dict.keys():\n",
    "                    dialogue_content = row[use_text]\n",
    "                    for values in Sensitive_replace_dict[session]:\n",
    "                        dialogue_content = dialogue_content.replace(values[0], values[1])\n",
    "                    \n",
    "                else:\n",
    "                    dialogue_content = row[use_text]\n",
    "\n",
    "                prompt=prompt_template.format(dialogue_content=dialogue_content)\n",
    "                ans_middle = chatopenai.invoke(prompt)\n",
    "\n",
    "                output_parser = StrOutputParser()\n",
    "                summary = output_parser.parse(ans_middle).content\n",
    "                Summary_dict[session] = summary\n",
    "                Prompt_dict[session] = prompt\n",
    "\n",
    "            session_df['Psych_Summary'] = session_df.index.to_series().apply(lambda x: Summary_dict.get(x, []))\n",
    "            session_df['Psych_Prompt'] = session_df.index.to_series().apply(lambda x: Prompt_dict.get(x, []))\n",
    "            return session_df\n",
    "        if self.process_summary:\n",
    "            df_train=get_sessiondf_summary(df_train, self.result_prompts, self.chatopenai, Sensitive_replace_dict, use_text='text')\n",
    "            df_val=get_sessiondf_summary(df_val, self.result_prompts, self.chatopenai, Sensitive_replace_dict, use_text='text')\n",
    "            df_test=get_sessiondf_summary(df_test, self.result_prompts, self.chatopenai, Sensitive_replace_dict, use_text='text')\n",
    "\n",
    "        self.train_data = TensorDataset(\n",
    "            torch.tensor(df_train[t_col_name].tolist(), dtype=torch.long),\n",
    "            # torch.tensor(df_train[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_train[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "        \n",
    "        self.val_data = TensorDataset(\n",
    "             torch.tensor(df_val[t_col_name].tolist(), dtype=torch.long),\n",
    "            #  torch.tensor(df_val[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_val[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        self.test_data = TensorDataset(\n",
    "             torch.tensor(df_test[t_col_name].tolist(), dtype=torch.long),\n",
    "            #  torch.tensor(df_test[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_test[self.label_cols].tolist(), dtype=torch.long),\n",
    "             torch.tensor(df_test.index.tolist(), dtype=torch.long),\n",
    "        )\n",
    "    \n",
    "    def preprocess_loaded_summaries(self):\n",
    "        df_train = pd.read_pickle(f\"{config.summary_dir_in}/train.pkl\")\n",
    "        df_val = pd.read_pickle(f\"{config.summary_dir_in}/dev.pkl\")\n",
    "        df_test = pd.read_pickle(f\"{config.summary_dir_in}/test.pkl\")\n",
    "\n",
    "        t_col_name='Psych_Summary'\n",
    "\n",
    "        def Tokenize(df_data):\n",
    "            df_data[t_col_name] = df_data[t_col_name].map(lambda x: self.t_tokenizer.encode(\n",
    "                str(x),\n",
    "                padding = 'max_length',\n",
    "                max_length=self.args.max_length,\n",
    "                truncation=True,\n",
    "                ))\n",
    "            return df_data\n",
    "        df_train=Tokenize(df_train)\n",
    "        df_val=Tokenize(df_val)\n",
    "        df_test=Tokenize(df_test)\n",
    "        df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "        self.train_data = TensorDataset(\n",
    "            torch.tensor(df_train[t_col_name].tolist(), dtype=torch.long),\n",
    "            # torch.tensor(df_train[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_train[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        self.val_data = TensorDataset(\n",
    "                torch.tensor(df_val[t_col_name].tolist(), dtype=torch.long),\n",
    "            #  torch.tensor(df_val[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_val[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        self.test_data = TensorDataset(\n",
    "                torch.tensor(df_test[t_col_name].tolist(), dtype=torch.long),\n",
    "            #  torch.tensor(df_test[a_col_name].tolist(), dtype=torch.float),\n",
    "            torch.tensor(df_test[self.label_cols].tolist(), dtype=torch.long),\n",
    "                torch.tensor(df_test.index.tolist(), dtype=torch.long),\n",
    "        )\n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        return DataLoader(\n",
    "            self.train_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.args.cpu_workers,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "\n",
    "        return DataLoader(\n",
    "            self.val_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.args.cpu_workers,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "\n",
    "        return DataLoader(\n",
    "            self.test_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.args.cpu_workers,\n",
    "        )\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # token, audio, labels = batch  \n",
    "        token,  labels = batch  \n",
    "        # logits = self(token, audio) \n",
    "        logits = self(token) \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)   \n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # token, audio, labels = batch  \n",
    "        token, labels = batch  \n",
    "        # logits = self(token, audio) \n",
    "        logits = self(token) \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)     \n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true = list(labels.cpu().numpy())\n",
    "        y_pred = list(preds.cpu().numpy())\n",
    "\n",
    "        # --> HERE STEP 2 <--\n",
    "        self.val_step_outputs.append({\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        })\n",
    "        # self.val_step_targets.append(y_true)\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "        \n",
    "            \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # token, audio, labels,id_ = batch \n",
    "        token, labels,id_ = batch \n",
    "        print('id', id_)\n",
    "        # logits = self(token, audio) \n",
    "        logits = self(token) \n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true = list(labels.cpu().numpy())\n",
    "        y_pred = list(preds.cpu().numpy())\n",
    "\n",
    "        # --> HERE STEP 2 <--\n",
    "        self.test_step_outputs.append({\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        })\n",
    "        # self.test_step_targets.append(y_true)\n",
    "        return {\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = torch.tensor(0, dtype=torch.float)\n",
    "        # print(\"Value= \",self.val_step_outputs)\n",
    "        # print(\"type(self.val_step_outputs)=\",type(self.val_step_outputs))\n",
    "        # print(\"type(self.val_step_outputs[0])=\",type(self.val_step_outputs[0]))\n",
    "        # print(\"type(self.val_step_outputs[0] loss)=\",type(self.val_step_outputs[0]['loss']))\n",
    "        for i in self.val_step_outputs:\n",
    "            loss += i['loss'].cpu().detach()\n",
    "        _loss = loss / len(self.val_step_outputs)\n",
    "        loss = float(_loss)\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in self.val_step_outputs:\n",
    "            y_true += i['y_true']\n",
    "            y_pred += i['y_pred']\n",
    "            \n",
    "        y_pred = np.asanyarray(y_pred)#y_temp_pred y_pred\n",
    "        y_true = np.asanyarray(y_true)\n",
    "        \n",
    "        pred_dict = {}\n",
    "        pred_dict['y_pred']= y_pred\n",
    "        pred_dict['y_true']= y_true\n",
    "        \n",
    "        val_acc = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "        \n",
    "        self.log(\"val_acc\", val_acc)\n",
    "        # print(\"y_pred= \", y_pred)\n",
    "        # print('\\n\\n\\n')\n",
    "        # print(\"y_true= \", y_true)\n",
    "        # print('\\n\\n\\n')\n",
    "        print(\"-------val_report-------\")\n",
    "        metrics_dict = classification_report(y_true, y_pred,zero_division=1,\n",
    "                                             target_names = self.label_names, \n",
    "                                             output_dict=True)\n",
    "        df_result = pd.DataFrame(metrics_dict).transpose()\n",
    "        pprint(df_result)\n",
    "        \n",
    "        Output_dir=f\"{SaveRoot}/result\"\n",
    "        os.makedirs(Output_dir, exist_ok=True)\n",
    "        df_result.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_val.csv')\n",
    "\n",
    "        pred_df = pd.DataFrame(pred_dict)\n",
    "        pred_df.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_val_pred.csv')\n",
    "        self.val_step_outputs.clear()\n",
    "        # self.val_step_targets.clear()\n",
    "        return {'loss': _loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in self.test_step_outputs:\n",
    "            y_true += i['y_true']\n",
    "            y_pred += i['y_pred']\n",
    "            \n",
    "        y_pred = np.asanyarray(y_pred)#y_temp_pred y_pred\n",
    "        y_true = np.asanyarray(y_true)\n",
    "        \n",
    "        pred_dict = {}\n",
    "        pred_dict['y_pred']= y_pred\n",
    "        pred_dict['y_true']= y_true\n",
    "        \n",
    "        \n",
    "        print(\"-------test_report-------\")\n",
    "        metrics_dict = classification_report(y_true, y_pred,zero_division=1,\n",
    "                                             target_names = self.label_names, \n",
    "                                             output_dict=True)\n",
    "        df_result = pd.DataFrame(metrics_dict).transpose()\n",
    "        self.test_step_outputs.clear()\n",
    "        # self.test_step_targets.clear()\n",
    "        pprint(df_result)\n",
    "        \n",
    "        Output_dir=f\"{SaveRoot}/result\"\n",
    "        os.makedirs(Output_dir, exist_ok=True)\n",
    "        df_result.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_test.csv')\n",
    "\n",
    "        pred_df = pd.DataFrame(pred_dict)\n",
    "        pred_df.to_csv(\n",
    "            f'{Output_dir}/{datetime.now().__format__(\"%m%d_%H%M\")}_DM_MM_{self.t_embed_type}_{self.a_embed_type}_test_pred.csv')\n",
    "\n",
    "    # def preprocess_existing_summary_dataframe():\n",
    "\n",
    "def main(args,config):\n",
    "    print(\"Using PyTorch Ver\", torch.__version__)\n",
    "    print(\"Fix Seed:\", config['random_seed'])\n",
    "    seed_everything( config['random_seed'])\n",
    "        \n",
    "    model = Model(args,config) \n",
    "    # model.preprocess_dataframe()\n",
    "    model.preprocess_loaded_summaries()\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=f\"{SaveRoot}/Model/checkpoints\",\n",
    "        monitor='val_acc',\n",
    "        auto_insert_metric_name=True,\n",
    "        verbose=True,\n",
    "        mode='max', \n",
    "        save_top_k=1,\n",
    "      )    \n",
    "\n",
    "    print(\":: Start Training ::\")\n",
    "    #     \n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        callbacks=[early_stop_callback,checkpoint_callback],\n",
    "        enable_checkpointing = True,\n",
    "        max_epochs=args.epochs,\n",
    "        fast_dev_run=args.test_mode,\n",
    "        num_sanity_val_steps=None if args.test_mode else 0,\n",
    "        deterministic=True, # ensure full reproducibility from run to run you need to set seeds for pseudo-random generators,\n",
    "        # For GPU Setup\n",
    "        # gpus=[config['gpu']] if torch.cuda.is_available() else None,\n",
    "        precision=16 if args.fp16 else 32\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model,dataloaders=model.test_dataloader(),ckpt_path=\"best\")\n",
    "    \n",
    "if __name__ == '__main__': \n",
    "\n",
    "    parser = argparse.ArgumentParser(\"main.py\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\"--gpu\", type=int, default=1)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=5)\n",
    "    parser.add_argument(\"--lr\", type=float, default=2e-5, help=\"learning rate\")\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=2023) \n",
    "    parser.add_argument(\"--t_embed\", type=str, default=\"mbert\") \n",
    "    parser.add_argument(\"--a_embed\", type=str, default=\"en\") \n",
    "    parser.add_argument(\"--SaveRoot\", type=str, default='/mnt/External/Seagate/FedASR/LLaMa2/dacs') \n",
    "    parser.add_argument(\"--file_in\", type=str, default='/home/FedASR/dacs/centralized/saves/results/data2vec-audio-large-960h_total.csv') \n",
    "    parser.add_argument(\"--process_summary\", type=bool, default=False) \n",
    "    parser.add_argument(\"--summary_dir_in\", type=str, default='/mnt/External/Seagate/FedASR/LLaMa2/dacs/EmbFeats/Lexical/Embeddings/text_data2vec-audio-large-960h_Phych-anomia') \n",
    "    \n",
    "    config = parser.parse_args(args=[])\n",
    "    SaveRoot=config.SaveRoot\n",
    "    \n",
    "    print(config)\n",
    "    args = Arg()\n",
    "    args.epochs=config.epochs\n",
    "    main(args,config.__dict__)       \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed en\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed xlm --a_embed en\n",
    "\n",
    "# don\n",
    "python 0207_DM_multi.py --gpu 0 --t_embed xlm --a_embed gr\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed gr\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "args.epochs=config.epochs\n",
    "\n",
    "model = Model(args,config.__dict__) \n",
    "self=model\n",
    "\n",
    "\n",
    "tg_sr = 16000\n",
    "       \n",
    "# df = pd.read_json('/mnt/Internal/FedASR/Data/230126_total_asr_data.json')\n",
    "df_train = pd.read_pickle(f\"{config.summary_dir_in}/train.pkl\")\n",
    "df_val = pd.read_pickle(f\"{config.summary_dir_in}/dev.pkl\")\n",
    "df_test = pd.read_pickle(f\"{config.summary_dir_in}/test.pkl\")\n",
    "\n",
    "t_col_name='Psych_Summary'\n",
    "\n",
    "def Tokenize(df_data):\n",
    "    df_data[t_col_name] = df_data[t_col_name].map(lambda x: self.t_tokenizer.encode(\n",
    "        str(x),\n",
    "        padding = 'max_length',\n",
    "        max_length=self.args.max_length,\n",
    "        truncation=True,\n",
    "        ))\n",
    "    return df_data\n",
    "df_train=Tokenize(df_train)\n",
    "df_val=Tokenize(df_val)\n",
    "df_test=Tokenize(df_test)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "self.train_data = TensorDataset(\n",
    "    torch.tensor(df_train[t_col_name].tolist(), dtype=torch.long),\n",
    "    # torch.tensor(df_train[a_col_name].tolist(), dtype=torch.float),\n",
    "    torch.tensor(df_train[self.label_cols].tolist(), dtype=torch.long),\n",
    ")\n",
    "\n",
    "self.val_data = TensorDataset(\n",
    "        torch.tensor(df_val[t_col_name].tolist(), dtype=torch.long),\n",
    "    #  torch.tensor(df_val[a_col_name].tolist(), dtype=torch.float),\n",
    "    torch.tensor(df_val[self.label_cols].tolist(), dtype=torch.long),\n",
    ")\n",
    "\n",
    "self.test_data = TensorDataset(\n",
    "        torch.tensor(df_test[t_col_name].tolist(), dtype=torch.long),\n",
    "    #  torch.tensor(df_test[a_col_name].tolist(), dtype=torch.float),\n",
    "    torch.tensor(df_test[self.label_cols].tolist(), dtype=torch.long),\n",
    "        torch.tensor(df_test.index.tolist(), dtype=torch.long),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>dementia_labels</th>\n",
       "      <th>pred_str</th>\n",
       "      <th>ID</th>\n",
       "      <th>mmse</th>\n",
       "      <th>session</th>\n",
       "      <th>role</th>\n",
       "      <th>number</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Psych_Summary</th>\n",
       "      <th>Psych_Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S160</th>\n",
       "      <td>S160_PAR_1_3957_12857</td>\n",
       "      <td>PAR: UH THIS BOY IS ABOUT TO FALL OFF OF THE S...</td>\n",
       "      <td>0</td>\n",
       "      <td>PAR: UH THIS BOY'S ABOUT TO FALL OFF OF THE ST...</td>\n",
       "      <td>S160</td>\n",
       "      <td>28.0</td>\n",
       "      <td>S160</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25308</td>\n",
       "      <td>[-0.017200241456827626, 0.016914930776282977, ...</td>\n",
       "      <td>detected problems:\\nEmpty speech: PAR's speech...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S161</th>\n",
       "      <td>S161_PAR_0_0_8530</td>\n",
       "      <td>PAR: UH A BOY WITH A COOKIE IN HIS ONE HAND AN...</td>\n",
       "      <td>0</td>\n",
       "      <td>PAR: A BOY WITH A COOKIE IN HIS ONE HAND AND H...</td>\n",
       "      <td>S161</td>\n",
       "      <td>29.0</td>\n",
       "      <td>S161</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73291</td>\n",
       "      <td>[-0.011408883298941883, 0.01720419362756741, 0...</td>\n",
       "      <td>Detected problems:\\n- Trailing off speech: \"AN...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S162</th>\n",
       "      <td>S162_INV_1_72967_74751</td>\n",
       "      <td>INV: IN THE PICTURE\\nPAR: I SEE UH TWO KIDS UP...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: O THE PICTURE\\nPAR: I SEE UH TWO KIDS UP ...</td>\n",
       "      <td>S162</td>\n",
       "      <td>24.0</td>\n",
       "      <td>S162</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74751</td>\n",
       "      <td>[-0.017208302246136026, -0.0005765883202629639...</td>\n",
       "      <td>detected problems: trailing off speech\\n\\nSumm...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S163</th>\n",
       "      <td>S163_PAR_0_3972_8850</td>\n",
       "      <td>INV: I'D LIKE YOU TO TELL ME ALL THE THINGS YO...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: I'D LIKE YOU TO TELL ME ALL THE THINGS YO...</td>\n",
       "      <td>S163</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S163</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75438</td>\n",
       "      <td>[-0.023935779514867146, -0.0017524650216672048...</td>\n",
       "      <td>detected problems: trailing off speech\\nSummar...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S164</th>\n",
       "      <td>S164_PAR_7_24016_27600</td>\n",
       "      <td>PAR: WELL HE'S INTO THE COOKIE JAR AND THE THE...</td>\n",
       "      <td>1</td>\n",
       "      <td>PAR: WELL IT'S INTO THE COOKIE JAR AND THE THE...</td>\n",
       "      <td>S164</td>\n",
       "      <td>21.0</td>\n",
       "      <td>S164</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>33208</td>\n",
       "      <td>[-0.01118055865047027, 0.029392665740456726, 0...</td>\n",
       "      <td>detected problems:\\n- Empty speech: The speake...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S165</th>\n",
       "      <td>S165_INV_10_86423_90174</td>\n",
       "      <td>INV: THAT IT'S NOT REAL CLEAR SO DO WANT YOU C...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: BAT IT'S NOT REAL CLEARS TO DO WHAT YOU C...</td>\n",
       "      <td>S165</td>\n",
       "      <td>15.0</td>\n",
       "      <td>S165</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>101287</td>\n",
       "      <td>[-0.010539898705052297, 0.008740892839361516, ...</td>\n",
       "      <td>Detected problems:\\n- Trailing off speech: PAR...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S166</th>\n",
       "      <td>S166_PAR_33_149371_160002</td>\n",
       "      <td>INV: PICTURE\\nPAR: OH IT'S THE SAME PICTURE\\nP...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: OKAY\\nPAR: OH IT'S THE SAME PICTURE\\nPAR:...</td>\n",
       "      <td>S166</td>\n",
       "      <td>29.0</td>\n",
       "      <td>S166</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>167767</td>\n",
       "      <td>[-0.023409109270509928, 0.02357328839984978, 0...</td>\n",
       "      <td>detected problems:\\n- Empty speech: PAR provid...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S167</th>\n",
       "      <td>S167_PAR_10_151227_161006</td>\n",
       "      <td>INV: JUST TELL ME WHAT'S HAPPENING IN THE PICT...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: JUST TELL ME WHAT'S HAPPENING IN THE PICT...</td>\n",
       "      <td>S167</td>\n",
       "      <td>28.0</td>\n",
       "      <td>S167</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>267007</td>\n",
       "      <td>[-0.019582836821966258, 0.022503438467869303, ...</td>\n",
       "      <td>Detected problems: \\n- Empty speech: PAR's spe...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S168</th>\n",
       "      <td>S168_PAR_2_16202_21324</td>\n",
       "      <td>PAR: WELL THE UH THE LITTLE BOY IS STEALING CO...</td>\n",
       "      <td>1</td>\n",
       "      <td>PAR: WELL THE UH A LITTLE BOY IS STEALING COOK...</td>\n",
       "      <td>S168</td>\n",
       "      <td>27.0</td>\n",
       "      <td>S168</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41262</td>\n",
       "      <td>[-0.02177493675064444, 0.010412626103897458, 0...</td>\n",
       "      <td>detected problems:\\n- Empty speech: PAR's spee...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S169</th>\n",
       "      <td>S169_PAR_2_15223_19034</td>\n",
       "      <td>INV: LOOK AT THIS PICTURE\\nINV: TELL ME EVERYT...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: LOOK AT THIS PICTURE\\nINV: TELL ME EVERYT...</td>\n",
       "      <td>S169</td>\n",
       "      <td>26.0</td>\n",
       "      <td>S169</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64857</td>\n",
       "      <td>[-0.029138698425263773, 0.00752970463807912, 0...</td>\n",
       "      <td>detected problems:\\n- Empty speech: The PAR's ...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S170</th>\n",
       "      <td>S170_PAR_1_7099_17758</td>\n",
       "      <td>PAR: I S SEE THIS WOMAN WHO'S STANDING BY THE ...</td>\n",
       "      <td>0</td>\n",
       "      <td>PAR: SEE THIS WOMAN IS STANDING BY THE SINK WA...</td>\n",
       "      <td>S170</td>\n",
       "      <td>28.0</td>\n",
       "      <td>S170</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40528</td>\n",
       "      <td>[-0.01742267403864414, 0.010395887197354122, 0...</td>\n",
       "      <td>detected problems:\\n- Empty speech: The speake...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S171</th>\n",
       "      <td>S171_PAR_2_26000_42894</td>\n",
       "      <td>INV: I'M GOING TO ASK YOU TO TAKE A LOOK AT TH...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: I'M GOING TO ASK YOU TO TAKE A LOOK AT TH...</td>\n",
       "      <td>S171</td>\n",
       "      <td>23.0</td>\n",
       "      <td>S171</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68202</td>\n",
       "      <td>[-0.013063071499074331, 0.004969197868464235, ...</td>\n",
       "      <td>detected problems:\\n- Empty speech\\n- Trailing...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S172</th>\n",
       "      <td>S172_PAR_5_31111_36133</td>\n",
       "      <td>INV: TAKE A LOOK AT THAT AND TELL ME EVERYTHIN...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: TAKE A LOOK AT THAT AND TELL ME EVERYTHIN...</td>\n",
       "      <td>S172</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S172</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>72884</td>\n",
       "      <td>[-0.017618706412876176, 0.01596906591579406, 0...</td>\n",
       "      <td>detected problems: \\n- Trailing off speech: PA...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S173</th>\n",
       "      <td>S173_PAR_7_44739_47017</td>\n",
       "      <td>INV: NOW I'M GOING TO SHOW YOU A PICTURE\\nINV:...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: NOW I'M GOING TO SHOW YOU A PICTURE\\nINV:...</td>\n",
       "      <td>S173</td>\n",
       "      <td>17.0</td>\n",
       "      <td>S173</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>75294</td>\n",
       "      <td>[-0.02399181166392612, 0.02215795358036029, 0....</td>\n",
       "      <td>detected problems: \\n\\nPAR's speech does not e...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S174</th>\n",
       "      <td>S174_PAR_7_65944_71860</td>\n",
       "      <td>INV: WHAT DO YOU SEE GOING ON\\nPAR: I SEE A LI...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: KO JUCK WHAT DO YOU SEE GOING ON\\nPAR: I ...</td>\n",
       "      <td>S174</td>\n",
       "      <td>29.0</td>\n",
       "      <td>S174</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>114629</td>\n",
       "      <td>[-0.0156752196455846, 0.010762393140391615, 0....</td>\n",
       "      <td>detected problems: \\n- Empty speech: The speak...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S175</th>\n",
       "      <td>S175_PAR_11_45382_46099</td>\n",
       "      <td>PAR: UH THE SINK'S RUNNING OVER\\nPAR: THE WATE...</td>\n",
       "      <td>0</td>\n",
       "      <td>PAR: UH THE SINK'S RUNNING OVER\\nPAR: THE WATE...</td>\n",
       "      <td>S175</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S175</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>120602</td>\n",
       "      <td>[-0.01542252257722733, 0.020441851920849786, 0...</td>\n",
       "      <td>detected problems:\\nEmpty speech: Eloquent art...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S176</th>\n",
       "      <td>S176_PAR_17_93832_94689</td>\n",
       "      <td>INV: ALL OF THE ACTION\\nPAR: WHEW\\nPAR: UH DO ...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: ALL OF THE ACTION\\nPAR: IHM\\nPAR: UMH DO ...</td>\n",
       "      <td>S176</td>\n",
       "      <td>27.0</td>\n",
       "      <td>S176</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>94689</td>\n",
       "      <td>[-0.016498148059967948, 0.014675220135390145, ...</td>\n",
       "      <td>Detected problems:\\n- Empty speech: PAR's spee...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S177</th>\n",
       "      <td>S177_PAR_8_37633_41944</td>\n",
       "      <td>INV: START WHENEVER YOU WANT\\nPAR: COOKIE JAR\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: START WHENEVER YOU WINTE\\nPAR: UH COOKIE ...</td>\n",
       "      <td>S177</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S177</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>105982</td>\n",
       "      <td>[-0.0017595761536363056, 0.006366498331891652,...</td>\n",
       "      <td>Detected problems: \\n- Empty speech: \"START WH...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S178</th>\n",
       "      <td>S178_PAR_6_31719_41122</td>\n",
       "      <td>PAR: A LITTLE GIRL IS REACHING FOR HER BROTHER...</td>\n",
       "      <td>0</td>\n",
       "      <td>PAR: UH THE LITTLE GIRL IS REACHING FOR HER BR...</td>\n",
       "      <td>S178</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S178</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>75545</td>\n",
       "      <td>[-0.021014778847333167, 0.007265109237362094, ...</td>\n",
       "      <td>detected problems: \\n- Empty speech: PAR's spe...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S179</th>\n",
       "      <td>S179_PAR_1_4016_8825</td>\n",
       "      <td>PAR: WELL THE TABLE THE SEAT IS FALLING\\nPAR: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>PAR: ON THE TABLE THE SEAM IS FALLING\\nPAR: TH...</td>\n",
       "      <td>S179</td>\n",
       "      <td>10.0</td>\n",
       "      <td>S179</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71112</td>\n",
       "      <td>[-0.009437096937888773, 0.008546678078926616, ...</td>\n",
       "      <td>detected problems: \\n- Empty speech: The utter...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S180</th>\n",
       "      <td>S180_PAR_1_15721_22041</td>\n",
       "      <td>INV: SEE GOING ON THERE\\nPAR: WELL THE BOY IS ...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: I COUN SEE GOING ON THON\\nPAR: WELL THE B...</td>\n",
       "      <td>S180</td>\n",
       "      <td>29.0</td>\n",
       "      <td>S180</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66818</td>\n",
       "      <td>[-0.02204846845042956, 0.007690075556504581, 0...</td>\n",
       "      <td>detected problems: \\n- Empty speech: The speak...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S181</th>\n",
       "      <td>S181_PAR_9_52341_55795</td>\n",
       "      <td>INV: WHAT DO YOU SEE GOING ON IN THAT PICTURE\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: WHAT DO YOU SEE GOING ON IN THAT PICTURE\\...</td>\n",
       "      <td>S181</td>\n",
       "      <td>17.0</td>\n",
       "      <td>S181</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>98237</td>\n",
       "      <td>[-0.018814830106520058, -0.0050965300364263924...</td>\n",
       "      <td>detected problems: trailing off speech\\nSummar...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S182</th>\n",
       "      <td>S182_INV_19_155667_157145</td>\n",
       "      <td>INV: WHAT'S HAPPENING IN THAT PICTURE\\nINV: WH...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: WHAT'S HAPPENING IN THAT PICTURE\\nINV: WH...</td>\n",
       "      <td>S182</td>\n",
       "      <td>12.0</td>\n",
       "      <td>S182</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>157145</td>\n",
       "      <td>[-0.016777639987730828, 0.005909546666281508, ...</td>\n",
       "      <td>detected problems:\\n- Empty speech: The PAR's ...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S183</th>\n",
       "      <td>S183_PAR_5_23051_30972</td>\n",
       "      <td>INV: I WANT YOU TO TELL ME EVERYTHING YOU SEE ...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: I WANT YOU TO TELL ME EVERYTHING YOU SEE ...</td>\n",
       "      <td>S183</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S183</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>97443</td>\n",
       "      <td>[-0.015054313462163862, 0.011930708577192113, ...</td>\n",
       "      <td>detected problems: \\n- Empty speech: The PAR p...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S184</th>\n",
       "      <td>S184_PAR_9_43610_45417</td>\n",
       "      <td>INV: TELL ME EVERYTHING THAT YOU SEE GOING ON ...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: TELL ME EVERYTHING THAT I SEE GOING ON IN...</td>\n",
       "      <td>S184</td>\n",
       "      <td>29.0</td>\n",
       "      <td>S184</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>100478</td>\n",
       "      <td>[0.0015690418099436455, -0.016748680447425682,...</td>\n",
       "      <td></td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S185</th>\n",
       "      <td>S185_PAR_1_5464_9590</td>\n",
       "      <td>INV: OKAY AND HERE'S THE PICTURE\\nINV: TELL ME...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: OKAY AND HERE'S THE PICTR\\nINV: TELL ME A...</td>\n",
       "      <td>S185</td>\n",
       "      <td>19.0</td>\n",
       "      <td>S185</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57880</td>\n",
       "      <td>[-0.011397738605338697, 0.014988060599226088, ...</td>\n",
       "      <td>detected problems:\\n- Empty speech: The PAR pr...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S186</th>\n",
       "      <td>S186_PAR_1_1963_7183</td>\n",
       "      <td>PAR: MHM\\nINV: AND THERE'S THE PICTURE\\nPAR: T...</td>\n",
       "      <td>0</td>\n",
       "      <td>PAR: MHM\\nINV: MHM\\nPAR: UN THE LITTLE BOY IS ...</td>\n",
       "      <td>S186</td>\n",
       "      <td>29.0</td>\n",
       "      <td>S186</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66897</td>\n",
       "      <td>[-0.003002290124395314, 0.025734882463847836, ...</td>\n",
       "      <td>detected problems:\\n- Empty speech: The PAR's ...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S187</th>\n",
       "      <td>S187_PAR_10_125088_136477</td>\n",
       "      <td>INV: AND THERE'S THE PICTURE\\nINV: ALL THE ACT...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: AND THERE'S THE PICTURE\\nINV: ALL THE ACT...</td>\n",
       "      <td>S187</td>\n",
       "      <td>18.0</td>\n",
       "      <td>S187</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>163188</td>\n",
       "      <td>[-0.008125194182623635, 0.017210270858352264, ...</td>\n",
       "      <td>Detected problems:\\n- Trailing off speech: In ...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S188</th>\n",
       "      <td>S188_PAR_2_37027_45491</td>\n",
       "      <td>INV: I JUST WANT YOU TO TELL ME EVERYTHING THA...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: I JUST WANT YOU TO TELL ME EVERYTHING THA...</td>\n",
       "      <td>S188</td>\n",
       "      <td>20.0</td>\n",
       "      <td>S188</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95467</td>\n",
       "      <td>[-0.023653150128251723, 0.008754191424517646, ...</td>\n",
       "      <td>detected problems:\\n- Trailing off speech: PAR...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S189</th>\n",
       "      <td>S189_PAR_4_17824_23860</td>\n",
       "      <td>INV: NOW THERE IT IS\\nPAR: ALRIGHT\\nPAR: UH TH...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: EH THERE IT IS\\nPAR: WA TINT\\nPAR: AND UH...</td>\n",
       "      <td>S189</td>\n",
       "      <td>20.0</td>\n",
       "      <td>S189</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>78733</td>\n",
       "      <td>[-0.012884860728218938, 0.010804914760267655, ...</td>\n",
       "      <td>detected problems:\\n- Empty speech: Eloquent a...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S190</th>\n",
       "      <td>S190_PAR_2_41182_54364</td>\n",
       "      <td>INV: HAVE A LOOK AT THAT PICTURE AND TELL ME E...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: HAVE A LOOK AT THAT PICTURE AND TELL ME E...</td>\n",
       "      <td>S190</td>\n",
       "      <td>13.0</td>\n",
       "      <td>S190</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>116198</td>\n",
       "      <td>[-0.02227273647255223, 0.012765429348586097, 0...</td>\n",
       "      <td>detected problems: \\nEmpty speech: The PAR's r...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S191</th>\n",
       "      <td>S191_INV_0_0_1713</td>\n",
       "      <td>INV: ON IN THE PICTURE\\nPAR: MHM\\nPAR: HM WELL...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: FOIN TO THE PICTURE\\nPAR: THAT'S ET\\nPAR:...</td>\n",
       "      <td>S191</td>\n",
       "      <td>22.0</td>\n",
       "      <td>S191</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135903</td>\n",
       "      <td>[-0.027742111493210667, 0.016615378517931767, ...</td>\n",
       "      <td>detected problems: \\nEmpty speech: PAR's respo...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S192</th>\n",
       "      <td>S192_PAR_13_120090_122241</td>\n",
       "      <td>INV: AND THERE'S THE PICTURE\\nINV: TELL ME ALL...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: AND THERE'S THE PICTURE\\nINV: TELL ME ALL...</td>\n",
       "      <td>S192</td>\n",
       "      <td>12.0</td>\n",
       "      <td>S192</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>127980</td>\n",
       "      <td>[-0.013981684870589546, -0.0008102332798393739...</td>\n",
       "      <td>Detected problems: \\n- Empty speech: PAR frequ...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S193</th>\n",
       "      <td>S193_PAR_13_57229_58410</td>\n",
       "      <td>INV: THAT YOU SEE GOING ON IN THE PICTURE\\nPAR...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: WHAT YOU SEE GOING ON IN THE PICTURE\\nPAR...</td>\n",
       "      <td>S193</td>\n",
       "      <td>24.0</td>\n",
       "      <td>S193</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>69851</td>\n",
       "      <td>[-0.019742048307550913, 0.018121634498715018, ...</td>\n",
       "      <td>detected problems: \\n- Empty speech\\n- Trailin...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S194</th>\n",
       "      <td>S194_INV_0_0_700</td>\n",
       "      <td>INV: PICTURE\\nINV: WHAT'S GOING ON IN THAT PIC...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: PICTURE\\nINV: WHAT'S GOING ON IN THAT PIC...</td>\n",
       "      <td>S194</td>\n",
       "      <td>11.0</td>\n",
       "      <td>S194</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35974</td>\n",
       "      <td>[-0.009621753460460705, 0.003454565238871823, ...</td>\n",
       "      <td>Detected problems: \\n- Empty speech: The PAR p...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S195</th>\n",
       "      <td>S195_PAR_9_39770_40528</td>\n",
       "      <td>INV: TELL ME EVERYTHING YOU SEE HAPPENING IN T...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: TELL ME EVERYTHING YOU SEE HAPPENING IN T...</td>\n",
       "      <td>S195</td>\n",
       "      <td>26.0</td>\n",
       "      <td>S195</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>41320</td>\n",
       "      <td>[-0.0021249447820338115, 0.02598543464806268, ...</td>\n",
       "      <td>detected problems:\\n- Trailing off speech: \"AN...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S196</th>\n",
       "      <td>S196_PAR_0_3969_8141</td>\n",
       "      <td>INV: OKAY GREAT\\nINV: AND THERE'S THE PICTURE\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: OKAY GOOD\\nINV: HOW MANY THN THERE TO THE...</td>\n",
       "      <td>S196</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S196</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41200</td>\n",
       "      <td>[-0.01859882289466125, 0.0020314583108699564, ...</td>\n",
       "      <td>detected problems:\\nEmpty speech: In the dialo...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S197</th>\n",
       "      <td>S197_INV_0_0_3222</td>\n",
       "      <td>INV: THIS PICTURE\\nINV: AND I WANT YOU TO TELL...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: THIS PICTURE\\nINV: AND I WANT YOU TO TELL...</td>\n",
       "      <td>S197</td>\n",
       "      <td>28.0</td>\n",
       "      <td>S197</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52779</td>\n",
       "      <td>[-0.014282264086954977, 0.005531532900060594, ...</td>\n",
       "      <td>detected problems:\\n- Empty speech: The PAR's ...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S198</th>\n",
       "      <td>S198_PAR_3_17378_19655</td>\n",
       "      <td>PAR: YOU MEAN LIKE THE WOMAN DOING THE DISHES ...</td>\n",
       "      <td>1</td>\n",
       "      <td>PAR: DO YOU MEAN LIKE THE WOMAN DOING THE DISH...</td>\n",
       "      <td>S198</td>\n",
       "      <td>19.0</td>\n",
       "      <td>S198</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51191</td>\n",
       "      <td>[-0.020178594912254166, 0.013416403475338916, ...</td>\n",
       "      <td>Detected problems: \\n- Empty speech: The speak...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S199</th>\n",
       "      <td>S199_PAR_1_12904_18004</td>\n",
       "      <td>INV: PLEASE SPEAK UP SO WE CAN HEAR YOU\\nPAR: ...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: OMS THAT'S EVERYTHING ERE\\nPAR: THERE'S U...</td>\n",
       "      <td>S199</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S199</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58009</td>\n",
       "      <td>[-0.018019140791406957, 0.008817146122220046, ...</td>\n",
       "      <td>detected problems:\\n- Empty speech\\n- Trailing...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S200</th>\n",
       "      <td>S200_PAR_4_21500_23579</td>\n",
       "      <td>INV: SEE GOING ON\\nPAR: SEEING THE MOTHER\\nPAR...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: HE GOT OM MOTCH\\nPAR: SEEING THE MOTHER\\n...</td>\n",
       "      <td>S200</td>\n",
       "      <td>25.0</td>\n",
       "      <td>S200</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40934</td>\n",
       "      <td>[-0.01397226463441031, -0.0019452706931580325,...</td>\n",
       "      <td>detected problems: \\n\\nEmpty speech: The state...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S201</th>\n",
       "      <td>S201_PAR_6_48605_53616</td>\n",
       "      <td>INV: OKAY THERE IT IS\\nINV: WHAT DO YOU SEE GO...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: OKAY EVIDENCE\\nINV: WHAT DO YOU SEE GOING...</td>\n",
       "      <td>S201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S201</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>57446</td>\n",
       "      <td>[-0.020321667180211007, 0.012150132837827668, ...</td>\n",
       "      <td>detected problems:\\n- Empty speech: The PAR pr...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S202</th>\n",
       "      <td>S202_PAR_2_23504_23887</td>\n",
       "      <td>INV: I WANT YOU TO TELL ME EVERYTHING THAT YOU...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: I WANT YOU TO TELL ME EVERYTHING THAT YOU...</td>\n",
       "      <td>S202</td>\n",
       "      <td>30.0</td>\n",
       "      <td>S202</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>78329</td>\n",
       "      <td>[-0.017056077172014118, -0.001045339239387044,...</td>\n",
       "      <td>detected problems: \\n- Empty speech: PAR's res...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S203</th>\n",
       "      <td>S203_PAR_3_26519_30011</td>\n",
       "      <td>INV: GETTING IN THE PICTURE\\nINV: ALL THE ACTI...</td>\n",
       "      <td>1</td>\n",
       "      <td>INV: HOW MANY GOING ON IN THE PICTURE\\nINV: AL...</td>\n",
       "      <td>S203</td>\n",
       "      <td>18.0</td>\n",
       "      <td>S203</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50858</td>\n",
       "      <td>[-0.017804934583466395, 0.008595721317696607, ...</td>\n",
       "      <td>detected problems:\\n- Empty speech: The speake...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S204</th>\n",
       "      <td>S204_PAR_0_4467_9075</td>\n",
       "      <td>INV: WHAT YOU SEE HAPPENING IN THAT PICTURE\\nI...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: WAN THAT YOU SEE HAPPENING IN THAT PICTUR...</td>\n",
       "      <td>S204</td>\n",
       "      <td>28.0</td>\n",
       "      <td>S204</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38586</td>\n",
       "      <td>[-0.0041423884474207605, -0.002759343542451781...</td>\n",
       "      <td>detected problems: trailing off speech\\nSummar...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S205</th>\n",
       "      <td>S205_INV_3_37758_38450</td>\n",
       "      <td>INV: TAKE A LOOK AT THAT PICTURE AND TELL ME E...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: WELL TAKE A LOOK AT THAT PICTURE AND TELL...</td>\n",
       "      <td>S205</td>\n",
       "      <td>23.0</td>\n",
       "      <td>S205</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>59299</td>\n",
       "      <td>[-0.004579121383329486, 0.02591802815807409, 0...</td>\n",
       "      <td>detected problems: \\nEmpty speech: The PAR pro...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S206</th>\n",
       "      <td>S206_INV_1_3966_7083</td>\n",
       "      <td>INV: I WANT YOU TO TELL ME EVERYTHING THAT YOU...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: I WANT YOU TO TELL ME EVERYTHING THAT YOU...</td>\n",
       "      <td>S206</td>\n",
       "      <td>28.0</td>\n",
       "      <td>S206</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76182</td>\n",
       "      <td>[-0.0074447772256718845, 0.008405173789683543,...</td>\n",
       "      <td>Detected problems:\\n- Trailing off speech: In ...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S207</th>\n",
       "      <td>S207_PAR_1_7624_11845</td>\n",
       "      <td>INV: JUST TELL ME ALL OF THE ACTION\\nPAR: LITT...</td>\n",
       "      <td>0</td>\n",
       "      <td>INV: JUST TELL ME ALL OF THE ACTION\\nPAR: BO H...</td>\n",
       "      <td>S207</td>\n",
       "      <td>27.0</td>\n",
       "      <td>S207</td>\n",
       "      <td>INV+PAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48372</td>\n",
       "      <td>[-0.022953584155319114, -0.006614187620455314,...</td>\n",
       "      <td>detected problems: trailing off speech\\nSummar...</td>\n",
       "      <td>psycological definition:\\n\\n            - defi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  \\\n",
       "S160      S160_PAR_1_3957_12857   \n",
       "S161          S161_PAR_0_0_8530   \n",
       "S162     S162_INV_1_72967_74751   \n",
       "S163       S163_PAR_0_3972_8850   \n",
       "S164     S164_PAR_7_24016_27600   \n",
       "S165    S165_INV_10_86423_90174   \n",
       "S166  S166_PAR_33_149371_160002   \n",
       "S167  S167_PAR_10_151227_161006   \n",
       "S168     S168_PAR_2_16202_21324   \n",
       "S169     S169_PAR_2_15223_19034   \n",
       "S170      S170_PAR_1_7099_17758   \n",
       "S171     S171_PAR_2_26000_42894   \n",
       "S172     S172_PAR_5_31111_36133   \n",
       "S173     S173_PAR_7_44739_47017   \n",
       "S174     S174_PAR_7_65944_71860   \n",
       "S175    S175_PAR_11_45382_46099   \n",
       "S176    S176_PAR_17_93832_94689   \n",
       "S177     S177_PAR_8_37633_41944   \n",
       "S178     S178_PAR_6_31719_41122   \n",
       "S179       S179_PAR_1_4016_8825   \n",
       "S180     S180_PAR_1_15721_22041   \n",
       "S181     S181_PAR_9_52341_55795   \n",
       "S182  S182_INV_19_155667_157145   \n",
       "S183     S183_PAR_5_23051_30972   \n",
       "S184     S184_PAR_9_43610_45417   \n",
       "S185       S185_PAR_1_5464_9590   \n",
       "S186       S186_PAR_1_1963_7183   \n",
       "S187  S187_PAR_10_125088_136477   \n",
       "S188     S188_PAR_2_37027_45491   \n",
       "S189     S189_PAR_4_17824_23860   \n",
       "S190     S190_PAR_2_41182_54364   \n",
       "S191          S191_INV_0_0_1713   \n",
       "S192  S192_PAR_13_120090_122241   \n",
       "S193    S193_PAR_13_57229_58410   \n",
       "S194           S194_INV_0_0_700   \n",
       "S195     S195_PAR_9_39770_40528   \n",
       "S196       S196_PAR_0_3969_8141   \n",
       "S197          S197_INV_0_0_3222   \n",
       "S198     S198_PAR_3_17378_19655   \n",
       "S199     S199_PAR_1_12904_18004   \n",
       "S200     S200_PAR_4_21500_23579   \n",
       "S201     S201_PAR_6_48605_53616   \n",
       "S202     S202_PAR_2_23504_23887   \n",
       "S203     S203_PAR_3_26519_30011   \n",
       "S204       S204_PAR_0_4467_9075   \n",
       "S205     S205_INV_3_37758_38450   \n",
       "S206       S206_INV_1_3966_7083   \n",
       "S207      S207_PAR_1_7624_11845   \n",
       "\n",
       "                                                   text  dementia_labels  \\\n",
       "S160  PAR: UH THIS BOY IS ABOUT TO FALL OFF OF THE S...                0   \n",
       "S161  PAR: UH A BOY WITH A COOKIE IN HIS ONE HAND AN...                0   \n",
       "S162  INV: IN THE PICTURE\\nPAR: I SEE UH TWO KIDS UP...                0   \n",
       "S163  INV: I'D LIKE YOU TO TELL ME ALL THE THINGS YO...                0   \n",
       "S164  PAR: WELL HE'S INTO THE COOKIE JAR AND THE THE...                1   \n",
       "S165  INV: THAT IT'S NOT REAL CLEAR SO DO WANT YOU C...                0   \n",
       "S166  INV: PICTURE\\nPAR: OH IT'S THE SAME PICTURE\\nP...                0   \n",
       "S167  INV: JUST TELL ME WHAT'S HAPPENING IN THE PICT...                1   \n",
       "S168  PAR: WELL THE UH THE LITTLE BOY IS STEALING CO...                1   \n",
       "S169  INV: LOOK AT THIS PICTURE\\nINV: TELL ME EVERYT...                1   \n",
       "S170  PAR: I S SEE THIS WOMAN WHO'S STANDING BY THE ...                0   \n",
       "S171  INV: I'M GOING TO ASK YOU TO TAKE A LOOK AT TH...                1   \n",
       "S172  INV: TAKE A LOOK AT THAT AND TELL ME EVERYTHIN...                0   \n",
       "S173  INV: NOW I'M GOING TO SHOW YOU A PICTURE\\nINV:...                1   \n",
       "S174  INV: WHAT DO YOU SEE GOING ON\\nPAR: I SEE A LI...                0   \n",
       "S175  PAR: UH THE SINK'S RUNNING OVER\\nPAR: THE WATE...                0   \n",
       "S176  INV: ALL OF THE ACTION\\nPAR: WHEW\\nPAR: UH DO ...                1   \n",
       "S177  INV: START WHENEVER YOU WANT\\nPAR: COOKIE JAR\\...                0   \n",
       "S178  PAR: A LITTLE GIRL IS REACHING FOR HER BROTHER...                0   \n",
       "S179  PAR: WELL THE TABLE THE SEAT IS FALLING\\nPAR: ...                1   \n",
       "S180  INV: SEE GOING ON THERE\\nPAR: WELL THE BOY IS ...                0   \n",
       "S181  INV: WHAT DO YOU SEE GOING ON IN THAT PICTURE\\...                1   \n",
       "S182  INV: WHAT'S HAPPENING IN THAT PICTURE\\nINV: WH...                0   \n",
       "S183  INV: I WANT YOU TO TELL ME EVERYTHING YOU SEE ...                0   \n",
       "S184  INV: TELL ME EVERYTHING THAT YOU SEE GOING ON ...                0   \n",
       "S185  INV: OKAY AND HERE'S THE PICTURE\\nINV: TELL ME...                1   \n",
       "S186  PAR: MHM\\nINV: AND THERE'S THE PICTURE\\nPAR: T...                0   \n",
       "S187  INV: AND THERE'S THE PICTURE\\nINV: ALL THE ACT...                1   \n",
       "S188  INV: I JUST WANT YOU TO TELL ME EVERYTHING THA...                1   \n",
       "S189  INV: NOW THERE IT IS\\nPAR: ALRIGHT\\nPAR: UH TH...                1   \n",
       "S190  INV: HAVE A LOOK AT THAT PICTURE AND TELL ME E...                1   \n",
       "S191  INV: ON IN THE PICTURE\\nPAR: MHM\\nPAR: HM WELL...                0   \n",
       "S192  INV: AND THERE'S THE PICTURE\\nINV: TELL ME ALL...                1   \n",
       "S193  INV: THAT YOU SEE GOING ON IN THE PICTURE\\nPAR...                0   \n",
       "S194  INV: PICTURE\\nINV: WHAT'S GOING ON IN THAT PIC...                0   \n",
       "S195  INV: TELL ME EVERYTHING YOU SEE HAPPENING IN T...                0   \n",
       "S196  INV: OKAY GREAT\\nINV: AND THERE'S THE PICTURE\\...                0   \n",
       "S197  INV: THIS PICTURE\\nINV: AND I WANT YOU TO TELL...                0   \n",
       "S198  PAR: YOU MEAN LIKE THE WOMAN DOING THE DISHES ...                1   \n",
       "S199  INV: PLEASE SPEAK UP SO WE CAN HEAR YOU\\nPAR: ...                0   \n",
       "S200  INV: SEE GOING ON\\nPAR: SEEING THE MOTHER\\nPAR...                1   \n",
       "S201  INV: OKAY THERE IT IS\\nINV: WHAT DO YOU SEE GO...                0   \n",
       "S202  INV: I WANT YOU TO TELL ME EVERYTHING THAT YOU...                0   \n",
       "S203  INV: GETTING IN THE PICTURE\\nINV: ALL THE ACTI...                1   \n",
       "S204  INV: WHAT YOU SEE HAPPENING IN THAT PICTURE\\nI...                0   \n",
       "S205  INV: TAKE A LOOK AT THAT PICTURE AND TELL ME E...                0   \n",
       "S206  INV: I WANT YOU TO TELL ME EVERYTHING THAT YOU...                0   \n",
       "S207  INV: JUST TELL ME ALL OF THE ACTION\\nPAR: LITT...                0   \n",
       "\n",
       "                                               pred_str ID     mmse session  \\\n",
       "S160  PAR: UH THIS BOY'S ABOUT TO FALL OFF OF THE ST...  S160  28.0    S160   \n",
       "S161  PAR: A BOY WITH A COOKIE IN HIS ONE HAND AND H...  S161  29.0    S161   \n",
       "S162  INV: O THE PICTURE\\nPAR: I SEE UH TWO KIDS UP ...  S162  24.0    S162   \n",
       "S163  INV: I'D LIKE YOU TO TELL ME ALL THE THINGS YO...  S163  30.0    S163   \n",
       "S164  PAR: WELL IT'S INTO THE COOKIE JAR AND THE THE...  S164  21.0    S164   \n",
       "S165  INV: BAT IT'S NOT REAL CLEARS TO DO WHAT YOU C...  S165  15.0    S165   \n",
       "S166  INV: OKAY\\nPAR: OH IT'S THE SAME PICTURE\\nPAR:...  S166  29.0    S166   \n",
       "S167  INV: JUST TELL ME WHAT'S HAPPENING IN THE PICT...  S167  28.0    S167   \n",
       "S168  PAR: WELL THE UH A LITTLE BOY IS STEALING COOK...  S168  27.0    S168   \n",
       "S169  INV: LOOK AT THIS PICTURE\\nINV: TELL ME EVERYT...  S169  26.0    S169   \n",
       "S170  PAR: SEE THIS WOMAN IS STANDING BY THE SINK WA...  S170  28.0    S170   \n",
       "S171  INV: I'M GOING TO ASK YOU TO TAKE A LOOK AT TH...  S171  23.0    S171   \n",
       "S172  INV: TAKE A LOOK AT THAT AND TELL ME EVERYTHIN...  S172  30.0    S172   \n",
       "S173  INV: NOW I'M GOING TO SHOW YOU A PICTURE\\nINV:...  S173  17.0    S173   \n",
       "S174  INV: KO JUCK WHAT DO YOU SEE GOING ON\\nPAR: I ...  S174  29.0    S174   \n",
       "S175  PAR: UH THE SINK'S RUNNING OVER\\nPAR: THE WATE...  S175  30.0    S175   \n",
       "S176  INV: ALL OF THE ACTION\\nPAR: IHM\\nPAR: UMH DO ...  S176  27.0    S176   \n",
       "S177  INV: START WHENEVER YOU WINTE\\nPAR: UH COOKIE ...  S177  30.0    S177   \n",
       "S178  PAR: UH THE LITTLE GIRL IS REACHING FOR HER BR...  S178  30.0    S178   \n",
       "S179  PAR: ON THE TABLE THE SEAM IS FALLING\\nPAR: TH...  S179  10.0    S179   \n",
       "S180  INV: I COUN SEE GOING ON THON\\nPAR: WELL THE B...  S180  29.0    S180   \n",
       "S181  INV: WHAT DO YOU SEE GOING ON IN THAT PICTURE\\...  S181  17.0    S181   \n",
       "S182  INV: WHAT'S HAPPENING IN THAT PICTURE\\nINV: WH...  S182  12.0    S182   \n",
       "S183  INV: I WANT YOU TO TELL ME EVERYTHING YOU SEE ...  S183  30.0    S183   \n",
       "S184  INV: TELL ME EVERYTHING THAT I SEE GOING ON IN...  S184  29.0    S184   \n",
       "S185  INV: OKAY AND HERE'S THE PICTR\\nINV: TELL ME A...  S185  19.0    S185   \n",
       "S186  PAR: MHM\\nINV: MHM\\nPAR: UN THE LITTLE BOY IS ...  S186  29.0    S186   \n",
       "S187  INV: AND THERE'S THE PICTURE\\nINV: ALL THE ACT...  S187  18.0    S187   \n",
       "S188  INV: I JUST WANT YOU TO TELL ME EVERYTHING THA...  S188  20.0    S188   \n",
       "S189  INV: EH THERE IT IS\\nPAR: WA TINT\\nPAR: AND UH...  S189  20.0    S189   \n",
       "S190  INV: HAVE A LOOK AT THAT PICTURE AND TELL ME E...  S190  13.0    S190   \n",
       "S191  INV: FOIN TO THE PICTURE\\nPAR: THAT'S ET\\nPAR:...  S191  22.0    S191   \n",
       "S192  INV: AND THERE'S THE PICTURE\\nINV: TELL ME ALL...  S192  12.0    S192   \n",
       "S193  INV: WHAT YOU SEE GOING ON IN THE PICTURE\\nPAR...  S193  24.0    S193   \n",
       "S194  INV: PICTURE\\nINV: WHAT'S GOING ON IN THAT PIC...  S194  11.0    S194   \n",
       "S195  INV: TELL ME EVERYTHING YOU SEE HAPPENING IN T...  S195  26.0    S195   \n",
       "S196  INV: OKAY GOOD\\nINV: HOW MANY THN THERE TO THE...  S196  30.0    S196   \n",
       "S197  INV: THIS PICTURE\\nINV: AND I WANT YOU TO TELL...  S197  28.0    S197   \n",
       "S198  PAR: DO YOU MEAN LIKE THE WOMAN DOING THE DISH...  S198  19.0    S198   \n",
       "S199  INV: OMS THAT'S EVERYTHING ERE\\nPAR: THERE'S U...  S199  30.0    S199   \n",
       "S200  INV: HE GOT OM MOTCH\\nPAR: SEEING THE MOTHER\\n...  S200  25.0    S200   \n",
       "S201  INV: OKAY EVIDENCE\\nINV: WHAT DO YOU SEE GOING...  S201  30.0    S201   \n",
       "S202  INV: I WANT YOU TO TELL ME EVERYTHING THAT YOU...  S202  30.0    S202   \n",
       "S203  INV: HOW MANY GOING ON IN THE PICTURE\\nINV: AL...  S203  18.0    S203   \n",
       "S204  INV: WAN THAT YOU SEE HAPPENING IN THAT PICTUR...  S204  28.0    S204   \n",
       "S205  INV: WELL TAKE A LOOK AT THAT PICTURE AND TELL...  S205  23.0    S205   \n",
       "S206  INV: I WANT YOU TO TELL ME EVERYTHING THAT YOU...  S206  28.0    S206   \n",
       "S207  INV: JUST TELL ME ALL OF THE ACTION\\nPAR: BO H...  S207  27.0    S207   \n",
       "\n",
       "         role number  start_time  end_time  \\\n",
       "S160  INV+PAR      1           0     25308   \n",
       "S161  INV+PAR      0           0     73291   \n",
       "S162  INV+PAR      1           0     74751   \n",
       "S163  INV+PAR      0           0     75438   \n",
       "S164  INV+PAR      7           0     33208   \n",
       "S165  INV+PAR     10           0    101287   \n",
       "S166  INV+PAR     33           0    167767   \n",
       "S167  INV+PAR     10           0    267007   \n",
       "S168  INV+PAR      2           0     41262   \n",
       "S169  INV+PAR      2           0     64857   \n",
       "S170  INV+PAR      1           0     40528   \n",
       "S171  INV+PAR      2           0     68202   \n",
       "S172  INV+PAR      5           0     72884   \n",
       "S173  INV+PAR      7           0     75294   \n",
       "S174  INV+PAR      7           0    114629   \n",
       "S175  INV+PAR     11           0    120602   \n",
       "S176  INV+PAR     17           0     94689   \n",
       "S177  INV+PAR      8           0    105982   \n",
       "S178  INV+PAR      6           0     75545   \n",
       "S179  INV+PAR      1           0     71112   \n",
       "S180  INV+PAR      1           0     66818   \n",
       "S181  INV+PAR      9           0     98237   \n",
       "S182  INV+PAR     19           0    157145   \n",
       "S183  INV+PAR      5           0     97443   \n",
       "S184  INV+PAR      9           0    100478   \n",
       "S185  INV+PAR      1           0     57880   \n",
       "S186  INV+PAR      1           0     66897   \n",
       "S187  INV+PAR     10           0    163188   \n",
       "S188  INV+PAR      2           0     95467   \n",
       "S189  INV+PAR      4           0     78733   \n",
       "S190  INV+PAR      2           0    116198   \n",
       "S191  INV+PAR      0           0    135903   \n",
       "S192  INV+PAR     13           0    127980   \n",
       "S193  INV+PAR     13           0     69851   \n",
       "S194  INV+PAR      0           0     35974   \n",
       "S195  INV+PAR      9           0     41320   \n",
       "S196  INV+PAR      0           0     41200   \n",
       "S197  INV+PAR      0           0     52779   \n",
       "S198  INV+PAR      3           0     51191   \n",
       "S199  INV+PAR      1           0     58009   \n",
       "S200  INV+PAR      4           0     40934   \n",
       "S201  INV+PAR      6           0     57446   \n",
       "S202  INV+PAR      2           0     78329   \n",
       "S203  INV+PAR      3           0     50858   \n",
       "S204  INV+PAR      0           0     38586   \n",
       "S205  INV+PAR      3           0     59299   \n",
       "S206  INV+PAR      1           0     76182   \n",
       "S207  INV+PAR      1           0     48372   \n",
       "\n",
       "                                              Embedding  \\\n",
       "S160  [-0.017200241456827626, 0.016914930776282977, ...   \n",
       "S161  [-0.011408883298941883, 0.01720419362756741, 0...   \n",
       "S162  [-0.017208302246136026, -0.0005765883202629639...   \n",
       "S163  [-0.023935779514867146, -0.0017524650216672048...   \n",
       "S164  [-0.01118055865047027, 0.029392665740456726, 0...   \n",
       "S165  [-0.010539898705052297, 0.008740892839361516, ...   \n",
       "S166  [-0.023409109270509928, 0.02357328839984978, 0...   \n",
       "S167  [-0.019582836821966258, 0.022503438467869303, ...   \n",
       "S168  [-0.02177493675064444, 0.010412626103897458, 0...   \n",
       "S169  [-0.029138698425263773, 0.00752970463807912, 0...   \n",
       "S170  [-0.01742267403864414, 0.010395887197354122, 0...   \n",
       "S171  [-0.013063071499074331, 0.004969197868464235, ...   \n",
       "S172  [-0.017618706412876176, 0.01596906591579406, 0...   \n",
       "S173  [-0.02399181166392612, 0.02215795358036029, 0....   \n",
       "S174  [-0.0156752196455846, 0.010762393140391615, 0....   \n",
       "S175  [-0.01542252257722733, 0.020441851920849786, 0...   \n",
       "S176  [-0.016498148059967948, 0.014675220135390145, ...   \n",
       "S177  [-0.0017595761536363056, 0.006366498331891652,...   \n",
       "S178  [-0.021014778847333167, 0.007265109237362094, ...   \n",
       "S179  [-0.009437096937888773, 0.008546678078926616, ...   \n",
       "S180  [-0.02204846845042956, 0.007690075556504581, 0...   \n",
       "S181  [-0.018814830106520058, -0.0050965300364263924...   \n",
       "S182  [-0.016777639987730828, 0.005909546666281508, ...   \n",
       "S183  [-0.015054313462163862, 0.011930708577192113, ...   \n",
       "S184  [0.0015690418099436455, -0.016748680447425682,...   \n",
       "S185  [-0.011397738605338697, 0.014988060599226088, ...   \n",
       "S186  [-0.003002290124395314, 0.025734882463847836, ...   \n",
       "S187  [-0.008125194182623635, 0.017210270858352264, ...   \n",
       "S188  [-0.023653150128251723, 0.008754191424517646, ...   \n",
       "S189  [-0.012884860728218938, 0.010804914760267655, ...   \n",
       "S190  [-0.02227273647255223, 0.012765429348586097, 0...   \n",
       "S191  [-0.027742111493210667, 0.016615378517931767, ...   \n",
       "S192  [-0.013981684870589546, -0.0008102332798393739...   \n",
       "S193  [-0.019742048307550913, 0.018121634498715018, ...   \n",
       "S194  [-0.009621753460460705, 0.003454565238871823, ...   \n",
       "S195  [-0.0021249447820338115, 0.02598543464806268, ...   \n",
       "S196  [-0.01859882289466125, 0.0020314583108699564, ...   \n",
       "S197  [-0.014282264086954977, 0.005531532900060594, ...   \n",
       "S198  [-0.020178594912254166, 0.013416403475338916, ...   \n",
       "S199  [-0.018019140791406957, 0.008817146122220046, ...   \n",
       "S200  [-0.01397226463441031, -0.0019452706931580325,...   \n",
       "S201  [-0.020321667180211007, 0.012150132837827668, ...   \n",
       "S202  [-0.017056077172014118, -0.001045339239387044,...   \n",
       "S203  [-0.017804934583466395, 0.008595721317696607, ...   \n",
       "S204  [-0.0041423884474207605, -0.002759343542451781...   \n",
       "S205  [-0.004579121383329486, 0.02591802815807409, 0...   \n",
       "S206  [-0.0074447772256718845, 0.008405173789683543,...   \n",
       "S207  [-0.022953584155319114, -0.006614187620455314,...   \n",
       "\n",
       "                                          Psych_Summary  \\\n",
       "S160  detected problems:\\nEmpty speech: PAR's speech...   \n",
       "S161  Detected problems:\\n- Trailing off speech: \"AN...   \n",
       "S162  detected problems: trailing off speech\\n\\nSumm...   \n",
       "S163  detected problems: trailing off speech\\nSummar...   \n",
       "S164  detected problems:\\n- Empty speech: The speake...   \n",
       "S165  Detected problems:\\n- Trailing off speech: PAR...   \n",
       "S166  detected problems:\\n- Empty speech: PAR provid...   \n",
       "S167  Detected problems: \\n- Empty speech: PAR's spe...   \n",
       "S168  detected problems:\\n- Empty speech: PAR's spee...   \n",
       "S169  detected problems:\\n- Empty speech: The PAR's ...   \n",
       "S170  detected problems:\\n- Empty speech: The speake...   \n",
       "S171  detected problems:\\n- Empty speech\\n- Trailing...   \n",
       "S172  detected problems: \\n- Trailing off speech: PA...   \n",
       "S173  detected problems: \\n\\nPAR's speech does not e...   \n",
       "S174  detected problems: \\n- Empty speech: The speak...   \n",
       "S175  detected problems:\\nEmpty speech: Eloquent art...   \n",
       "S176  Detected problems:\\n- Empty speech: PAR's spee...   \n",
       "S177  Detected problems: \\n- Empty speech: \"START WH...   \n",
       "S178  detected problems: \\n- Empty speech: PAR's spe...   \n",
       "S179  detected problems: \\n- Empty speech: The utter...   \n",
       "S180  detected problems: \\n- Empty speech: The speak...   \n",
       "S181  detected problems: trailing off speech\\nSummar...   \n",
       "S182  detected problems:\\n- Empty speech: The PAR's ...   \n",
       "S183  detected problems: \\n- Empty speech: The PAR p...   \n",
       "S184                                                      \n",
       "S185  detected problems:\\n- Empty speech: The PAR pr...   \n",
       "S186  detected problems:\\n- Empty speech: The PAR's ...   \n",
       "S187  Detected problems:\\n- Trailing off speech: In ...   \n",
       "S188  detected problems:\\n- Trailing off speech: PAR...   \n",
       "S189  detected problems:\\n- Empty speech: Eloquent a...   \n",
       "S190  detected problems: \\nEmpty speech: The PAR's r...   \n",
       "S191  detected problems: \\nEmpty speech: PAR's respo...   \n",
       "S192  Detected problems: \\n- Empty speech: PAR frequ...   \n",
       "S193  detected problems: \\n- Empty speech\\n- Trailin...   \n",
       "S194  Detected problems: \\n- Empty speech: The PAR p...   \n",
       "S195  detected problems:\\n- Trailing off speech: \"AN...   \n",
       "S196  detected problems:\\nEmpty speech: In the dialo...   \n",
       "S197  detected problems:\\n- Empty speech: The PAR's ...   \n",
       "S198  Detected problems: \\n- Empty speech: The speak...   \n",
       "S199  detected problems:\\n- Empty speech\\n- Trailing...   \n",
       "S200  detected problems: \\n\\nEmpty speech: The state...   \n",
       "S201  detected problems:\\n- Empty speech: The PAR pr...   \n",
       "S202  detected problems: \\n- Empty speech: PAR's res...   \n",
       "S203  detected problems:\\n- Empty speech: The speake...   \n",
       "S204  detected problems: trailing off speech\\nSummar...   \n",
       "S205  detected problems: \\nEmpty speech: The PAR pro...   \n",
       "S206  Detected problems:\\n- Trailing off speech: In ...   \n",
       "S207  detected problems: trailing off speech\\nSummar...   \n",
       "\n",
       "                                           Psych_Prompt  \n",
       "S160  psycological definition:\\n\\n            - defi...  \n",
       "S161  psycological definition:\\n\\n            - defi...  \n",
       "S162  psycological definition:\\n\\n            - defi...  \n",
       "S163  psycological definition:\\n\\n            - defi...  \n",
       "S164  psycological definition:\\n\\n            - defi...  \n",
       "S165  psycological definition:\\n\\n            - defi...  \n",
       "S166  psycological definition:\\n\\n            - defi...  \n",
       "S167  psycological definition:\\n\\n            - defi...  \n",
       "S168  psycological definition:\\n\\n            - defi...  \n",
       "S169  psycological definition:\\n\\n            - defi...  \n",
       "S170  psycological definition:\\n\\n            - defi...  \n",
       "S171  psycological definition:\\n\\n            - defi...  \n",
       "S172  psycological definition:\\n\\n            - defi...  \n",
       "S173  psycological definition:\\n\\n            - defi...  \n",
       "S174  psycological definition:\\n\\n            - defi...  \n",
       "S175  psycological definition:\\n\\n            - defi...  \n",
       "S176  psycological definition:\\n\\n            - defi...  \n",
       "S177  psycological definition:\\n\\n            - defi...  \n",
       "S178  psycological definition:\\n\\n            - defi...  \n",
       "S179  psycological definition:\\n\\n            - defi...  \n",
       "S180  psycological definition:\\n\\n            - defi...  \n",
       "S181  psycological definition:\\n\\n            - defi...  \n",
       "S182  psycological definition:\\n\\n            - defi...  \n",
       "S183  psycological definition:\\n\\n            - defi...  \n",
       "S184  psycological definition:\\n\\n            - defi...  \n",
       "S185  psycological definition:\\n\\n            - defi...  \n",
       "S186  psycological definition:\\n\\n            - defi...  \n",
       "S187  psycological definition:\\n\\n            - defi...  \n",
       "S188  psycological definition:\\n\\n            - defi...  \n",
       "S189  psycological definition:\\n\\n            - defi...  \n",
       "S190  psycological definition:\\n\\n            - defi...  \n",
       "S191  psycological definition:\\n\\n            - defi...  \n",
       "S192  psycological definition:\\n\\n            - defi...  \n",
       "S193  psycological definition:\\n\\n            - defi...  \n",
       "S194  psycological definition:\\n\\n            - defi...  \n",
       "S195  psycological definition:\\n\\n            - defi...  \n",
       "S196  psycological definition:\\n\\n            - defi...  \n",
       "S197  psycological definition:\\n\\n            - defi...  \n",
       "S198  psycological definition:\\n\\n            - defi...  \n",
       "S199  psycological definition:\\n\\n            - defi...  \n",
       "S200  psycological definition:\\n\\n            - defi...  \n",
       "S201  psycological definition:\\n\\n            - defi...  \n",
       "S202  psycological definition:\\n\\n            - defi...  \n",
       "S203  psycological definition:\\n\\n            - defi...  \n",
       "S204  psycological definition:\\n\\n            - defi...  \n",
       "S205  psycological definition:\\n\\n            - defi...  \n",
       "S206  psycological definition:\\n\\n            - defi...  \n",
       "S207  psycological definition:\\n\\n            - defi...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
