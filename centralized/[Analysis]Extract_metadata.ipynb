{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               path  \\\n",
      "0        S015_PAR_7_26693_32357.wav   \n",
      "1        S076_PAR_8_37400_38800.wav   \n",
      "2       S018_PAR_12_68242_69305.wav   \n",
      "3        S062_PAR_2_14910_19143.wav   \n",
      "4        S059_PAR_4_14123_15540.wav   \n",
      "...                             ...   \n",
      "1863     S128_PAR_2_14645_16871.wav   \n",
      "1864       S093_PAR_1_7950_9462.wav   \n",
      "1865    S142_PAR_10_48811_65198.wav   \n",
      "1866  S107_PAR_19_114314_116598.wav   \n",
      "1867      S129_PAR_4_9789_11833.wav   \n",
      "\n",
      "                                                   text  dementia_labels  \\\n",
      "0     THE STOOL IS TIPPING FOR THE LITTLE BOY AND HE...                0   \n",
      "1                                       IT MUST BE JUNE                0   \n",
      "2                                I DON'T SEE IT SNOWING                0   \n",
      "3     THE COOKIE JAR IS OPEN OF COURSE THE CUPBOARD'...                0   \n",
      "4                              THE WATER'S RUNNING OVER                0   \n",
      "...                                                 ...              ...   \n",
      "1863                                         COOKIE JAR                1   \n",
      "1864                           AND HE'S GETTING COOKIES                1   \n",
      "1865  SHE'S GOT UH A DRESS ON AND AND THERE'S SHE'S ...                1   \n",
      "1866                                WINDOWS WINDOWS WIN                1   \n",
      "1867                 WATER'S POURING ALL OVER THE FLOOR                1   \n",
      "\n",
      "                                               pred_str ID    mmse  \n",
      "0     THE STOOL IS TIPPING OT THE LITTLE BOY AND HE'...  S015   29  \n",
      "1                                       IT MUST BE JUNE  S076   28  \n",
      "2                                I DON'T SEE IT SNOWING  S018   29  \n",
      "3     THE COOKIE JAR IS OPEN OF COURSE THE CUPBOARD'...  S062   30  \n",
      "4                              THE WATER'S RUNNING OVER  S059   30  \n",
      "...                                                 ...   ...  ...  \n",
      "1863                                         COOKIE JAR  S128   16  \n",
      "1864                           AND HE'S GETTING COOKIES  S093   25  \n",
      "1865  SHE'S GOT UH A DRESS ON AND AND THERE'S SHE'S ...  S142   14  \n",
      "1866                                  WINDOW WINDOWS IN  S107   22  \n",
      "1867                 WATER'S POURING ALL OVER THE FLOOR  S129   19  \n",
      "\n",
      "[1868 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 這個腳本會新增mmse和ID 這兩個項目\n",
    "\n",
    "ad_train_file = \"/mnt/Internal/FedASR/Data/ADReSS-IS2020-data/train/cd_meta_data.txt\"\n",
    "hc_train_file = \"/mnt/Internal/FedASR/Data/ADReSS-IS2020-data/train/cc_meta_data.txt\"\n",
    "test_file = \"/mnt/Internal/FedASR/Data/ADReSS-IS2020-data/test/meta_data_test.txt\"\n",
    "\n",
    "# 讀取CSV文件並轉換為DataFrame\n",
    "ad_df = pd.read_csv(ad_train_file, delimiter=';')\n",
    "hc_df = pd.read_csv(hc_train_file, delimiter=';')\n",
    "test_df = pd.read_csv(test_file, delimiter=';')\n",
    "\n",
    "# 將兩個DataFrame疊起來\n",
    "merged_df = pd.concat([ad_df, hc_df, test_df], ignore_index=True)\n",
    "\n",
    "#############\n",
    "ASR_train_file='/home/FedASR/dacs/centralized/saves/results/data2vec-audio-large-960h_train.csv'\n",
    "ASR_test_file='/home/FedASR/dacs/centralized/saves/results/data2vec-audio-large-960h_test.csv'\n",
    "ASR_dev_file='/home/FedASR/dacs/centralized/saves/results/data2vec-audio-large-960h_dev.csv'\n",
    "ASR_train_df = pd.read_csv(ASR_train_file, delimiter=',')\n",
    "ASR_test_df = pd.read_csv(ASR_test_file, delimiter=',')\n",
    "ASR_dev_df = pd.read_csv(ASR_dev_file, delimiter=',')\n",
    "ASR_train_df['ID   ']=ASR_train_df['path'].apply(lambda x: x.split('.')[0].split(\"_\")[0])\n",
    "ASR_test_df['ID   ']=ASR_test_df['path'].apply(lambda x: x.split('.')[0].split(\"_\")[0])\n",
    "ASR_dev_df['ID   ']=ASR_dev_df['path'].apply(lambda x: x.split('.')[0].split(\"_\")[0])\n",
    "\n",
    "for i, row in ASR_train_df.iterrows():\n",
    "    session=row['ID   ']\n",
    "    val=merged_df[merged_df['ID   ']==f'{session} ']['mmse'].values[0]\n",
    "    mmse=val.lstrip() if type(val)==str else val\n",
    "    ASR_train_df.loc[i,\"mmse\"]=mmse\n",
    "\n",
    "for i, row in ASR_dev_df.iterrows():\n",
    "    session=row['ID   ']\n",
    "    val=merged_df[merged_df['ID   ']==f'{session} ']['mmse'].values[0]\n",
    "    mmse=val.lstrip() if type(val)==str else val\n",
    "    ASR_dev_df.loc[i,\"mmse\"]=mmse\n",
    "\n",
    "for i, row in ASR_test_df.iterrows():\n",
    "    session=row['ID   ']\n",
    "    val=merged_df[merged_df['ID   ']==f'{session} ']['mmse'].values[0]\n",
    "    mmse=val.lstrip() if type(val)==str else val\n",
    "    ASR_test_df.loc[i,\"mmse\"]=mmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(ASR_train_df)\n",
    "# merged_df_sorted = merged_df.sort_values(by='mmse', na_position='first')\n",
    "# ASR_train_df=ASR_train_df.drop('ID   ')\n",
    "ASR_train_df.to_csv(ASR_train_file)\n",
    "ASR_test_df.to_csv(ASR_test_file)\n",
    "ASR_dev_df.to_csv(ASR_dev_file)\n",
    "merged_df.to_csv(\"./saves/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df['ID   ']==session]\n",
    "\n",
    "merged_df[merged_df['ID   ']==f'{session} ']['mmse'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.merge(ASR_train_df, merged_df[['ID   ', 'mmse']], on='ID   ', how='left')\n",
    "\n",
    "ASR_train_df.set_index('ID   ', inplace=True)\n",
    "merged_df.set_index('ID   ', inplace=True)\n",
    "\n",
    "result_df = ASR_train_df.join(merged_df[['mmse']], how='left')\n",
    "\n",
    "# 打印合併後的 DataFrame\n",
    "print(\"Merged DataFrame:\")\n",
    "print(result_df.reset_index())\n",
    "\n",
    "# print(ASR_train_df['path'])\n",
    "print(len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
