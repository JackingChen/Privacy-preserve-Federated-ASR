{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# torch:\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor\n",
    "from transformers import BertTokenizer, BertConfig, BertModel,XLMTokenizer, XLMModel\n",
    "\n",
    "from Dementia_challenge_models import SingleForwardModel, BertPooler, Audio_pretrain, ModelArg, Model_settings_dict, Text_pretrain, Text_Summary\n",
    "import librosa\n",
    "\n",
    "\n",
    "class Model(SingleForwardModel):\n",
    "    def __init__(self, args, config):\n",
    "        super().__init__(args, config)\n",
    "        self.inp1Arg = args.inp1Arg\n",
    "        self.inp2Arg = args.inp2Arg\n",
    "        self.inp1_embed_type = self.config['inp1_embed']\n",
    "        self.inp2_embed_type = self.config['inp2_embed']\n",
    "        self.inp1_col_name = self.inp1Arg.inp_col_name\n",
    "        self.inp2_col_name = self.inp2Arg.inp_col_name\n",
    "        \n",
    "\n",
    "        self.inp1_hidden_size = self.inp1Arg.inp_hidden_size\n",
    "        self.inp2_hidden_size = self.inp2Arg.inp_hidden_size\n",
    "        self.hidden = int(self.inp1_hidden_size + self.inp2_hidden_size)\n",
    "        self.alignhiddensize=min(self.inp1_hidden_size,self.inp2_hidden_size)\n",
    "\n",
    "        # self.clf1 = nn.Linear(self.inp1_hidden_size, self.alignhiddensize)\n",
    "        # self.clf2 = nn.Linear(self.inp1_hidden_size, self.alignhiddensize)\n",
    "        self.pool=nn.AdaptiveMaxPool2d((1, self.alignhiddensize)) #ex) [16, 500, 768] -> [16, 1, self.hidden_size] \n",
    "        self.inp1_tokenizer, self.inp1_model, self.pooler1=self._setup_embedding(self.inp1_embed_type, self.inp1_hidden_size)\n",
    "        self.inp2_tokenizer, self.inp2_model, self.pooler2=self._setup_embedding(self.inp2_embed_type, self.inp2_hidden_size)\n",
    "\n",
    "        self.ta_nh = self.config['ta_nh']\n",
    "        self.at_nh = self.config['at_nh']\n",
    "        \n",
    "        self.ta_dp = self.config['ta_dp']\n",
    "        self.at_dp = self.config['at_dp']\n",
    "\n",
    "        self.mha_a_t = nn.MultiheadAttention(embed_dim=self.alignhiddensize, num_heads= self.ta_nh,dropout=self.at_dp)\n",
    "        self.mha_t_a = nn.MultiheadAttention(embed_dim=self.alignhiddensize, num_heads= self.ta_nh ,dropout= self.ta_dp)\n",
    "        hidden_half=int(self.hidden/2)\n",
    "        self.dense1 = nn.Linear(self.hidden, hidden_half)\n",
    "        self.dense2 = nn.Linear(hidden_half, hidden_half)\n",
    "        self.dense3 = nn.Linear(hidden_half, self.num_labels)\n",
    "    def forward(self, inp1, inp2):\n",
    "        # Add or modify the forward method for NewModel2\n",
    "        # You can still use the functionality from the parent class by calling super().forward(inp)\n",
    "        # ...\n",
    "        out1 = self._get_embedding(inp1,self.inp1_embed_type, self.inp1_model, self.pooler1)\n",
    "        out2 = self._get_embedding(inp2,self.inp2_embed_type, self.inp2_model, self.pooler2)\n",
    "        out1, out2 = self.pool(out1), self.pool(out2)\n",
    "\n",
    "        # audio to text \n",
    "        x_a2t, _ = self.mha_a_t(out1, out2, out2) \n",
    "        x_a2t = torch.mean(x_a2t, dim=1)\n",
    "        \n",
    "        # text to audio  \n",
    "        x_t2a, _ = self.mha_t_a(out2, out1, out1) \n",
    "        x_t2a = torch.mean(x_t2a, dim=1)\n",
    "\n",
    "        x_ta2 = torch.stack((x_a2t, x_t2a), dim=1) \n",
    "        x_ta2_mean, x_ta2_std = torch.std_mean(x_ta2, dim=1)\n",
    "        x_ta2 = torch.cat((x_ta2_mean, x_ta2_std), dim=1) \n",
    "        fuse = x_ta2\n",
    "\n",
    "        logits=self.dense3(self.dense2(self.dense1(fuse)))   \n",
    "    \n",
    "        return logits\n",
    "    def preprocess_dataframe(self):\n",
    "        \n",
    "        df_train = pd.read_csv(f\"{self.inp1Arg.file_in}/train.csv\")\n",
    "        df_dev = pd.read_csv(f\"{self.inp1Arg.file_in}/dev.csv\")\n",
    "        df_test = pd.read_csv(f\"{self.inp1Arg.file_in}/test.csv\")\n",
    "        self.df_train=self._Tokenize(df_train, self.inp1_embed_type, self.inp1Arg.inp_col_name, self.inp1_tokenizer)\n",
    "        self.df_dev=self._Tokenize(df_dev, self.inp1_embed_type, self.inp1Arg.inp_col_name, self.inp1_tokenizer)\n",
    "        self.df_test=self._Tokenize(df_test, self.inp1_embed_type, self.inp1Arg.inp_col_name, self.inp1_tokenizer)\n",
    "\n",
    "        self._preprocess_loaded_summaries(self.inp2_embed_type,self.inp2Arg.inp_col_name, self.inp2_tokenizer)\n",
    "        self._merge_DataAug2Data()\n",
    "        print(f'# of train:{len(df_train)}, val:{len(df_dev)}, test:{len(df_test)}')\n",
    "        self._df2Dataset()\n",
    "\n",
    "    def _preprocess_loaded_summaries(self,inp2_embed_type,inp_col_name,inp2_tokenizer):\n",
    "        df_train = pd.read_pickle(f\"{self.inp2Arg.file_in}/train.pkl\")\n",
    "        df_dev = pd.read_pickle(f\"{self.inp2Arg.file_in}/dev.pkl\")\n",
    "        df_test = pd.read_pickle(f\"{self.inp2Arg.file_in}/test.pkl\")\n",
    "\n",
    "\n",
    "        df_train=self._Tokenize(df_train, inp2_embed_type,inp_col_name, inp2_tokenizer)\n",
    "        df_dev=self._Tokenize(df_dev, inp2_embed_type,inp_col_name, inp2_tokenizer)\n",
    "        df_test=self._Tokenize(df_test, inp2_embed_type,inp_col_name, inp2_tokenizer)\n",
    "\n",
    "        \n",
    "        df_test = df_test.reset_index(drop=True)\n",
    "        self.df_train_aug=df_train\n",
    "        self.df_dev_aug=df_dev\n",
    "        self.df_test_aug=df_test\n",
    "        self.Aug_col_name=self.inp2Arg.inp_col_name\n",
    "\n",
    "    def _merge_DataAug2Data(self):\n",
    "        pname_col_name='ID   '\n",
    "        similar_col_name='session'\n",
    "        def AppendID(df_data):\n",
    "            if pname_col_name not in df_data.columns:\n",
    "                df_data[pname_col_name]=df_data[similar_col_name]\n",
    "        AppendID(self.df_train_aug)\n",
    "        AppendID(self.df_dev_aug)\n",
    "        AppendID(self.df_test_aug)\n",
    "\n",
    "        self.df_train = pd.merge(self.df_train, self.df_train_aug, on='ID   ', how='left', suffixes=('', '_aug'))\n",
    "        self.df_dev = pd.merge(self.df_dev, self.df_dev_aug, on='ID   ', how='left', suffixes=('', '_aug'))\n",
    "        self.df_test = pd.merge(self.df_test, self.df_test_aug, on='ID   ', how='left', suffixes=('', '_aug'))\n",
    " \n",
    "    def _df2Dataset(self):\n",
    "        dtype1=self._DecideDtype(self.inp1_embed_type)\n",
    "        dtype2=self._DecideDtype(self.inp2_embed_type)\n",
    "        \n",
    "        self.train_data = TensorDataset(\n",
    "            torch.tensor(self.df_train[self.inp1Arg.inp_col_name].tolist(), dtype=dtype1),\n",
    "            torch.tensor(self.df_train[self.inp2Arg.inp_col_name].tolist(), dtype=dtype2),\n",
    "            torch.tensor(self.df_train[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "        \n",
    "        self.val_data = TensorDataset(\n",
    "             torch.tensor(self.df_dev[self.inp1Arg.inp_col_name].tolist(), dtype=dtype1),\n",
    "             torch.tensor(self.df_dev[self.inp2Arg.inp_col_name].tolist(), dtype=dtype2),\n",
    "            torch.tensor(self.df_dev[self.label_cols].tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        self.test_data = TensorDataset(\n",
    "             torch.tensor(self.df_test[self.inp1Arg.inp_col_name].tolist(), dtype=dtype1),\n",
    "             torch.tensor(self.df_test[self.inp2Arg.inp_col_name].tolist(), dtype=dtype2),\n",
    "            torch.tensor(self.df_test[self.label_cols].tolist(), dtype=torch.long),\n",
    "             torch.tensor(self.df_test.index.tolist(), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inp1, inp2, labels = batch  \n",
    "        # token,  labels = batch  \n",
    "        logits = self(inp1, inp2) \n",
    "        # logits = self(token) \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)   \n",
    "        \n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inp1, inp2, labels = batch  \n",
    "        # token, labels = batch  \n",
    "        logits = self(inp1, inp2) \n",
    "        # logits = self(token) \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)     \n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true = list(labels.cpu().numpy())\n",
    "        y_pred = list(preds.cpu().numpy())\n",
    "\n",
    "        # --> HERE STEP 2 <--\n",
    "        self.val_step_outputs.append({\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        })\n",
    "        # self.val_step_targets.append(y_true)\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inp1, inp2, labels,id_ = batch \n",
    "        # token, labels,id_ = batch \n",
    "        print('id', id_)\n",
    "        logits = self(inp1, inp2) \n",
    "        # logits = self(token) \n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true = list(labels.cpu().numpy())\n",
    "        y_pred = list(preds.cpu().numpy())\n",
    "\n",
    "        # --> HERE STEP 2 <--\n",
    "        self.test_step_outputs.append({\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        })\n",
    "        # self.test_step_targets.append(y_true)\n",
    "        return {\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "\n",
    "    def _save_results_to_csv(self, df_result, pred_dict, args, suffix):\n",
    "        # Save df_result to CSV\n",
    "        df_result.to_csv(f'{args.Output_dir}/{self.inp1_embed_type}_{self.inp2_embed_type}{suffix}.csv')\n",
    "\n",
    "        # Save pred_df to CSV\n",
    "        pred_df = pd.DataFrame(pred_dict)\n",
    "        pred_df.to_csv(f'{args.Output_dir}/{self.inp1_embed_type}_{self.inp2_embed_type}{suffix}_pred.csv')\n",
    "\n",
    "\n",
    "\n",
    "def main(args,config):\n",
    "    print(\"Using PyTorch Ver\", torch.__version__)\n",
    "    print(\"Fix Seed:\", config['random_seed'])\n",
    "    seed_everything( config['random_seed'])\n",
    "        \n",
    "    if config['task']=='regression':\n",
    "        model=ModelRegression(args,config)\n",
    "    elif config['task']=='classification':\n",
    "        model = Model(args,config) \n",
    "    else:\n",
    "        raise ValueError()\n",
    "    model.preprocess_dataframe()\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=f\"{SaveRoot}/Model/{config['params_tuning_str']}/checkpoints\",\n",
    "        monitor='val_acc',\n",
    "        auto_insert_metric_name=True,\n",
    "        verbose=True,\n",
    "        mode='max', \n",
    "        save_top_k=1,\n",
    "      )    \n",
    "\n",
    "    print(\":: Start Training ::\")\n",
    "    #     \n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        callbacks=[early_stop_callback,checkpoint_callback],\n",
    "        # callbacks=[early_stop_callback],\n",
    "        enable_checkpointing = True,\n",
    "        max_epochs=args.mdlArg.epochs,\n",
    "        fast_dev_run=args.mdlArg.test_mode,\n",
    "        num_sanity_val_steps=None if args.mdlArg.test_mode else 0,\n",
    "        # deterministic=True, # True會有bug，先false\n",
    "        deterministic=False,\n",
    "        # For GPU Setup\n",
    "        # gpus=[config['gpu']] if torch.cuda.is_available() else None,\n",
    "        strategy='ddp_find_unused_parameters_true',\n",
    "        precision=16 if args.mdlArg.fp16 else 32\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model,dataloaders=model.test_dataloader(),ckpt_path=\"best\")\n",
    "    \n",
    "\n",
    "if __name__ == '__main__': \n",
    "\n",
    "    parser = argparse.ArgumentParser(\"main.py\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\"--gpu\", type=int, default=1)\n",
    "\n",
    "    parser.add_argument(\"--epochs\", type=int, default=5)\n",
    "    parser.add_argument(\"--lr\", type=float, default=2e-5, help=\"learning rate\")\n",
    "    parser.add_argument(\"--lr_scheduler\", type=str, default='exp', help=\"learning rate\")\n",
    "\n",
    "    parser.add_argument(\"--ta_nh\", type=int, default=2)\n",
    "    parser.add_argument(\"--at_nh\", type=int, default=2)\n",
    "    parser.add_argument(\"--ta_dp\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--at_dp\", type=float, default=0.1)\n",
    "\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=2023) \n",
    "    parser.add_argument(\"--inp1_embed\", type=str, default=\"albert-base-v1\", help=\"should only be raw text or raw audio. It has to be sentence level stuff\") \n",
    "    parser.add_argument(\"--inp2_embed\", type=str, default=\"anomia\", help=\"\") \n",
    "    parser.add_argument(\"--SaveRoot\", type=str, default='/mnt/External/Seagate/FedASR/LLaMa2/dacs') \n",
    "    parser.add_argument(\"--task\", type=str, default=\"classification\") \n",
    "\n",
    "    \n",
    "    config = parser.parse_args(args=[])\n",
    "    SaveRoot=config.SaveRoot\n",
    "    __file__ = os.path.abspath(\"__file__\")\n",
    "\n",
    "    script_path, file_extension = os.path.splitext(__file__)\n",
    "\n",
    "    config.params_tuning_str='__'.join([config.inp1_embed,config.inp2_embed])\n",
    "    # 使用os.path模組取得檔案名稱\n",
    "    script_name = os.path.basename(script_path)\n",
    "    task_str='result_regression' if config.task=='regression' else 'result_classification'\n",
    "    Output_dir=f\"{SaveRoot}/{task_str}/{script_name}/\" \n",
    "    os.makedirs(Output_dir, exist_ok=True)\n",
    "    print(config)\n",
    "\n",
    "    \n",
    "    class Inp1Arg:\n",
    "        inp_hidden_size = Model_settings_dict[config.inp1_embed]['inp_hidden_size']\n",
    "        pool_hidden_size = inp_hidden_size # BERT-base: 768, BERT-large: 1024, BERT paper setting\n",
    "        linear_hidden_size = inp_hidden_size\n",
    "        inp_col_name = Model_settings_dict[config.inp1_embed]['inp_col_name']\n",
    "        file_in = Model_settings_dict[config.inp1_embed]['file_in']\n",
    "    class Inp2Arg:\n",
    "        inp_hidden_size = Model_settings_dict[config.inp2_embed]['inp_hidden_size']\n",
    "        pool_hidden_size = inp_hidden_size # BERT-base: 768, BERT-large: 1024, BERT paper setting\n",
    "        linear_hidden_size = inp_hidden_size\n",
    "        inp_col_name = Model_settings_dict[config.inp2_embed]['inp_col_name']\n",
    "        file_in = Model_settings_dict[config.inp2_embed]['file_in']\n",
    "    class Arg:\n",
    "        mdlArg=ModelArg()\n",
    "        inp1Arg=Inp1Arg()\n",
    "        inp2Arg=Inp2Arg()\n",
    "        Output_dir=Output_dir\n",
    "\n",
    "    args = Arg()\n",
    "    args.mdlArg.epochs=config.epochs\n",
    "    # main(args,config.__dict__)       \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed en\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed xlm --a_embed en\n",
    "\n",
    "# don\n",
    "python 0207_DM_multi.py --gpu 0 --t_embed xlm --a_embed gr\n",
    "python 0207_DM_multi.py --gpu 1 --t_embed mbert --a_embed gr\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arg()\n",
    "args.mdlArg.epochs=config.epochs\n",
    "model = Model(args,config.__dict__) \n",
    "model.preprocess_dataframe()\n",
    "self=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataloader\n",
    "test_dataloader = model.test_dataloader()\n",
    "\n",
    "# Iterate over the dataloader to get one batch\n",
    "for batch in test_dataloader:\n",
    "    # Use the batch as needed\n",
    "    # For example, print the batch size\n",
    "    print(\"Batch size:\", len(batch))\n",
    "    break  # Break the loop after the first batch\n",
    "\n",
    "\n",
    "# out1 = self._get_embedding(inp1,self.inp1_embed_type, self.inp1_model, self.pooler1)\n",
    "# out2 = self._get_embedding(inp2,self.inp2_embed_type, self.inp2_model, self.pooler2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1, inp2, labels,id_ = batch \n",
    "\n",
    "# Add or modify the forward method for NewModel2\n",
    "# You can still use the functionality from the parent class by calling super().forward(inp)\n",
    "# ...\n",
    "out1 = self._get_embedding(inp1,self.inp1_embed_type, self.inp1_model, self.pooler1)\n",
    "out2 = self._get_embedding(inp2,self.inp2_embed_type, self.inp2_model, self.pooler2)\n",
    "out1, out2 = self.pool(out1), self.pool(out2)\n",
    "\n",
    "# audio to text \n",
    "x_a2t, _ = self.mha_a_t(out1, out2, out2) \n",
    "x_a2t = torch.mean(x_a2t, dim=1)\n",
    "\n",
    "# text to audio  \n",
    "x_t2a, _ = self.mha_t_a(out2, out1, out1) \n",
    "x_t2a = torch.mean(x_t2a, dim=1)\n",
    "\n",
    "x_ta2 = torch.stack((x_a2t, x_t2a), dim=1) \n",
    "x_ta2_mean, x_ta2_std = torch.std_mean(x_ta2, dim=1)\n",
    "x_ta2 = torch.cat((x_ta2_mean, x_ta2_std), dim=1) \n",
    "fuse = x_ta2\n",
    "\n",
    "logits=self.dense3(self.dense2(self.dense1(fuse))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'shpe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embedding(inp1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minp1_embed_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minp1_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler1)\n\u001b[1;32m      2\u001b[0m out2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embedding(inp2,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minp2_embed_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minp2_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler2)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mout1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshpe\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'shpe'"
     ]
    }
   ],
   "source": [
    "out1 = self._get_embedding(inp1,self.inp1_embed_type, self.inp1_model, self.pooler1)\n",
    "out2 = self._get_embedding(inp2,self.inp2_embed_type, self.inp2_model, self.pooler2)\n",
    "out1_expanded = out1.unsqueeze(1)\n",
    "out2_expanded = out2.unsqueeze(1)\n",
    "\n",
    "\n",
    "\n",
    "# audio to text \n",
    "x_a2t, _ = self.mha_a_t(out1, out2, out2) \n",
    "x_a2t = torch.mean(x_a2t, dim=1)\n",
    "\n",
    "# text to audio  \n",
    "x_t2a, _ = self.mha_t_a(out2, out1, out1) \n",
    "x_t2a = torch.mean(x_t2a, dim=1)\n",
    "\n",
    "# print(x_t2a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
